{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPJ3hWfJOliqvhMrBHiSjSd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapibara3chi/DeepLearningPredictionOfScalarValue/blob/main/DeepLearningPredictionOfScalarValue.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A.I.\n",
        "- [ ] csvデータの読み込み\n",
        "- [x] 精度の確認方法\n",
        "- [x] 精度の改善方法\n",
        "- [▶] モデル構成、 ハイパーパラメーターの最適化方法の実装\n",
        "  - [x] BatchNormalization　各層の正規化\n",
        "  - [ ] 同一 ハイパーパラメータでの最適モデルの選択方法の実装\n",
        "  - [x] 最適化アルゴリズムを利用した最適モデルの選択\n",
        "  - [x] モデルの保存、外部出力方法\n",
        "  - [x] 最適化されたモデルでのモデルの再構築\n",
        "  - [x] 外部モデルの参照方法\n",
        "  - [x] 最適化モデルの保存 → 途中から再開\n",
        "  - [x] グラフ化散布図\n",
        "  - [ ] 過学習防止\n",
        "  - [ ] プルーニングの実装\n",
        "  - [ ] MinMax scalerとstandard scalerどっちがいい？\n",
        "  - [ ] パラメーターの最適化は離散値のほうがいい？\n",
        "  - [x] [[バッチサイズのハイパーパラメータ最適化への考慮]]\n",
        "  - [x] 履歴の外部出力[[最適化履歴を外部ファイルに保存]]\n",
        "  - [ ] ベイズ最適化以外の手法の精度調査"
      ],
      "metadata": {
        "id": "POKgccoDdM10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.pip"
      ],
      "metadata": {
        "id": "cJywH6yY0c5Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL6c-qx7zyGn",
        "outputId": "aa8ba5e9-46ae-4fbb-d217-40fd9bdd2718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy tensorflow scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 基本コードの理解"
      ],
      "metadata": {
        "id": "NmgSKrbt1ABR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## code"
      ],
      "metadata": {
        "id": "ufckqR331FIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import sys\n",
        "\n",
        "\n",
        "# データの読み込み\n",
        "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()\n",
        "## データの確認\n",
        "print(\"train data\")\n",
        "print(f\"data shape{train_data.shape}\")\n",
        "print(f\"data type:{type(train_data)}\")\n",
        "print(f\"data ex:{train_data}\")\n",
        "print(f\"Number of test data:{len(test_data)}\")\n",
        "print(test_data.shape)\n",
        "print(f\"Number of train data:{len(train_data)}\")\n",
        "print(train_data.shape)\n",
        "\n",
        "num_rows,num_cols=train_data.shape\n",
        "print(f\"行数:{num_rows},列数:{num_cols}\")\n",
        "print(train_data.shape[1])\n",
        "# モデルの定義\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "#input_shape:データ列数のタプル※単一次元なので(,)つき\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1))  # 出力層\n",
        "\n",
        "# モデルのコンパイル\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# 過学習の防止 Early stopping\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "## EarlyStoppingコールバックを作成\n",
        "# early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# モデルの学習\n",
        "# history=model.fit(train_data, train_labels, epochs=100, batch_size=8, validation_split=0.2, callbacks=[early_stopping_callback])\n",
        "history=model.fit(train_data, train_labels, epochs=100, batch_size=8, validation_split=0.2)\n",
        "\n",
        "# モデルの評価\n",
        "test_loss, test_mae = model.evaluate(test_data, test_labels)\n",
        "# test_loss, test_mae = model.evaluate(test_data, test_labels,verbose=1)\n",
        "print(f\"Test Loss:{test_loss:.3f}\")\n",
        "print(f\"Test MAE: {test_mae:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# トレーニングと検証の損失をプロット\n",
        "print(type(history.history))\n",
        "print(f\"loss :{history.history['loss']}\")\n",
        "print(f\"loss numb:{len(history.history['loss'])}\")\n",
        "print(f\"val loss :{history.history['val_loss']}\")\n",
        "print(f\"val_loss numb:{len(history.history['val_loss'])}\")\n",
        "# モデルの学習曲線をプロット\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training vs. Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# テストデータセット上で予測を行う\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "# 予測結果を出力する\n",
        "for i, prediction in enumerate(predictions):\n",
        "    print(f\"予測された住宅価格: {prediction[0]:.2f}, 実際の住宅価格: {test_labels[i]}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cjN5ubB41Iuk",
        "outputId": "b10fc6bb-a5f6-44db-9406-06562d62bfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data\n",
            "data shape(404, 13)\n",
            "data type:<class 'numpy.ndarray'>\n",
            "data ex:[[1.23247e+00 0.00000e+00 8.14000e+00 ... 2.10000e+01 3.96900e+02\n",
            "  1.87200e+01]\n",
            " [2.17700e-02 8.25000e+01 2.03000e+00 ... 1.47000e+01 3.95380e+02\n",
            "  3.11000e+00]\n",
            " [4.89822e+00 0.00000e+00 1.81000e+01 ... 2.02000e+01 3.75520e+02\n",
            "  3.26000e+00]\n",
            " ...\n",
            " [3.46600e-02 3.50000e+01 6.06000e+00 ... 1.69000e+01 3.62250e+02\n",
            "  7.83000e+00]\n",
            " [2.14918e+00 0.00000e+00 1.95800e+01 ... 1.47000e+01 2.61950e+02\n",
            "  1.57900e+01]\n",
            " [1.43900e-02 6.00000e+01 2.93000e+00 ... 1.56000e+01 3.76700e+02\n",
            "  4.38000e+00]]\n",
            "Number of test data:102\n",
            "(102, 13)\n",
            "Number of train data:404\n",
            "(404, 13)\n",
            "行数:404,列数:13\n",
            "13\n",
            "Epoch 1/100\n",
            "41/41 [==============================] - 2s 21ms/step - loss: 172.0403 - mae: 9.9192 - val_loss: 84.8795 - val_mae: 6.6094\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 97.9450 - mae: 7.1545 - val_loss: 84.8338 - val_mae: 6.9471\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 66.8656 - mae: 5.6514 - val_loss: 70.4483 - val_mae: 6.3345\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 71.8785 - mae: 6.0587 - val_loss: 74.7569 - val_mae: 6.8676\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 60.7325 - mae: 5.6035 - val_loss: 64.1674 - val_mae: 5.4195\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 49.3583 - mae: 4.7596 - val_loss: 63.6919 - val_mae: 6.2156\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 50.9945 - mae: 5.0502 - val_loss: 61.7769 - val_mae: 6.1566\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 55.8140 - mae: 5.3182 - val_loss: 68.3527 - val_mae: 5.9921\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 48.1966 - mae: 4.8512 - val_loss: 53.2075 - val_mae: 4.7867\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 44.8624 - mae: 4.6145 - val_loss: 49.0751 - val_mae: 5.2196\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 45.1697 - mae: 4.6127 - val_loss: 70.4616 - val_mae: 7.0996\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 56.7961 - mae: 5.3903 - val_loss: 55.7875 - val_mae: 5.1162\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 44.7517 - mae: 4.6166 - val_loss: 60.2479 - val_mae: 6.2914\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 50.8574 - mae: 5.0684 - val_loss: 45.2291 - val_mae: 4.6533\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 47.9762 - mae: 4.9099 - val_loss: 45.2900 - val_mae: 4.7449\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 37.0446 - mae: 4.1939 - val_loss: 49.7087 - val_mae: 5.6578\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 41.6490 - mae: 4.6583 - val_loss: 42.1612 - val_mae: 4.4220\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 37.7492 - mae: 4.2702 - val_loss: 44.9312 - val_mae: 5.0448\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 42.4351 - mae: 4.5652 - val_loss: 42.5525 - val_mae: 4.9717\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 34.5543 - mae: 4.1211 - val_loss: 59.8335 - val_mae: 6.3640\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 47.1779 - mae: 4.8265 - val_loss: 42.6002 - val_mae: 4.9650\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 37.0970 - mae: 4.4500 - val_loss: 42.2358 - val_mae: 4.3023\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 30.5131 - mae: 3.9865 - val_loss: 40.9133 - val_mae: 4.5965\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 36.7386 - mae: 4.3395 - val_loss: 48.7095 - val_mae: 4.8135\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 38.0350 - mae: 4.4543 - val_loss: 66.7582 - val_mae: 6.8196\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 42.1407 - mae: 4.6389 - val_loss: 37.1181 - val_mae: 4.1297\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 32.2800 - mae: 3.8406 - val_loss: 60.0398 - val_mae: 6.7771\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 46.4768 - mae: 4.8151 - val_loss: 51.1386 - val_mae: 6.0084\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 50.0959 - mae: 5.2362 - val_loss: 37.1712 - val_mae: 4.4123\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 36.0939 - mae: 4.3854 - val_loss: 41.6203 - val_mae: 4.3388\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 35.9196 - mae: 4.2001 - val_loss: 34.1363 - val_mae: 4.0253\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 30.9753 - mae: 3.8990 - val_loss: 40.7022 - val_mae: 4.7245\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 28.7822 - mae: 3.8345 - val_loss: 41.3628 - val_mae: 5.1513\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 36.0890 - mae: 4.4319 - val_loss: 36.4567 - val_mae: 3.9491\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 32.2432 - mae: 4.1953 - val_loss: 33.9200 - val_mae: 3.8504\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 31.7393 - mae: 3.9612 - val_loss: 39.2029 - val_mae: 4.1541\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 26.4048 - mae: 3.6802 - val_loss: 36.1370 - val_mae: 4.4751\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 28.5520 - mae: 3.9327 - val_loss: 32.5880 - val_mae: 3.9846\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 32.6896 - mae: 4.0741 - val_loss: 38.3858 - val_mae: 3.9708\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 28.3007 - mae: 3.8126 - val_loss: 33.2571 - val_mae: 4.4331\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 27.3035 - mae: 3.7772 - val_loss: 37.0302 - val_mae: 5.0205\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 32.3024 - mae: 4.2314 - val_loss: 37.4229 - val_mae: 4.5223\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 26.8908 - mae: 3.7884 - val_loss: 30.3843 - val_mae: 3.8672\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 32.0077 - mae: 4.0140 - val_loss: 30.3945 - val_mae: 3.7202\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 32.7224 - mae: 4.1096 - val_loss: 34.2155 - val_mae: 4.3267\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 42.0627 - mae: 4.9283 - val_loss: 31.0089 - val_mae: 3.6965\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 24.8856 - mae: 3.5804 - val_loss: 45.6378 - val_mae: 4.6178\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 34.3119 - mae: 4.4549 - val_loss: 34.9201 - val_mae: 4.1468\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 29.7427 - mae: 4.0289 - val_loss: 45.7172 - val_mae: 5.4909\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 27.9844 - mae: 3.9274 - val_loss: 37.4491 - val_mae: 4.1526\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 28.2451 - mae: 3.8206 - val_loss: 40.3327 - val_mae: 4.2149\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 30.0730 - mae: 3.9352 - val_loss: 31.1785 - val_mae: 3.6551\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 24.8529 - mae: 3.5156 - val_loss: 38.2878 - val_mae: 5.1738\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 27.0396 - mae: 3.8315 - val_loss: 28.8348 - val_mae: 3.6750\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 26.0087 - mae: 3.6693 - val_loss: 30.5614 - val_mae: 3.6699\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 23.4418 - mae: 3.4235 - val_loss: 32.6615 - val_mae: 3.9111\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 25.2979 - mae: 3.6747 - val_loss: 26.9969 - val_mae: 3.9561\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 28.2188 - mae: 3.8382 - val_loss: 45.0004 - val_mae: 4.4846\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 24.6579 - mae: 3.6280 - val_loss: 32.5042 - val_mae: 3.9324\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 25.6344 - mae: 3.6700 - val_loss: 36.8357 - val_mae: 4.9092\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 27.4963 - mae: 3.7588 - val_loss: 33.5302 - val_mae: 4.0831\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 23.7879 - mae: 3.5148 - val_loss: 27.8320 - val_mae: 3.5952\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 22.4617 - mae: 3.3966 - val_loss: 29.8375 - val_mae: 3.7666\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 20.7511 - mae: 3.2702 - val_loss: 29.1834 - val_mae: 4.0757\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 23.8007 - mae: 3.5286 - val_loss: 28.0010 - val_mae: 3.9194\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 26.7326 - mae: 3.8151 - val_loss: 32.0905 - val_mae: 4.4416\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 24.1805 - mae: 3.6366 - val_loss: 52.8180 - val_mae: 5.6493\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 31.2975 - mae: 4.0962 - val_loss: 40.0170 - val_mae: 4.7764\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 27.1118 - mae: 3.8586 - val_loss: 28.6148 - val_mae: 4.1663\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 20.2425 - mae: 3.2769 - val_loss: 34.6891 - val_mae: 4.0495\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 24.0387 - mae: 3.6551 - val_loss: 28.3721 - val_mae: 3.6317\n",
            "Epoch 72/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 20.3716 - mae: 3.2988 - val_loss: 26.5603 - val_mae: 4.0500\n",
            "Epoch 73/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 20.3566 - mae: 3.2646 - val_loss: 37.2964 - val_mae: 4.2643\n",
            "Epoch 74/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 23.0207 - mae: 3.5148 - val_loss: 29.9158 - val_mae: 4.1789\n",
            "Epoch 75/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 22.9280 - mae: 3.5201 - val_loss: 29.3084 - val_mae: 3.5684\n",
            "Epoch 76/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 28.4295 - mae: 4.0533 - val_loss: 30.7430 - val_mae: 3.8621\n",
            "Epoch 77/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 25.8320 - mae: 3.7285 - val_loss: 27.8868 - val_mae: 3.6191\n",
            "Epoch 78/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 28.6861 - mae: 3.8711 - val_loss: 27.9435 - val_mae: 3.9582\n",
            "Epoch 79/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 25.2112 - mae: 3.7048 - val_loss: 28.3166 - val_mae: 4.3955\n",
            "Epoch 80/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 21.3882 - mae: 3.3716 - val_loss: 23.8244 - val_mae: 3.4101\n",
            "Epoch 81/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 21.2761 - mae: 3.3443 - val_loss: 31.4077 - val_mae: 4.6940\n",
            "Epoch 82/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 22.8174 - mae: 3.4513 - val_loss: 34.7082 - val_mae: 4.0313\n",
            "Epoch 83/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 22.9632 - mae: 3.5101 - val_loss: 25.4028 - val_mae: 3.7806\n",
            "Epoch 84/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 22.2194 - mae: 3.4583 - val_loss: 27.7871 - val_mae: 3.5538\n",
            "Epoch 85/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 19.8942 - mae: 3.3840 - val_loss: 29.9020 - val_mae: 3.8341\n",
            "Epoch 86/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 17.4422 - mae: 3.0738 - val_loss: 30.1517 - val_mae: 3.7138\n",
            "Epoch 87/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 18.8852 - mae: 3.2468 - val_loss: 24.0663 - val_mae: 3.5442\n",
            "Epoch 88/100\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 23.2274 - mae: 3.6722 - val_loss: 41.4923 - val_mae: 5.4416\n",
            "Epoch 89/100\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 22.2012 - mae: 3.6077 - val_loss: 27.3981 - val_mae: 3.5727\n",
            "Epoch 90/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 20.7112 - mae: 3.2492 - val_loss: 25.2345 - val_mae: 3.6285\n",
            "Epoch 91/100\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 19.8600 - mae: 3.2487 - val_loss: 24.1562 - val_mae: 3.4433\n",
            "Epoch 92/100\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 19.0975 - mae: 3.2138 - val_loss: 25.9269 - val_mae: 4.1271\n",
            "Epoch 93/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 20.4238 - mae: 3.3298 - val_loss: 25.2302 - val_mae: 3.5307\n",
            "Epoch 94/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 18.7747 - mae: 3.2191 - val_loss: 23.4653 - val_mae: 3.3492\n",
            "Epoch 95/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 17.8635 - mae: 3.0925 - val_loss: 25.6604 - val_mae: 3.5287\n",
            "Epoch 96/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 16.6834 - mae: 2.9772 - val_loss: 22.2385 - val_mae: 3.2962\n",
            "Epoch 97/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 18.1832 - mae: 3.1307 - val_loss: 34.8810 - val_mae: 4.0779\n",
            "Epoch 98/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 21.3030 - mae: 3.3441 - val_loss: 26.6344 - val_mae: 3.5647\n",
            "Epoch 99/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 17.9981 - mae: 2.9784 - val_loss: 21.6803 - val_mae: 3.4779\n",
            "Epoch 100/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 17.8938 - mae: 3.1748 - val_loss: 20.3267 - val_mae: 3.3421\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 26.7876 - mae: 3.7550\n",
            "Test Loss:26.788\n",
            "Test MAE: 3.75\n",
            "<class 'dict'>\n",
            "loss :[172.04031372070312, 97.94496154785156, 66.86560821533203, 71.87847900390625, 60.732452392578125, 49.3582763671875, 50.994503021240234, 55.813987731933594, 48.196617126464844, 44.8624153137207, 45.1696662902832, 56.79608154296875, 44.75173568725586, 50.85741424560547, 47.976165771484375, 37.04459762573242, 41.649024963378906, 37.74916076660156, 42.435089111328125, 34.55427932739258, 47.1778678894043, 37.097023010253906, 30.5130672454834, 36.738616943359375, 38.03498840332031, 42.140689849853516, 32.279964447021484, 46.47675323486328, 50.09593200683594, 36.09391784667969, 35.91963577270508, 30.975250244140625, 28.782150268554688, 36.0889892578125, 32.24324417114258, 31.739336013793945, 26.404788970947266, 28.551965713500977, 32.68955612182617, 28.300735473632812, 27.303510665893555, 32.30238342285156, 26.890836715698242, 32.0076789855957, 32.722408294677734, 42.06266784667969, 24.88563346862793, 34.311851501464844, 29.742746353149414, 27.984371185302734, 28.245092391967773, 30.07300567626953, 24.85293960571289, 27.03960418701172, 26.008743286132812, 23.44183349609375, 25.297889709472656, 28.21883773803711, 24.657855987548828, 25.634357452392578, 27.496294021606445, 23.787860870361328, 22.461721420288086, 20.751117706298828, 23.800716400146484, 26.732572555541992, 24.180540084838867, 31.297462463378906, 27.11175537109375, 20.242467880249023, 24.03870964050293, 20.371570587158203, 20.35663604736328, 23.020715713500977, 22.92801284790039, 28.429521560668945, 25.8320255279541, 28.68609619140625, 25.211185455322266, 21.38819694519043, 21.276126861572266, 22.817352294921875, 22.963163375854492, 22.219417572021484, 19.894174575805664, 17.442171096801758, 18.885196685791016, 23.2274112701416, 22.201168060302734, 20.71115493774414, 19.859975814819336, 19.097492218017578, 20.42383575439453, 18.77467155456543, 17.86351203918457, 16.683425903320312, 18.183204650878906, 21.30299949645996, 17.99810028076172, 17.893768310546875]\n",
            "loss numb:100\n",
            "val loss :[84.87945556640625, 84.83382415771484, 70.44831085205078, 74.7569351196289, 64.16743469238281, 63.69185256958008, 61.776920318603516, 68.35272979736328, 53.20746994018555, 49.07511520385742, 70.46160888671875, 55.78748321533203, 60.24788284301758, 45.22908401489258, 45.29000473022461, 49.70866012573242, 42.16115188598633, 44.931175231933594, 42.5524787902832, 59.833465576171875, 42.60023880004883, 42.23582458496094, 40.913291931152344, 48.70951461791992, 66.7581558227539, 37.11807632446289, 60.03982925415039, 51.13856506347656, 37.17118453979492, 41.62028121948242, 34.13630676269531, 40.702178955078125, 41.362815856933594, 36.456722259521484, 33.920013427734375, 39.20287322998047, 36.13695526123047, 32.5880126953125, 38.385807037353516, 33.25709533691406, 37.030208587646484, 37.42293167114258, 30.384252548217773, 30.39447784423828, 34.21554183959961, 31.008935928344727, 45.637847900390625, 34.92008590698242, 45.7171745300293, 37.449100494384766, 40.33274841308594, 31.1784610748291, 38.28783416748047, 28.83477020263672, 30.561412811279297, 32.66154098510742, 26.99689483642578, 45.00040817260742, 32.5041618347168, 36.835723876953125, 33.53018569946289, 27.83197021484375, 29.837474822998047, 29.183427810668945, 28.0009708404541, 32.090538024902344, 52.817962646484375, 40.017032623291016, 28.614830017089844, 34.689125061035156, 28.372116088867188, 26.5603084564209, 37.29638671875, 29.91582489013672, 29.30843162536621, 30.743045806884766, 27.886796951293945, 27.943540573120117, 28.316635131835938, 23.824373245239258, 31.407718658447266, 34.708168029785156, 25.402814865112305, 27.787063598632812, 29.902015686035156, 30.151689529418945, 24.06632423400879, 41.492252349853516, 27.398141860961914, 25.234466552734375, 24.156160354614258, 25.926898956298828, 25.23017120361328, 23.465312957763672, 25.660396575927734, 22.238529205322266, 34.88100814819336, 26.634428024291992, 21.68025779724121, 20.32665252685547]\n",
            "val_loss numb:100\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step\n",
            "予測された住宅価格: 12.17, 実際の住宅価格: 7.2\n",
            "予測された住宅価格: 20.81, 実際の住宅価格: 18.8\n",
            "予測された住宅価格: 22.49, 実際の住宅価格: 19.0\n",
            "予測された住宅価格: 31.26, 実際の住宅価格: 27.0\n",
            "予測された住宅価格: 23.35, 実際の住宅価格: 22.2\n",
            "予測された住宅価格: 21.53, 実際の住宅価格: 24.5\n",
            "予測された住宅価格: 29.23, 実際の住宅価格: 31.2\n",
            "予測された住宅価格: 23.35, 実際の住宅価格: 22.9\n",
            "予測された住宅価格: 19.46, 実際の住宅価格: 20.5\n",
            "予測された住宅価格: 19.32, 実際の住宅価格: 23.2\n",
            "予測された住宅価格: 15.38, 実際の住宅価格: 18.6\n",
            "予測された住宅価格: 19.55, 実際の住宅価格: 14.5\n",
            "予測された住宅価格: 18.70, 実際の住宅価格: 17.8\n",
            "予測された住宅価格: 35.76, 実際の住宅価格: 50.0\n",
            "予測された住宅価格: 19.20, 実際の住宅価格: 20.8\n",
            "予測された住宅価格: 21.62, 実際の住宅価格: 24.3\n",
            "予測された住宅価格: 25.04, 実際の住宅価格: 24.2\n",
            "予測された住宅価格: 21.27, 実際の住宅価格: 19.8\n",
            "予測された住宅価格: 17.57, 実際の住宅価格: 19.1\n",
            "予測された住宅価格: 26.39, 実際の住宅価格: 22.7\n",
            "予測された住宅価格: 11.73, 実際の住宅価格: 12.0\n",
            "予測された住宅価格: 12.77, 実際の住宅価格: 10.2\n",
            "予測された住宅価格: 20.23, 実際の住宅価格: 20.0\n",
            "予測された住宅価格: 16.36, 実際の住宅価格: 18.5\n",
            "予測された住宅価格: 24.19, 実際の住宅価格: 20.9\n",
            "予測された住宅価格: 23.20, 実際の住宅価格: 23.0\n",
            "予測された住宅価格: 28.03, 実際の住宅価格: 27.5\n",
            "予測された住宅価格: 39.49, 実際の住宅価格: 30.1\n",
            "予測された住宅価格: 14.27, 実際の住宅価格: 9.5\n",
            "予測された住宅価格: 23.95, 実際の住宅価格: 22.0\n",
            "予測された住宅価格: 22.05, 実際の住宅価格: 21.2\n",
            "予測された住宅価格: 15.82, 実際の住宅価格: 14.1\n",
            "予測された住宅価格: 33.58, 実際の住宅価格: 33.1\n",
            "予測された住宅価格: 23.61, 実際の住宅価格: 23.4\n",
            "予測された住宅価格: 15.99, 実際の住宅価格: 20.1\n",
            "予測された住宅価格: 5.74, 実際の住宅価格: 7.4\n",
            "予測された住宅価格: 16.65, 実際の住宅価格: 15.4\n",
            "予測された住宅価格: 13.13, 実際の住宅価格: 23.8\n",
            "予測された住宅価格: 17.27, 実際の住宅価格: 20.1\n",
            "予測された住宅価格: 27.95, 実際の住宅価格: 24.5\n",
            "予測された住宅価格: 26.62, 実際の住宅価格: 33.0\n",
            "予測された住宅価格: 22.37, 実際の住宅価格: 28.4\n",
            "予測された住宅価格: 16.77, 実際の住宅価格: 14.1\n",
            "予測された住宅価格: 31.79, 実際の住宅価格: 46.7\n",
            "予測された住宅価格: 39.58, 実際の住宅価格: 32.5\n",
            "予測された住宅価格: 24.88, 実際の住宅価格: 29.6\n",
            "予測された住宅価格: 29.87, 実際の住宅価格: 28.4\n",
            "予測された住宅価格: 18.64, 実際の住宅価格: 19.8\n",
            "予測された住宅価格: 26.18, 実際の住宅価格: 20.2\n",
            "予測された住宅価格: 21.27, 実際の住宅価格: 25.0\n",
            "予測された住宅価格: 37.91, 実際の住宅価格: 35.4\n",
            "予測された住宅価格: 17.58, 実際の住宅価格: 20.3\n",
            "予測された住宅価格: 11.46, 実際の住宅価格: 9.7\n",
            "予測された住宅価格: 17.44, 実際の住宅価格: 14.5\n",
            "予測された住宅価格: 31.42, 実際の住宅価格: 34.9\n",
            "予測された住宅価格: 25.26, 実際の住宅価格: 26.6\n",
            "予測された住宅価格: 15.26, 実際の住宅価格: 7.2\n",
            "予測された住宅価格: 33.26, 実際の住宅価格: 50.0\n",
            "予測された住宅価格: 35.70, 実際の住宅価格: 32.4\n",
            "予測された住宅価格: 23.64, 実際の住宅価格: 21.6\n",
            "予測された住宅価格: 22.45, 実際の住宅価格: 29.8\n",
            "予測された住宅価格: 17.74, 実際の住宅価格: 13.1\n",
            "予測された住宅価格: 16.97, 実際の住宅価格: 27.5\n",
            "予測された住宅価格: 21.48, 実際の住宅価格: 21.2\n",
            "予測された住宅価格: 24.04, 実際の住宅価格: 23.1\n",
            "予測された住宅価格: 25.09, 実際の住宅価格: 21.9\n",
            "予測された住宅価格: 18.15, 実際の住宅価格: 13.0\n",
            "予測された住宅価格: 26.33, 実際の住宅価格: 23.2\n",
            "予測された住宅価格: 10.25, 実際の住宅価格: 8.1\n",
            "予測された住宅価格: 10.04, 実際の住宅価格: 5.6\n",
            "予測された住宅価格: 25.33, 実際の住宅価格: 21.7\n",
            "予測された住宅価格: 28.86, 実際の住宅価格: 29.6\n",
            "予測された住宅価格: 22.13, 実際の住宅価格: 19.6\n",
            "予測された住宅価格: 14.05, 実際の住宅価格: 7.0\n",
            "予測された住宅価格: 25.04, 実際の住宅価格: 26.4\n",
            "予測された住宅価格: 21.42, 実際の住宅価格: 18.9\n",
            "予測された住宅価格: 22.53, 実際の住宅価格: 20.9\n",
            "予測された住宅価格: 20.67, 実際の住宅価格: 28.1\n",
            "予測された住宅価格: 33.26, 実際の住宅価格: 35.4\n",
            "予測された住宅価格: 7.63, 実際の住宅価格: 10.2\n",
            "予測された住宅価格: 22.28, 実際の住宅価格: 24.3\n",
            "予測された住宅価格: 36.74, 実際の住宅価格: 43.1\n",
            "予測された住宅価格: 18.89, 実際の住宅価格: 17.6\n",
            "予測された住宅価格: 15.85, 実際の住宅価格: 15.4\n",
            "予測された住宅価格: 21.36, 実際の住宅価格: 16.2\n",
            "予測された住宅価格: 18.32, 実際の住宅価格: 27.1\n",
            "予測された住宅価格: 19.33, 実際の住宅価格: 21.4\n",
            "予測された住宅価格: 20.55, 実際の住宅価格: 21.5\n",
            "予測された住宅価格: 20.05, 実際の住宅価格: 22.4\n",
            "予測された住宅価格: 29.39, 実際の住宅価格: 25.0\n",
            "予測された住宅価格: 18.61, 実際の住宅価格: 16.6\n",
            "予測された住宅価格: 23.73, 実際の住宅価格: 18.6\n",
            "予測された住宅価格: 22.21, 実際の住宅価格: 22.0\n",
            "予測された住宅価格: 30.43, 実際の住宅価格: 42.8\n",
            "予測された住宅価格: 33.93, 実際の住宅価格: 35.1\n",
            "予測された住宅価格: 20.79, 実際の住宅価格: 21.5\n",
            "予測された住宅価格: 36.48, 実際の住宅価格: 36.0\n",
            "予測された住宅価格: 40.44, 実際の住宅価格: 21.9\n",
            "予測された住宅価格: 29.28, 実際の住宅価格: 24.1\n",
            "予測された住宅価格: 43.58, 実際の住宅価格: 50.0\n",
            "予測された住宅価格: 29.88, 実際の住宅価格: 26.7\n",
            "予測された住宅価格: 17.67, 実際の住宅価格: 25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 過学習の防止の実装"
      ],
      "metadata": {
        "id": "xcPeVZbi-0D9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## code"
      ],
      "metadata": {
        "id": "EROxWf8rY6mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import sys\n",
        "\n",
        "\n",
        "# データの読み込み\n",
        "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()\n",
        "## データの確認\n",
        "# print(\"train data\")\n",
        "# print(f\"data shape{train_data.shape}\")\n",
        "# print(f\"data type:{type(train_data)}\")\n",
        "# print(f\"data ex:{train_data}\")\n",
        "# print(f\"Number of test data:{len(test_data)}\")\n",
        "# print(test_data.shape)\n",
        "# print(f\"Number of train data:{len(train_data)}\")\n",
        "# print(train_data.shape)\n",
        "\n",
        "num_rows,num_cols=train_data.shape\n",
        "print(f\"行数:{num_rows},列数:{num_cols}\")\n",
        "print(train_data.shape[1])\n",
        "# モデルの定義\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "#input_shape:データ列数のタプル※単一次元なので(,)つき\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1))  # 出力層\n",
        "\n",
        "# モデルのコンパイル\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# 過学習の防止 Early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "## EarlyStoppingコールバックを作成\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# モデルの学習\n",
        "history=model.fit(train_data, train_labels, epochs=100, batch_size=8, validation_split=0.2, callbacks=[early_stopping_callback])\n",
        "\n",
        "# モデルの評価\n",
        "test_loss, test_mae = model.evaluate(test_data, test_labels)\n",
        "# test_loss, test_mae = model.evaluate(test_data, test_labels,verbose=1)\n",
        "print(f\"Test Loss:{test_loss:.3f}\")\n",
        "print(f\"Test MAE: {test_mae:.2f}\")\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# トレーニングと検証の損失をプロット\n",
        "print(type(history.history))\n",
        "print(f\"loss :{history.history['loss']}\")\n",
        "print(f\"loss numb:{len(history.history['loss'])}\")\n",
        "print(f\"val loss :{history.history['val_loss']}\")\n",
        "print(f\"val_loss numb:{len(history.history['val_loss'])}\")\n",
        "# モデルの学習曲線をプロット\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training vs. Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "# テストデータセット上で予測を行う\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "# 予測結果を出力する\n",
        "for i, prediction in enumerate(predictions):\n",
        "    print(f\"予測された住宅価格: {prediction[0]:.2f}, 実際の住宅価格: {test_labels[i]}\")\n",
        "'''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f38d9fdc-f7cc-4f62-98d7-c748b337d873",
        "id": "aGqfkAya-8q0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "行数:404,列数:13\n",
            "13\n",
            "Epoch 1/100\n",
            "41/41 [==============================] - 1s 11ms/step - loss: 445.1086 - mae: 14.1150 - val_loss: 71.3842 - val_mae: 5.9245\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 70.6680 - mae: 6.1514 - val_loss: 83.3248 - val_mae: 6.0561\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 66.1151 - mae: 5.9732 - val_loss: 67.1715 - val_mae: 5.7973\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 69.1602 - mae: 6.1107 - val_loss: 100.1116 - val_mae: 6.6822\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 63.5741 - mae: 5.6045 - val_loss: 65.4690 - val_mae: 5.3197\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 57.9140 - mae: 5.3223 - val_loss: 62.6856 - val_mae: 5.3927\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 58.0403 - mae: 5.3729 - val_loss: 67.9184 - val_mae: 6.2043\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 53.6850 - mae: 5.1408 - val_loss: 81.3179 - val_mae: 6.0564\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 51.6354 - mae: 5.0702 - val_loss: 60.4879 - val_mae: 5.0801\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 50.0185 - mae: 5.1125 - val_loss: 68.4051 - val_mae: 5.3576\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 48.9831 - mae: 4.7651 - val_loss: 87.8573 - val_mae: 8.2071\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 48.6263 - mae: 4.9853 - val_loss: 81.8905 - val_mae: 6.0293\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 51.0259 - mae: 5.0011 - val_loss: 59.2551 - val_mae: 4.9163\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 45.6946 - mae: 4.7983 - val_loss: 49.7799 - val_mae: 4.9678\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 44.6483 - mae: 4.7684 - val_loss: 56.5230 - val_mae: 4.8212\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 41.8622 - mae: 4.5611 - val_loss: 52.2782 - val_mae: 4.9280\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 44.7549 - mae: 4.7453 - val_loss: 47.4861 - val_mae: 5.0532\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 43.4611 - mae: 4.9989 - val_loss: 58.1903 - val_mae: 6.3310\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 46.2546 - mae: 5.1098 - val_loss: 75.6105 - val_mae: 6.1498\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 54.9132 - mae: 5.4257 - val_loss: 83.7369 - val_mae: 8.1652\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 51.9461 - mae: 5.3481 - val_loss: 45.7756 - val_mae: 5.4468\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 40.7086 - mae: 4.7454 - val_loss: 42.5381 - val_mae: 4.5349\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 41.1668 - mae: 4.6881 - val_loss: 41.0232 - val_mae: 4.5990\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 39.0686 - mae: 4.4725 - val_loss: 57.3374 - val_mae: 5.0713\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 42.4434 - mae: 4.7175 - val_loss: 42.4168 - val_mae: 5.0194\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 39.7744 - mae: 4.6956 - val_loss: 43.5661 - val_mae: 5.3887\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 36.9759 - mae: 4.4265 - val_loss: 41.1248 - val_mae: 5.0640\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 38.5576 - mae: 4.6394 - val_loss: 39.2965 - val_mae: 4.4103\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 33.8652 - mae: 4.1935 - val_loss: 51.2870 - val_mae: 4.7643\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 34.0871 - mae: 4.4137 - val_loss: 37.4668 - val_mae: 4.4310\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 49.6278 - mae: 5.1582 - val_loss: 46.7161 - val_mae: 4.5061\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 49.0629 - mae: 5.3974 - val_loss: 51.2519 - val_mae: 6.0151\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 40.0948 - mae: 4.7247 - val_loss: 38.5508 - val_mae: 4.2829\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 33.6794 - mae: 4.3023 - val_loss: 37.6562 - val_mae: 4.6858\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 35.2516 - mae: 4.5633 - val_loss: 41.0478 - val_mae: 5.2276\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 33.2102 - mae: 4.2588 - val_loss: 39.3369 - val_mae: 4.8519\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 35.5918 - mae: 4.4378 - val_loss: 44.2890 - val_mae: 4.5707\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 31.2084 - mae: 4.0271 - val_loss: 36.8904 - val_mae: 4.6240\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 30.5149 - mae: 4.0510 - val_loss: 45.8183 - val_mae: 4.6638\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 28.6571 - mae: 3.8699 - val_loss: 37.2871 - val_mae: 4.5931\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 30.7798 - mae: 4.0852 - val_loss: 37.6402 - val_mae: 4.4954\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 36.0190 - mae: 4.3959 - val_loss: 36.7065 - val_mae: 4.3347\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 26.5766 - mae: 3.7170 - val_loss: 45.4113 - val_mae: 5.5644\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 30.8731 - mae: 4.1846 - val_loss: 47.1551 - val_mae: 4.7332\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 35.5831 - mae: 4.5188 - val_loss: 36.5861 - val_mae: 4.3034\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 29.9595 - mae: 4.0654 - val_loss: 34.4132 - val_mae: 4.2484\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 29.4566 - mae: 3.9945 - val_loss: 39.8590 - val_mae: 5.0927\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 29.7607 - mae: 4.0909 - val_loss: 37.2934 - val_mae: 4.5066\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 32.1701 - mae: 4.2124 - val_loss: 36.0274 - val_mae: 4.2925\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 30.9795 - mae: 4.1746 - val_loss: 35.4891 - val_mae: 4.5682\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 30.6089 - mae: 4.2376 - val_loss: 41.2910 - val_mae: 4.3498\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 31.2032 - mae: 4.1244 - val_loss: 38.8007 - val_mae: 5.0109\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 30.3462 - mae: 4.0274 - val_loss: 35.5876 - val_mae: 4.6687\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 27.6094 - mae: 3.8074 - val_loss: 53.2737 - val_mae: 6.3285\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 32.2736 - mae: 4.3258 - val_loss: 32.6251 - val_mae: 4.1986\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 25.9096 - mae: 3.8020 - val_loss: 39.0962 - val_mae: 4.2248\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 28.0699 - mae: 3.8059 - val_loss: 33.2079 - val_mae: 4.3991\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 28.7890 - mae: 3.8756 - val_loss: 36.4239 - val_mae: 4.6857\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 28.9007 - mae: 4.1637 - val_loss: 48.8841 - val_mae: 4.7297\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 33.7322 - mae: 4.4494 - val_loss: 58.0355 - val_mae: 5.6071\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 25.9943 - mae: 3.7760 - val_loss: 33.8189 - val_mae: 3.9951\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 28.6571 - mae: 4.0012 - val_loss: 33.8599 - val_mae: 4.4361\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 28.1757 - mae: 3.8119 - val_loss: 61.6139 - val_mae: 6.9126\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 36.0902 - mae: 4.6216 - val_loss: 53.2141 - val_mae: 5.3775\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 27.2395 - mae: 3.9713 - val_loss: 36.3162 - val_mae: 4.0142\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 32.0943 - mae: 3.9584\n",
            "Test Loss:32.094\n",
            "Test MAE: 3.96\n",
            "<class 'dict'>\n",
            "loss :[445.1086120605469, 70.66800689697266, 66.11506652832031, 69.16024017333984, 63.57405090332031, 57.91401290893555, 58.040313720703125, 53.68497085571289, 51.63535690307617, 50.01848602294922, 48.983123779296875, 48.62629318237305, 51.02589797973633, 45.69464874267578, 44.648345947265625, 41.862247467041016, 44.754920959472656, 43.46114730834961, 46.25459289550781, 54.91321563720703, 51.94614028930664, 40.708587646484375, 41.166847229003906, 39.06864547729492, 42.443397521972656, 39.77444839477539, 36.97589111328125, 38.557640075683594, 33.8652458190918, 34.087100982666016, 49.62776565551758, 49.062870025634766, 40.09479522705078, 33.679443359375, 35.25161361694336, 33.21024703979492, 35.5917854309082, 31.208406448364258, 30.514917373657227, 28.65711212158203, 30.779783248901367, 36.018978118896484, 26.57659149169922, 30.873104095458984, 35.5831413269043, 29.95952606201172, 29.456602096557617, 29.760738372802734, 32.17006301879883, 30.979537963867188, 30.608919143676758, 31.203248977661133, 30.346220016479492, 27.609390258789062, 32.27356719970703, 25.909635543823242, 28.069931030273438, 28.78902244567871, 28.900693893432617, 33.73215103149414, 25.994279861450195, 28.657054901123047, 28.175689697265625, 36.09016799926758, 27.23948097229004]\n",
            "loss numb:65\n",
            "val loss :[71.38420867919922, 83.3248291015625, 67.17151641845703, 100.11155700683594, 65.46896362304688, 62.68558120727539, 67.91844940185547, 81.31790924072266, 60.48786544799805, 68.4050521850586, 87.8572769165039, 81.8905258178711, 59.25507736206055, 49.77985763549805, 56.523014068603516, 52.278167724609375, 47.48605728149414, 58.19031524658203, 75.61051177978516, 83.7369155883789, 45.77562713623047, 42.53805160522461, 41.02322006225586, 57.33742141723633, 42.416812896728516, 43.56609344482422, 41.1247673034668, 39.29646682739258, 51.28701400756836, 37.466819763183594, 46.71607208251953, 51.25193405151367, 38.55076217651367, 37.65616226196289, 41.04778289794922, 39.33690643310547, 44.2889518737793, 36.89037322998047, 45.81830596923828, 37.28705596923828, 37.64018630981445, 36.70650100708008, 45.41131591796875, 47.155052185058594, 36.586124420166016, 34.41323471069336, 39.859039306640625, 37.293434143066406, 36.02744674682617, 35.48908615112305, 41.291015625, 38.800689697265625, 35.58757019042969, 53.27367401123047, 32.625091552734375, 39.09622573852539, 33.20792770385742, 36.423919677734375, 48.884071350097656, 58.03548812866211, 33.818912506103516, 33.85989761352539, 61.613895416259766, 53.21413803100586, 36.31622314453125]\n",
            "val_loss numb:65\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAIjCAYAAAAJLyrXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACTY0lEQVR4nOzdd3iT5f7H8XeatOluoUDLKBtkyJIhoAIKMkSUoSKignuAW496HD/Fox7HOe7tEVyIeyEKiIgoU4ayN7SMltmW7iZ5fn/cNFBZHSl5ip/XdeVq+iR5cocWyCff+/7eDsuyLERERERERKTUQoI9ABERERERkapGQUpERERERKSMFKRERERERETKSEFKRERERESkjBSkREREREREykhBSkREREREpIwUpERERERERMpIQUpERERERKSMFKRERERERETKSEFKRKQKGj16NA0bNizXYx955BEcDkdgB/Q38vPPP+NwOPj555/9x0r789i8eTMOh4MJEyYEdEwNGzZk9OjRAT2niIgcm4KUiEgAORyOUl0OfRMuladt27bUr18fy7KOep8zzjiDxMREPB7PCRxZ2c2ZM4dHHnmEjIyMYA/Fb8KECTgcDn7//fdgD0VE5IRzBXsAIiInk/fff7/E9++99x7Tp08/7HjLli0r9DxvvfUWPp+vXI998MEHue+++yr0/FXFyJEjue+++5g9ezY9evQ47PbNmzczd+5cxo4di8tV/v8SK/LzKK05c+bw6KOPMnr0aOLj40vctmbNGkJC9NmoiMiJpCAlIhJAl19+eYnv582bx/Tp0w87/le5ublERkaW+nlCQ0PLNT4Al8tVodBQlVx22WXcf//9TJw48YhB6qOPPsKyLEaOHFmh56nIzyMQ3G53UJ9fROTvSB9fiYicYL169eLUU09l0aJF9OjRg8jISP75z38C8PXXXzNw4EDq1KmD2+2mSZMmPPbYY3i93hLn+OuanOK1N88++yxvvvkmTZo0we1207lzZxYuXFjisUdaI+VwOBg7dixfffUVp556Km63m9atW/PDDz8cNv6ff/6ZTp06ER4eTpMmTXjjjTdKte5q7NixREdHk5ube9htI0aMICkpyf86f//9d/r160eNGjWIiIigUaNGXH311cc8/5EkJyfTo0cPPvvsM4qKig67feLEiTRp0oTTTz+dLVu2cPPNN3PKKacQERFBQkICF198MZs3bz7u8xxpjVRGRgajR48mLi6O+Ph4Ro0adcRpeX/++SejR4+mcePGhIeHk5SUxNVXX82ePXv893nkkUe45557AGjUqJF/imjx2I60Rmrjxo1cfPHFVK9encjISLp27cp3331X4j7F670++eQTHn/8cerVq0d4eDi9e/dm/fr1x33dpbVkyRIGDBhAbGws0dHR9O7dm3nz5pW4T1FREY8++ijNmjUjPDychIQEzjzzTKZPn+6/T1paGldddRX16tXD7XZTu3ZtLrzwwlL9jEREAu3v8ZGkiIjN7NmzhwEDBnDppZdy+eWXk5iYCJg1J9HR0dx5551ER0fz008/8fDDD5OVlcUzzzxz3PNOnDiR/fv3c8MNN+BwOHj66acZOnQoGzduPG7V5Ndff+WLL77g5ptvJiYmhhdffJFhw4aRkpJCQkICYN4Q9+/fn9q1a/Poo4/i9XoZN24cNWvWPO7Yhg8fziuvvMJ3333HxRdf7D+em5vLt99+y+jRo3E6nezcuZO+fftSs2ZN7rvvPuLj49m8eTNffPHFcZ/jSEaOHMn111/P1KlTOf/88/3Hly1bxvLly3n44YcBWLhwIXPmzOHSSy+lXr16bN68mddee41evXqxcuXKMlUMLcviwgsv5Ndff+XGG2+kZcuWfPnll4waNeqw+06fPp2NGzdy1VVXkZSUxIoVK3jzzTdZsWIF8+bNw+FwMHToUNauXctHH33Ec889R40aNQCO+ueenp5O9+7dyc3N5dZbbyUhIYF3332XCy64gM8++4whQ4aUuP+///1vQkJCuPvuu8nMzOTpp59m5MiRzJ8/v9Sv+WhWrFjBWWedRWxsLP/4xz8IDQ3ljTfeoFevXsyaNYvTTz8dMGHxySef5Nprr6VLly5kZWXx+++/s3jxYs4991wAhg0bxooVK7jlllto2LAhO3fuZPr06aSkpJS7+YqISLlZIiJSacaMGWP99Z/anj17WoD1+uuvH3b/3Nzcw47dcMMNVmRkpJWfn+8/NmrUKKtBgwb+7zdt2mQBVkJCgrV3717/8a+//toCrG+//dZ/7P/+7/8OGxNghYWFWevXr/cf++OPPyzAeumll/zHBg0aZEVGRlrbtm3zH1u3bp3lcrkOO+df+Xw+q27dutawYcNKHP/kk08swPrll18sy7KsL7/80gKshQsXHvN8pbV3717L7XZbI0aMKHH8vvvuswBrzZo1lmUd+c9+7ty5FmC99957/mMzZ860AGvmzJn+Y3/9eXz11VcWYD399NP+Yx6PxzrrrLMswBo/frz/+JGe96OPPirxZ2JZlvXMM89YgLVp06bD7t+gQQNr1KhR/u9vv/12C7Bmz57tP7Z//36rUaNGVsOGDS2v11vitbRs2dIqKCjw3/eFF16wAGvZsmWHPdehxo8ff9yf1eDBg62wsDBrw4YN/mPbt2+3YmJirB49eviPtWvXzho4cOBRz7Nv3z4LsJ555pljjklE5ETR1D4RkSBwu91cddVVhx2PiIjwX9+/fz+7d+/mrLPOIjc3l9WrVx/3vMOHD6datWr+78866yzATPM6nj59+tCkSRP/923btiU2Ntb/WK/Xy48//sjgwYOpU6eO/35NmzZlwIABxz2/w+Hg4osvZsqUKWRnZ/uPf/zxx9StW5czzzwTwN9IYfLkyUecjldW1apV47zzzuObb74hJycHMBWjSZMm0alTJ5o3bw6U/LMvKipiz549NG3alPj4eBYvXlym55wyZQoul4ubbrrJf8zpdHLLLbccdt9Dnzc/P5/du3fTtWtXgDI/76HP36VLF/+fKUB0dDTXX389mzdvZuXKlSXuf9VVVxEWFub/viy/N8fi9XqZNm0agwcPpnHjxv7jtWvX5rLLLuPXX38lKysLMD/3FStWsG7duiOeKyIigrCwMH7++Wf27dtXoXGJiASCgpSISBDUrVu3xBvXYitWrGDIkCHExcURGxtLzZo1/Y0qMjMzj3ve+vXrl/i+OFSV5o3nXx9b/Pjix+7cuZO8vDyaNm162P2OdOxIhg8fTl5eHt988w0A2dnZTJkyhYsvvti/xqpnz54MGzaMRx99lBo1anDhhRcyfvx4CgoKSvUcRzJy5EhycnL4+uuvAdMBb/PmzSWaTOTl5fHwww+TnJyM2+2mRo0a1KxZk4yMjFL92R9qy5Yt1K5dm+jo6BLHTznllMPuu3fvXm677TYSExOJiIigZs2aNGrUCCjdz/xoz3+k5yruFrlly5YSxyvye3Msu3btIjc396hj8fl8pKamAjBu3DgyMjJo3rw5bdq04Z577uHPP//039/tdvPUU0/x/fffk5iYSI8ePXj66adJS0ur0BhFRMpLQUpEJAgOrUIUy8jIoGfPnvzxxx+MGzeOb7/9lunTp/PUU08BlKq9ttPpPOJx6xj7KAXisaXVtWtXGjZsyCeffALAt99+S15eHsOHD/ffx+Fw8Nlnn/nbkm/bto2rr76ajh07lqhklcX5559PXFwcEydOBMxaMqfTyaWXXuq/zy233MLjjz/OJZdcwieffMK0adOYPn06CQkJldra/JJLLuGtt97ixhtv5IsvvmDatGn+Jh+V3VK92In42R9Pjx492LBhA++88w6nnnoqb7/9Nqeddhpvv/22/z633347a9eu5cknnyQ8PJyHHnqIli1bsmTJkhM2ThGRYgpSIiI28fPPP7Nnzx4mTJjAbbfdxvnnn0+fPn1KTNULplq1ahEeHn7Ebm5l6fB2ySWX8MMPP5CVlcXHH39Mw4YN/VPZDtW1a1cef/xxfv/9dz788ENWrFjBpEmTyjV2t9vNRRddxLRp00hPT+fTTz/lnHPOISkpyX+fzz77jFGjRvGf//yHiy66iHPPPZczzzyzXBvgNmjQgB07dhwW/NasWVPi+3379jFjxgzuu+8+Hn30UYYMGcK5555bYhpcseN1Rfzr8//1uQD/9NAGDRqU+lwVUbNmTSIjI486lpCQEJKTk/3HqlevzlVXXcVHH31Eamoqbdu25ZFHHinxuCZNmnDXXXcxbdo0li9fTmFhIf/5z38q+6WIiBxGQUpExCaKqwKHVgEKCwt59dVXgzWkEpxOJ3369OGrr75i+/bt/uPr16/n+++/L/V5hg8fTkFBAe+++y4//PADl1xySYnb9+3bd1glpH379gAlpvdt2LCBDRs2lPp5R44cSVFRETfccAO7du06bO8op9N52PO+9NJLh7WeL43zzjsPj8fDa6+95j/m9Xp56aWXDntOOLzy8/zzzx92zqioKIBSBbvzzjuPBQsWMHfuXP+xnJwc3nzzTRo2bEirVq1K+1IqxOl00rdvX77++usSLcrT09OZOHEiZ555JrGxsQAl2r2DWdPVtGlT/888NzeX/Pz8Evdp0qQJMTExFZr2KSJSXmp/LiJiE927d6datWqMGjWKW2+9FYfDwfvvv39Cp1cdzyOPPMK0adM444wzuOmmm/B6vbz88suceuqpLF26tFTnOO2002jatCkPPPAABQUFJab1Abz77ru8+uqrDBkyhCZNmrB//37eeustYmNjOe+88/z36927N0Cp9xDq2bMn9erV4+uvvyYiIoKhQ4eWuP3888/n/fffJy4ujlatWjF37lx+/PFHf+v3shg0aBBnnHEG9913H5s3b6ZVq1Z88cUXh615io2N9a/1KSoqom7dukybNo1NmzYdds6OHTsC8MADD3DppZcSGhrKoEGD/AHrUPfddx8fffQRAwYM4NZbb6V69eq8++67bNq0ic8//5yQkMB+jvrOO+8ccc+x2267jX/9619Mnz6dM888k5tvvhmXy8Ubb7xBQUEBTz/9tP++rVq1olevXnTs2JHq1avz+++/89lnnzF27FgA1q5dS+/evbnkkkto1aoVLpeLL7/8kvT09BJTNEVEThQFKRERm0hISGDy5MncddddPPjgg1SrVo3LL7+c3r17069fv2APDzBv5r///nvuvvtuHnroIZKTkxk3bhyrVq0qVVfBYsOHD+fxxx+nadOmnHbaaSVu69mzJwsWLGDSpEmkp6cTFxdHly5d+PDDD/1NGMojJCSEESNG8MwzzzBo0CBiYmJK3P7CCy/gdDr58MMPyc/P54wzzuDHH38s1599SEgI33zzDbfffjsffPABDoeDCy64gP/85z906NChxH0nTpzILbfcwiuvvIJlWfTt25fvv/++RGdEgM6dO/PYY4/x+uuv88MPP+Dz+di0adMRg1RiYiJz5szh3nvv5aWXXiI/P5+2bdvy7bffMnDgwDK/nuM5tPJ2qNGjR9O6dWtmz57N/fffz5NPPonP5+P000/ngw8+8O8hBXDrrbfyzTffMG3aNAoKCmjQoAH/+te//BsRJycnM2LECGbMmMH777+Py+WiRYsWfPLJJwwbNizgr0lE5Hgclp0+6hQRkSpp8ODBx2xdLSIicrLRGikRESmTvLy8Et+vW7eOKVOm0KtXr+AMSEREJAhUkRIRkTKpXbs2o0ePpnHjxmzZsoXXXnuNgoIClixZQrNmzYI9PBERkRNCa6RERKRM+vfvz0cffURaWhput5tu3brxxBNPKESJiMjfiipSIiIiIiIiZaQ1UiIiIiIiImWkICUiIiIiIlJGWiMF+Hw+tm/fTkxMDA6HI9jDERERERGRILEsi/3791OnTp1jbmCuIAVs376d5OTkYA9DRERERERsIjU1lXr16h31dgUp8O9un5qaSmxsbJBHIyIiIiIiwZKVlUVycrI/IxyNghT4p/PFxsYqSImIiIiIyHGX/KjZhIiIiIiISBkpSImIiIiIiJSRgpSIiIiIiEgZaY2UiIiIiNiOZVl4PB68Xm+whyInGafTicvlqvC2RwpSIiIiImIrhYWF7Nixg9zc3GAPRU5SkZGR1K5dm7CwsHKfQ0FKRERERGzD5/OxadMmnE4nderUISwsrMKVA5FilmVRWFjIrl272LRpE82aNTvmprvHoiAlIiIiIrZRWFiIz+cjOTmZyMjIYA9HTkIRERGEhoayZcsWCgsLCQ8PL9d51GxCRERERGynvFUCkdIIxO+XfkNFRERERETKSEFKRERERESkjBSkRERERERsqmHDhjz//POlvv/PP/+Mw+EgIyOj0sYkhoKUiIiIiEgFORyOY14eeeSRcp134cKFXH/99aW+f/fu3dmxYwdxcXHler7SUmBT1z4RERERkQrbsWOH//rHH3/Mww8/zJo1a/zHoqOj/dcty8Lr9eJyHf+teM2aNcs0jrCwMJKSksr0GCkfVaRERERExNYsyyK30BOUi2VZpRpjUlKS/xIXF4fD4fB/v3r1amJiYvj+++/p2LEjbrebX3/9lQ0bNnDhhReSmJhIdHQ0nTt35scffyxx3r9O7XM4HLz99tsMGTKEyMhImjVrxjfffOO//a+VogkTJhAfH8/UqVNp2bIl0dHR9O/fv0Tw83g83HrrrcTHx5OQkMC9997LqFGjGDx4cLl/Zvv27ePKK6+kWrVqREZGMmDAANatW+e/fcuWLQwaNIhq1aoRFRVF69atmTJliv+xI0eOpGbNmkRERNCsWTPGjx9f7rFUFlWkRERERMTW8oq8tHp4alCee+W4fkSGBeYt83333cezzz5L48aNqVatGqmpqZx33nk8/vjjuN1u3nvvPQYNGsSaNWuoX7/+Uc/z6KOP8vTTT/PMM8/w0ksvMXLkSLZs2UL16tWPeP/c3FyeffZZ3n//fUJCQrj88su5++67+fDDDwF46qmn+PDDDxk/fjwtW7bkhRde4KuvvuLss88u92sdPXo069at45tvviE2NpZ7772X8847j5UrVxIaGsqYMWMoLCzkl19+ISoqipUrV/qrdg899BArV67k+++/p0aNGqxfv568vLxyj6WyKEiJiIiIiJwA48aN49xzz/V/X716ddq1a+f//rHHHuPLL7/km2++YezYsUc9z+jRoxkxYgQATzzxBC+++CILFiygf//+R7x/UVERr7/+Ok2aNAFg7NixjBs3zn/7Sy+9xP3338+QIUMAePnll/3VofIoDlC//fYb3bt3B+DDDz8kOTmZr776iosvvpiUlBSGDRtGmzZtAGjcuLH/8SkpKXTo0IFOnToBpipnRwpSNpKVX8TcDXtwOhz0aZUY7OGIiIiI2EJEqJOV4/oF7bkDpTgYFMvOzuaRRx7hu+++Y8eOHXg8HvLy8khJSTnmedq2beu/HhUVRWxsLDt37jzq/SMjI/0hCqB27dr++2dmZpKenk6XLl38tzudTjp27IjP5yvT6yu2atUqXC4Xp59+uv9YQkICp5xyCqtWrQLg1ltv5aabbmLatGn06dOHYcOG+V/XTTfdxLBhw1i8eDF9+/Zl8ODB/kBmJ1ojZSM7MvK54f1F3Pv5n8EeioiIiIhtOBwOIsNcQbk4HI6AvY6oqKgS39999918+eWXPPHEE8yePZulS5fSpk0bCgsLj3me0NDQw/58jhV6jnT/0q79qizXXnstGzdu5IorrmDZsmV06tSJl156CYABAwawZcsW7rjjDrZv307v3r25++67gzreI1GQshG3y/w4CjzlS/8iIiIiUnX89ttvjB49miFDhtCmTRuSkpLYvHnzCR1DXFwciYmJLFy40H/M6/WyePHicp+zZcuWeDwe5s+f7z+2Z88e1qxZQ6tWrfzHkpOTufHGG/niiy+46667eOutt/y31axZk1GjRvHBBx/w/PPP8+abb5Z7PJVFU/tsJOxAkCpUkBIRERE56TVr1owvvviCQYMG4XA4eOihh8o9na4ibrnlFp588kmaNm1KixYteOmll9i3b1+pqnHLli0jJibG/73D4aBdu3ZceOGFXHfddbzxxhvExMRw3333UbduXS688EIAbr/9dgYMGEDz5s3Zt28fM2fOpGXLlgA8/PDDdOzYkdatW1NQUMDkyZP9t9mJgpSNFFekCr0+fD6LkJDAlZJFRERExF7++9//cvXVV9O9e3dq1KjBvffeS1ZW1gkfx7333ktaWhpXXnklTqeT66+/nn79+uF0Hn99WI8ePUp873Q68Xg8jB8/nttuu43zzz+fwsJCevTowZQpU/zTDL1eL2PGjGHr1q3ExsbSv39/nnvuOcDshXX//fezefNmIiIiOOuss5g0aVLgX3gFOaxgT5C0gaysLOLi4sjMzCQ2NjZo49ifX0SbR6YBsPqx/oQHcHGjiIiISFWQn5/Ppk2baNSoEeHh4cEezt+Sz+ejZcuWXHLJJTz22GPBHk6lONbvWWmzgSpSNuJ2HQxOBR6fgpSIiIiIVLotW7Ywbdo0evbsSUFBAS+//DKbNm3isssuC/bQbE3NJmwk1HlwKp/WSYmIiIjIiRASEsKECRPo3LkzZ5xxBsuWLePHH3+05bokO1FFykYcDgduVwgFHh8FHm+whyMiIiIifwPJycn89ttvwR5GlaOKlM2oc5+IiIiIiP0pSNlM8Top7SUlIiIiImJfClI241ZFSkRERETE9hSkbKY4SKkiJSIiIiJiXwpSNqM1UiIiIiIi9qcgZTMHK1Lq2iciIiIiYlcKUjajipSIiIjI31evXr24/fbb/d83bNiQ559//piPcTgcfPXVVxV+7kCd5+9CQcpm1LVPREREpOoZNGgQ/fv3P+Jts2fPxuFw8Oeff5b5vAsXLuT666+v6PBKeOSRR2jfvv1hx3fs2MGAAQMC+lx/NWHCBOLj4yv1OU4UBSmbUUVKREREpOq55pprmD59Olu3bj3stvHjx9OpUyfatm1b5vPWrFmTyMjIQAzxuJKSknC73SfkuU4GClI2ozVSIiIiIn9hWVCYE5yLZZVqiOeffz41a9ZkwoQJJY5nZ2fz6aefcs0117Bnzx5GjBhB3bp1iYyMpE2bNnz00UfHPO9fp/atW7eOHj16EB4eTqtWrZg+ffphj7n33ntp3rw5kZGRNG7cmIceeoiioiLAVIQeffRR/vjjDxwOBw6Hwz/mv07tW7ZsGeeccw4REREkJCRw/fXXk52d7b999OjRDB48mGeffZbatWuTkJDAmDFj/M9VHikpKVx44YVER0cTGxvLJZdcQnp6uv/2P/74g7PPPpuYmBhiY2Pp2LEjv//+OwBbtmxh0KBBVKtWjaioKFq3bs2UKVPKPZbjcVXamaVcwtT+XERERKSkolx4ok5wnvuf2yEs6rh3c7lcXHnllUyYMIEHHngAh8MBwKefforX62XEiBFkZ2fTsWNH7r33XmJjY/nuu++44ooraNKkCV26dDnuc/h8PoYOHUpiYiLz588nMzOzxHqqYjExMUyYMIE6deqwbNkyrrvuOmJiYvjHP/7B8OHDWb58OT/88AM//vgjAHFxcYedIycnh379+tGtWzcWLlzIzp07ufbaaxk7dmyJsDhz5kxq167NzJkzWb9+PcOHD6d9+/Zcd911x309R3p9xSFq1qxZeDwexowZw/Dhw/n5558BGDlyJB06dOC1117D6XSydOlSQkNDARgzZgyFhYX88ssvREVFsXLlSqKjo8s8jtJSkLIZ7SMlIiIiUjVdffXVPPPMM8yaNYtevXoBZlrfsGHDiIuLIy4ujrvvvtt//1tuuYWpU6fyySeflCpI/fjjj6xevZqpU6dSp44Jlk888cRh65oefPBB//WGDRty9913M2nSJP7xj38QERFBdHQ0LpeLpKSkoz7XxIkTyc/P57333iMqygTJl19+mUGDBvHUU0+RmJgIQLVq1Xj55ZdxOp20aNGCgQMHMmPGjHIFqRkzZrBs2TI2bdpEcnIyAO+99x6tW7dm4cKFdO7cmZSUFO655x5atGgBQLNmzfyPT0lJYdiwYbRp0waAxo0bl3kMZaEgZTNaIyUiIiLyF6GRpjIUrOcupRYtWtC9e3feeecdevXqxfr165k9ezbjxo0DwOv18sQTT/DJJ5+wbds2CgsLKSgoKPUaqFWrVpGcnOwPUQDdunU77H4ff/wxL774Ihs2bCA7OxuPx0NsbGypX0fxc7Vr184fogDOOOMMfD4fa9as8Qep1q1b43Q6/fepXbs2y5YtK9NzHfqcycnJ/hAF0KpVK+Lj41m1ahWdO3fmzjvv5Nprr+X999+nT58+XHzxxTRp0gSAW2+9lZtuuolp06bRp08fhg0bVq51aaWlNVI2o659IiIiIn/hcJjpdcG4HJiiV1rXXHMNn3/+Ofv372f8+PE0adKEnj17AvDMM8/wwgsvcO+99zJz5kyWLl1Kv379KCwsDNgf1dy5cxk5ciTnnXcekydPZsmSJTzwwAMBfY5DFU+rK+ZwOPD5Ku997COPPMKKFSsYOHAgP/30E61ateLLL78E4Nprr2Xjxo1cccUVLFu2jE6dOvHSSy9V2lgUpGxGFSkRERGRquuSSy4hJCSEiRMn8t5773H11Vf710v99ttvXHjhhVx++eW0a9eOxo0bs3bt2lKfu2XLlqSmprJjxw7/sXnz5pW4z5w5c2jQoAEPPPAAnTp1olmzZmzZsqXEfcLCwvB6j93YrGXLlvzxxx/k5OT4j/3222+EhIRwyimnlHrMZVH8+lJTU/3HVq5cSUZGBq1atfIfa968OXfccQfTpk1j6NChjB8/3n9bcnIyN954I1988QV33XUXb731VqWMFRSkbEdd+0RERESqrujoaIYPH87999/Pjh07GD16tP+2Zs2aMX36dObMmcOqVau44YYbSnSkO54+ffrQvHlzRo0axR9//MHs2bN54IEHStynWbNmpKSkMGnSJDZs2MCLL77or9gUa9iwIZs2bWLp0qXs3r2bgoKCw55r5MiRhIeHM2rUKJYvX87MmTO55ZZbuOKKK/zT+srL6/WydOnSEpdVq1bRp08f2rRpw8iRI1m8eDELFizgyiuvpGfPnnTq1Im8vDzGjh3Lzz//zJYtW/jtt99YuHAhLVu2BOD2229n6tSpbNq0icWLFzNz5kz/bZVBQcpmVJESERERqdquueYa9u3bR79+/UqsZ3rwwQc57bTT6NevH7169SIpKYnBgweX+rwhISF8+eWX5OXl0aVLF6699loef/zxEve54IILuOOOOxg7dizt27dnzpw5PPTQQyXuM2zYMPr378/ZZ59NzZo1j9iCPTIykqlTp7J37146d+7MRRddRO/evXn55ZfL9odxBNnZ2XTo0KHEZdCgQTgcDr7++muqVatGjx496NOnD40bN+bjjz8GwOl0smfPHq688kqaN2/OJZdcwoABA3j00UcBE9DGjBlDy5Yt6d+/P82bN+fVV1+t8HiPxmFZpWyOfxLLysoiLi6OzMzMMi/EC7T//bqJxyav5IJ2dXhxRIegjkVERETkRMvPz2fTpk00atSI8PDwYA9HTlLH+j0rbTZQRcpmVJESEREREbE/BSmb0RopERERERH7U5CymeIgVehVRUpERERExK4UpGzGX5EqUpASEREREbErBSmbKd6QVxUpERER+TtTPzSpTIH4/VKQspkwVaRERETkbyw0NBSA3NzcII9ETmbFv1/Fv2/l4QrUYCQw1GxCRERE/s6cTifx8fHs3LkTMPsZORyOII9KThaWZZGbm8vOnTuJj4/H6XSW+1wKUjaj9uciIiLyd5eUlATgD1MigRYfH+//PSsvBSmbKV4jVaAgJSIiIn9TDoeD2rVrU6tWLYqKioI9HDnJhIaGVqgSVUxBymZUkRIRERExnE5nQN7wilQGNZuwmYNrpBSkRERERETsSkHKZsIO2ZBXbT9FREREROxJQcpmiitSoKqUiIiIiIhdKUjZTNghQUqb8oqIiIiI2JOClM2EOQ+pSGlTXhERERERW1KQshmHw1FinZSIiIiIiNiPbYLUv//9bxwOB7fffrv/WH5+PmPGjCEhIYHo6GiGDRtGenp6icelpKQwcOBAIiMjqVWrFvfccw8ej+cEjz6w/J37irxBHomIiIiIiByJLYLUwoULeeONN2jbtm2J43fccQfffvstn376KbNmzWL79u0MHTrUf7vX62XgwIEUFhYyZ84c3n33XSZMmMDDDz98ol9CQLlVkRIRERERsbWgB6ns7GxGjhzJW2+9RbVq1fzHMzMz+d///sd///tfzjnnHDp27Mj48eOZM2cO8+bNA2DatGmsXLmSDz74gPbt2zNgwAAee+wxXnnlFQoLC4P1kirM7TIbz2mNlIiIiIiIPQU9SI0ZM4aBAwfSp0+fEscXLVpEUVFRieMtWrSgfv36zJ07F4C5c+fSpk0bEhMT/ffp168fWVlZrFix4qjPWVBQQFZWVomLnWiNlIiIiIiIvbmC+eSTJk1i8eLFLFy48LDb0tLSCAsLIz4+vsTxxMRE0tLS/Pc5NEQV315829E8+eSTPProoxUcfeU5uEZKQUpERERExI6CVpFKTU3ltttu48MPPyQ8PPyEPvf9999PZmam/5KamnpCn/94Dlak1GxCRERERMSOghakFi1axM6dOznttNNwuVy4XC5mzZrFiy++iMvlIjExkcLCQjIyMko8Lj09naSkJACSkpIO6+JX/H3xfY7E7XYTGxtb4mInqkiJiIiIiNhb0IJU7969WbZsGUuXLvVfOnXqxMiRI/3XQ0NDmTFjhv8xa9asISUlhW7dugHQrVs3li1bxs6dO/33mT59OrGxsbRq1eqEv6ZA0RopERERERF7C9oaqZiYGE499dQSx6KiokhISPAfv+aaa7jzzjupXr06sbGx3HLLLXTr1o2uXbsC0LdvX1q1asUVV1zB008/TVpaGg8++CBjxozB7Xaf8NcUKOraJyIiIiJib0FtNnE8zz33HCEhIQwbNoyCggL69evHq6++6r/d6XQyefJkbrrpJrp160ZUVBSjRo1i3LhxQRx1xYU5D0ztU0VKRERERMSWHJZlWcEeRLBlZWURFxdHZmamLdZL3TZpCV8v3c6DA1ty7VmNgz0cEREREZG/jdJmg6DvIyWHK65IaY2UiIiIiIg9KUjZkDtUXftEREREROxMQcqGwpym2YQqUiIiIiIi9qQgZUOqSImIiIiI2JuClA0dXCPlDfJIRERERETkSBSkbEgVKRERERERe1OQsiF17RMRERERsTcFKRtyh5pmE6pIiYiIiIjYk4KUDblVkRIRERERsTUFKRvyr5HyqNmEiIiIiIgdKUjZkH+NlEcVKRERERERO1KQsqGDFSkFKRERERERO1KQsqEwp2k2oYqUiIiIiIg9KUjZkCpSIiIiIiL2piBlQ1ojJSIiIiJibwpSNqSufSIiIiIi9qYgZUNu14ENeVWREhERERGxJQUpGwpzaY2UiIiIiIidKUjZkNt1cI2UZVlBHo2IiIiIiPyVgpQNFVekAAq9qkqJiIiIiNiNgpQNuQ8JUpreJyIiIiJiPwpSNlTc/hzUAl1ERERExI4UpGzI4XCo4YSIiIiIiI0pSNmUW5vyioiIiIjYloKUTWlTXhERERER+1KQsqkwVaRERERERGxLQcqm3KFOQGukRERERETsSEHKplSREhERERGxLwUpm9IaKRERERER+1KQsilVpERERERE7EtByqYOVqQUpERERERE7EZByqaKK1IKUiIiIiIi9qMgZVNul7r2iYiIiIjYlYKUTYW5tEZKRERERMSuFKRsyu1S1z4REREREbtSkLIpVaREREREROxLQcqmtEZKRERERMS+FKRsShUpERERERH7UpCyKa2REhERERGxLwUpm1JFSkRERETEvhSkbOpgRUpBSkRERETEbhSkbMqtipSIiIiIiG0pSNmUuvaJiIiIiNiXgpRNaY2UiIiIiIh9KUjZlLr2iYiIiIjYl4KUTakiJSIiIiJiXwpSNqU1UiIiIiIi9qUgZVOqSImIiIiI2JeClE1pHykREREREftSkLKpMAUpERERERHbUpCyKXXtExERERGxLwUpm9IaKRERERER+1KQsqlDu/ZZlhXk0YiIiIiIyKEUpGyquCIFUORVkBIRERERsRMFKZtyHxKktE5KRERERMReFKRsKsx58EejdVIiIiIiIvaiIGVTISEOf5hSC3QREREREXtRkLIxtzr3iYiIiIjYkoKUjWlTXhERERERe1KQsjFVpERERERE7ElBysYOVqTUtU9ERERExE4UpGzs0E15RURERETEPhSkbCxMU/tERERERGxJQcrG3JraJyIiIiJiSwpSNqaufSIiIiIi9qQgZWNuBSkREREREVtSkLIxrZESEREREbEnBSkbU9c+ERERERF7UpCyMVWkRERERETsSUHKxtS1T0RERETEnhSkbEwVKRERERERe1KQsjGtkRIRERERsScFKRtTRUpERERExJ4UpGxMa6REREREROxJQcrG3KpIiYiIiIjYkoKUjR2sSClIiYiIiIjYiYKUjWmNlIiIiIiIPSlI2Zi69omIiIiI2JOClI2pIiUiIiIiYk8KUjamrn0iIiIiIvakIGVjYWo2ISIiIiJiSwpSNla8RkpT+0RERERE7EVBysZUkRIRERERsScFKRvTPlIiIiIiIvakIGVjB7v2qdmEiIiIiIidKEjZmCpSIiIiIiL2pCBlY/6KlNeHZVlBHo2IiIiIiBRTkLKx4q59lgVFXgUpERERERG7UJCyseKpfWCqUiIiIiIiYg9BDVKvvfYabdu2JTY2ltjYWLp168b333/vvz0/P58xY8aQkJBAdHQ0w4YNIz09vcQ5UlJSGDhwIJGRkdSqVYt77rkHj8dzol9KpQhzHvzxFBSp4YSIiIiIiF0ENUjVq1ePf//73yxatIjff/+dc845hwsvvJAVK1YAcMcdd/Dtt9/y6aefMmvWLLZv387QoUP9j/d6vQwcOJDCwkLmzJnDu+++y4QJE3j44YeD9ZICKiTEQajTAagiJSIiIiJiJw7LZl0MqlevzjPPPMNFF11EzZo1mThxIhdddBEAq1evpmXLlsydO5euXbvy/fffc/7557N9+3YSExMBeP3117n33nvZtWsXYWFhpXrOrKws4uLiyMzMJDY2ttJeW3mc+n9TyS7w8PPdvWhYIyrYwxEREREROamVNhvYZo2U1+tl0qRJ5OTk0K1bNxYtWkRRURF9+vTx36dFixbUr1+fuXPnAjB37lzatGnjD1EA/fr1Iysry1/VOpKCggKysrJKXOzq0M59IiIiIiJiD0EPUsuWLSM6Ohq3282NN97Il19+SatWrUhLSyMsLIz4+PgS909MTCQtLQ2AtLS0EiGq+Pbi247mySefJC4uzn9JTk4O7IsKIP9eUkUKUiIiIiIidhH0IHXKKaewdOlS5s+fz0033cSoUaNYuXJlpT7n/fffT2Zmpv+Smppaqc9XEQcrUmo2ISIiIiJiF65gDyAsLIymTZsC0LFjRxYuXMgLL7zA8OHDKSwsJCMjo0RVKj09naSkJACSkpJYsGBBifMVd/Urvs+RuN1u3G53gF9J5VBFSkRERETEfoJekforn89HQUEBHTt2JDQ0lBkzZvhvW7NmDSkpKXTr1g2Abt26sWzZMnbu3Om/z/Tp04mNjaVVq1YnfOyVobgiVaA1UiIiIiIithHUitT999/PgAEDqF+/Pvv372fixIn8/PPPTJ06lbi4OK655hruvPNOqlevTmxsLLfccgvdunWja9euAPTt25dWrVpxxRVX8PTTT5OWlsaDDz7ImDFjqkzF6XjcLiegipSIiIiIiJ0ENUjt3LmTK6+8kh07dhAXF0fbtm2ZOnUq5557LgDPPfccISEhDBs2jIKCAvr168err77qf7zT6WTy5MncdNNNdOvWjaioKEaNGsW4ceOC9ZICrnhTXnXtExERERGxD9vtIxUMdt5HavT4Bfy8ZhfPXNSWizvZt7ugiIiIiMjJoMrtIyVH5tY+UiIiIiIitqMgZXNhWiMlIiIiImI7ClI2p4qUiIiIiIj9KEjZXJj2kRIRERERsR0FKZvzb8jr8QZ5JCIiIiIiUkxByuaKK1KFHlWkRERERETsQkHK5vwb8ipIiYiIiIjYhoKUzblVkRIRERERsR0FKZvTGikREREREftRkLK5MLU/FxERERGxHQUpm3Or/bmIiIiIiO0oSNmcKlIiIiIiIvajIGVz/q59qkiJiIiIiNiGgpTNhTkPTO1TRUpERERExDYUpGzOHVq8Rkpd+0RERERE7EJByuaKK1JaIyUiIiIiYh8KUjbnDtUaKRERERERu1GQsjlVpERERERE7EdByua0RkpERERExH4UpGxOFSkREREREftRkLI5f0XK48OyrCCPRkREREREQEHK9txO02zCssDjU5ASEREREbEDBSmbK65IgalKiYiIiIhI8ClI2VzxGimAQgUpERERERFbUJCyuZAQB6FOBwAFHnXuExERERGxAwWpKsDfuU8VKRERERERW1CQqgLcoabhhNZIiYiIiIjYg4JUFaCKlIiIiIiIvShIVQEH95LSGikRERERETtQkKoCiitSmtonIiIiImIPClJVwMGKlIKUiIiIiIgdKEhVAVojJSIiIiJiLwpSVYDbpa59IiIiIiJ2oiBVBYS5VJESEREREbETBakqwO1S1z4RERERETtRkKoCVJESEREREbEXBakqQGukRERERETsRUGqClBFSkRERETEXhSkqgCtkRIRERERsRcFqSrArYqUiIiIiIitKEhVAQcrUgpSIiIiIiJ2oCBVBbhDTbMJVaREREREROxBQaoKCHOqIiUiIiIiYicKUlWAO1RrpERERERE7ERBqgo4WJFS1z4RERERETtQkKoCiitSmtonIiIiImIP5QpSqampbN261f/9ggULuP3223nzzTcDNjA5KMxpmk0oSImIiIiI2EO5gtRll13GzJkzAUhLS+Pcc89lwYIFPPDAA4wbNy6gAxS1PxcRERERsZtyBanly5fTpUsXAD755BNOPfVU5syZw4cffsiECRMCOT4BwrQhr4iIiIiIrZQrSBUVFeF2uwH48ccfueCCCwBo0aIFO3bsCNzoBDi0IqVmEyIiIiIidlCuINW6dWtef/11Zs+ezfTp0+nfvz8A27dvJyEhIaADFFWkRERERETsplxB6qmnnuKNN96gV69ejBgxgnbt2gHwzTff+Kf8SeC4XWo2ISIiIiJiJ67yPKhXr17s3r2brKwsqlWr5j9+/fXXExkZGbDBiaGKlIiIiIiIvZSrIpWXl0dBQYE/RG3ZsoXnn3+eNWvWUKtWrYAOULRGSkRERETEbsoVpC688ELee+89ADIyMjj99NP5z3/+w+DBg3nttdcCOkA5GKQKPT4sywryaEREREREpFxBavHixZx11lkAfPbZZyQmJrJlyxbee+89XnzxxYAOUA6ukfJZ4PEpSImIiIiIBFu5glRubi4xMTEATJs2jaFDhxISEkLXrl3ZsmVLQAcoB9dIgdZJiYiIiIjYQbmCVNOmTfnqq69ITU1l6tSp9O3bF4CdO3cSGxsb0AFKySClzn0iIiIiIsFXriD18MMPc/fdd9OwYUO6dOlCt27dAFOd6tChQ0AHKOAMceAKcQCqSImIiIiI2EG52p9fdNFFnHnmmezYscO/hxRA7969GTJkSMAGJwe5XSF4Cr3q3CciIiIiYgPlClIASUlJJCUlsXXrVgDq1aunzXgrUZgrhJxCrypSIiIiIiI2UK6pfT6fj3HjxhEXF0eDBg1o0KAB8fHxPPbYY/h8eqNfGYo792mNlIiIiIhI8JWrIvXAAw/wv//9j3//+9+cccYZAPz666888sgj5Ofn8/jjjwd0kHKw4YSClIiIiIhI8JUrSL377ru8/fbbXHDBBf5jbdu2pW7dutx8880KUpXA7Q9SWiMlIiIiIhJs5Zrat3fvXlq0aHHY8RYtWrB3794KD0oOV1yR0hopEREREZHgK1eQateuHS+//PJhx19++WXatm1b4UHJ4dya2iciIiIiYhvlmtr39NNPM3DgQH788Uf/HlJz584lNTWVKVOmBHSAYqgiJSIiIiJiH+WqSPXs2ZO1a9cyZMgQMjIyyMjIYOjQoaxYsYL3338/0GMU1LVPRERERMROyr2PVJ06dQ5rKvHHH3/wv//9jzfffLPCA5OSVJESEREREbGPclWk5MRT1z4REREREftQkKoiVJESEREREbEPBakqQmukRERERETso0xrpIYOHXrM2zMyMioyFjkGtypSIiIiIiK2UaYgFRcXd9zbr7zyygoNSI5Ma6REREREROyjTEFq/PjxlTUOOQ6tkRIRERERsQ+tkaoiDlakFKRERERERIJNQaqKUEVKRERERMQ+FKSqCHXtExERERGxDwWpKiJMU/tERERERGxDQaqKUNc+ERERERH7UJCqIrRGSkRERETEPhSkqgitkRIRERERsQ8FqSpCFSkREREREftQkKoitEZKRERERMQ+FKSqiOIgVehVRUpEREREJNgUpKoIf/vzIgUpEREREZFgU5CqItRsQkRERETEPhSkqgi3mk2IiIiIiNiGglQVoWYTIiIiIiL2EdQg9eSTT9K5c2diYmKoVasWgwcPZs2aNSXuk5+fz5gxY0hISCA6Opphw4aRnp5e4j4pKSkMHDiQyMhIatWqxT333IPH4zmRL6XSFa+R8lngUcMJEREREZGgCmqQmjVrFmPGjGHevHlMnz6doqIi+vbtS05Ojv8+d9xxB99++y2ffvops2bNYvv27QwdOtR/u9frZeDAgRQWFjJnzhzeffddJkyYwMMPPxyMl1RpitdIgdZJiYiIiIgEm8OyLCvYgyi2a9cuatWqxaxZs+jRoweZmZnUrFmTiRMnctFFFwGwevVqWrZsydy5c+natSvff/89559/Ptu3bycxMRGA119/nXvvvZddu3YRFhZ23OfNysoiLi6OzMxMYmNjK/U1lpfXZ9Hkn1MAWPLQuVSLOv7rEhERERGRsiltNrDVGqnMzEwAqlevDsCiRYsoKiqiT58+/vu0aNGC+vXrM3fuXADmzp1LmzZt/CEKoF+/fmRlZbFixYojPk9BQQFZWVklLnbnDHHgCnEAqkiJiIiIiASbbYKUz+fj9ttv54wzzuDUU08FIC0tjbCwMOLj40vcNzExkbS0NP99Dg1RxbcX33YkTz75JHFxcf5LcnJygF9N5QhT5z4REREREVuwTZAaM2YMy5cvZ9KkSZX+XPfffz+ZmZn+S2pqaqU/ZyCoc5+IiIiIiD24gj0AgLFjxzJ58mR++eUX6tWr5z+elJREYWEhGRkZJapS6enpJCUl+e+zYMGCEucr7upXfJ+/crvduN3uAL+KyhfmD1KqSImIiIiIBFNQK1KWZTF27Fi+/PJLfvrpJxo1alTi9o4dOxIaGsqMGTP8x9asWUNKSgrdunUDoFu3bixbtoydO3f67zN9+nRiY2Np1arViXkhJ0hx5z4FKRERERGR4ApqRWrMmDFMnDiRr7/+mpiYGP+apri4OCIiIoiLi+Oaa67hzjvvpHr16sTGxnLLLbfQrVs3unbtCkDfvn1p1aoVV1xxBU8//TRpaWk8+OCDjBkzpkpWnY5Fa6REREREROwhqEHqtddeA6BXr14ljo8fP57Ro0cD8NxzzxESEsKwYcMoKCigX79+vPrqq/77Op1OJk+ezE033US3bt2Iiopi1KhRjBs37kS9jBNGa6REREREROwhqEGqNFtYhYeH88orr/DKK68c9T4NGjRgypQpgRyaLakiJSIiIiJiD7bp2ifH51azCRERERERW1CQqkLCDjSbUEVKRERERCS4FKSqEFWkRERERETsQUGqCjm4RkrNJkREREREgklBqgpRRUpERERExB4UpKoQt7r2iYiIiIjYgoJUFeI+0GxCFSkRERERkeBSkKpC/GukvApSIiIiIiLBpCBVhfjXSBWp2YSIiIiISDApSFUhYU5VpERERERE7EBBqgpxhxZXpBSkRERERESCSUGqCimuSBWoIiUiIiIiElQKUlWIO/RA1z5VpEREREREgkpBqgrRGikREREREXtQkKpCDq6RUtc+EREREZFgUpCqQlSREhERERGxBwWpKkRrpERERERE7EFBqgpRRUpERERExB4UpKoQ/xopj9ZIiYiIiIgEk4JUFeKvSHlUkRIRERERCSYFqSok3F+RUpASEREREQkmBakqJMxpmk2oIiUiIiIiElwKUlWIWxUpERERERFbUJCqQorXSHl9Fh517hMRERERCRoFqSqkuCIFaoEuIiIiIhJMClJVSHFFCrROSkREREQkmBSkqhCXMwRniAPQOikRERERkWBSkKpi3K4DDSeKFKRERERERIJFQaqKCTsQpAq93iCPRERERETk70tBqooprkjlqyIlIiIiIhI0ClJVzMGKlIKUiIiIiEiwKEhVMW6XE9AaKRERERGRYFKQqmKKW6CrIiUiIiIiEjwKUlVM8aa8BUVqNiEiIiIiEiwKUlWMKlIiIiIiIsGnIFXFuEO1RkpEREREJNgUpKoYVaRERERERIJPQaqK0RopEREREZHgU5CqYtyqSImIiIiIBJ2CVBVzsCKlICUiIiIiEiwKUlWM1kiJiIiIiASfglQV4+/a51GQEhEREREJFgWpKsZfkVKQEhEREREJGgWpKsbtOrBGyqOufSIiIiIiwaIgVcWE+YOUKlIiIiIiIsGiIFXFuBWkRERERESCTkGqiglzmWYTWiMlIiIiIhI8ClJVjCpSIiIiIiLBpyBVxRSvkSpUswkRERERkaBRkKpiVJESEREREQk+Bakq5mBFSkFKRERERCRYFKSqGPeBZhOqSImIiIiIBI+CVBWjipSIiIiISPApSFUxB9dIqdmEiIiIiEiwKEhVMW5VpEREREREgk5BqorRGikRERERkeBTkKpitEZKRERERCT4FKSqmOKpfR6fhddnBXk0IiIiIiJ/TwpSVUxxRQpUlRIRERERCRYFqSrGfUiQUuc+EREREZHgUJCqYlzOEEIc5roqUiIiIiIiwaEgVQWpc5+IiIiISHApSFVBYf5NeRWkRERERESCQUGqCnL7g5TWSImIiIiIBIOCVBWkvaRERERERIJLQaoKcmtqn4iIiIhIUClIVUHFzSZUkRIRERERCQ4FqSpIzSZERERERIJLQaoKUrMJEREREZHgUpCqgtRsQkREREQkuBSkqiBtyCsiIiIiElwKUlWQWxUpEREREZGgUpCqgrRGSkREREQkuBSkqiCtkRIRERERCS4FqSpIG/KKiIiIiASXglQVpIqUiIiIiEhwKUhVQeraJyIiIiISXApSVVCYpvaJiIiIiASVglQVpK59IiIiIiLBpSBVBWmNlIiIiIhIcClIVUFaIyUiIiIiElwKUlWQKlIiIiIiIsGlIFUFaY2UiIiIiEhwKUhVQapIiYiIiIgEl4JUFeRW+3MRERERkaBSkKqCVJESEREREQkuBakqSF37RERERESCS0GqCnKrIiUiIiIiElQKUlWQuvaJiIiIiASXglQVpDVSIiIiIiLBFdQg9csvvzBo0CDq1KmDw+Hgq6++KnG7ZVk8/PDD1K5dm4iICPr06cO6detK3Gfv3r2MHDmS2NhY4uPjueaaa8jOzj6Br+LE0xopEREREZHgCmqQysnJoV27drzyyitHvP3pp5/mxRdf5PXXX2f+/PlERUXRr18/8vPz/fcZOXIkK1asYPr06UyePJlffvmF66+//kS9hKAorkh5fBZenxXk0YiIiIiI/P24gvnkAwYMYMCAAUe8zbIsnn/+eR588EEuvPBCAN577z0SExP56quvuPTSS1m1ahU//PADCxcupFOnTgC89NJLnHfeeTz77LPUqVPniOcuKCigoKDA/31WVlaAX1nlKl4jBWZ6X0SYM3AntyyY+zLE1oVThwbuvCIiIiIiJxHbrpHatGkTaWlp9OnTx38sLi6O008/nblz5wIwd+5c4uPj/SEKoE+fPoSEhDB//vyjnvvJJ58kLi7Of0lOTq68F1IJwv4SpAIqZR5MexC+uB7yMgJ7bhERERGRk4Rtg1RaWhoAiYmJJY4nJib6b0tLS6NWrVolbne5XFSvXt1/nyO5//77yczM9F9SU1MDPPrK5QpxEOIw1wPeuW/Fl+arrwjWTQvsuUVEREREThK2DVKVye12ExsbW+JSlTgcDn9VKqANJ3w+WPXNwe9XfRu4c4uIiIiInERsG6SSkpIASE9PL3E8PT3df1tSUhI7d+4scbvH42Hv3r3++5ysKqVzX+p82L8DQg4snVv/IxTlBe78IiIiIiInCdsGqUaNGpGUlMSMGTP8x7Kyspg/fz7dunUDoFu3bmRkZLBo0SL/fX766Sd8Ph+nn376CR/ziVQpe0kVT+trczHE1oOiXNgwM3DnFxERERE5SQS1a192djbr16/3f79p0yaWLl1K9erVqV+/Prfffjv/+te/aNasGY0aNeKhhx6iTp06DB48GICWLVvSv39/rrvuOl5//XWKiooYO3Ysl1566VE79p0s3P6pfQFaI+XzwcqvzfXWQyA8Dua/DqsnQ4vzAvMcIiIiIiIniaAGqd9//52zzz7b//2dd94JwKhRo5gwYQL/+Mc/yMnJ4frrrycjI4MzzzyTH374gfDwcP9jPvzwQ8aOHUvv3r0JCQlh2LBhvPjiiyf8tZxoAa9Ipc6D7DRwx0HjsyE00gSpNVPA6wFnUH9VRERERERsJajvjnv16oVlHX1DWYfDwbhx4xg3btxR71O9enUmTpxYGcOztYCvkVrxlfnaYiC4wqB+N4ioDnl7Yctv0LhnYJ5HREREROQkYNs1UnJsAa1IlZjWN9h8dbrglANT+lZPrvhziIiIiIicRBSkqih3INuf/3VaX7GW55uvq7+DY1QORURERET+bhSkqqjiIFXoDUCzib9O6yvW+GwIjYKsbbB9ccWfR0RERETkJKEgVUX5K1JFFaxIHWlaX7HQcGh2rrm+StP7jiltOWxfGuxRiIiIiMgJoiBVRfnXSHkrGKSONq2vWMtB5uuqbyv2PCeznavhzV7wZk+YeKn5XkREREROagpSVZS/a19FK1JHm9ZXrNm5EBIKe9bBrjUVe66T1bQHwVdkrq/9Hl7rBl+PhaztwR2XiIiIiFQaBakqKswZgIrUsab1FQuPO9j6XFWpw63/EdZPN2Hzsk9NBc/ywZL34cXT4MdHIT8z2KMUERERkQBTkKqi3KHFa6Qq0GzieNP6ihVP71Mb9JK8Hpj6oLl++g3QvC8M/wCumW724fLkwa//hRfawdxXwFMQ3PH+XWTvhMxtwR6FiIiInOQUpKqoOLJ5MfQlumx+o/ytyVd8ab4ebVpfsVPOAxywfQlkpJbvuU5Gi9+FXavMxsU97j54PLkLXPU9XPoR1DgF8vbB1H/Cy53gz09MJVACz7JgyYcmuL7aDfIygj0iEREROYkpSFVFhTlcuv4eLnDO5czt/4Nln5X9HD4vrPzGXD/atL5i0bWgfldzffV3ZX+uk1F+Jsx8wlzvdT9EVCt5u8MBLc6Dm+bAoBchpjZkpMAX15mmFFvmnvgxn8wK9sOXN8DXN0NRLhRkwsaZwR6ViIiInMQUpKoabxF8Moq6+//EaznMsSl3QdaOsp0npZTT+oq1KN6c12bT+wpz4bNrYOoDJ3bT4Nn/gdzdUKM5dLrq6PdzuqDjKLhlMZzzEITFQNqf8P4Q2J924sZ7Mtvxp+ma+OfH4AiBWq3N8XXTgzosERERObkpSFUlPh98dROsn05RSDiXFj5ESngLUx355payBYmVX5mvx5vWV6zlgSC15TfI2VPmoVcKy4JvxsLyz2DuyyeuArFvM8x7zVzv+y9whh7/MWGRZvrfbX9AnQ5m/dSclyp1mCc9y4IFb8HbfWDPeoitC6OnQP8nze3rpmsapYiIiFQaBamqwrLgh/tg2acQ4mJmu2dZaLXg3cT7wOk2neMWv1e6c5VlWl+xag0hqY3pSLf2+/K8gsD79TlY/vnB72eMOzFVqen/B95CU8lr1rdsj41KgLMPNKj4/R3I2R348f0d5GXAJ1fAlLvBWwDNB8CNv0KDbqbRR1g05OyEtD+CPVIRERE5SSlIVRW/PAML3jDXB7/OrqQeAKQ6k6H3w+b41H+aasnxlHVaX7EWxZvz2mB635rvTXACE0zCok0zjFXfVO7zpswz1TxHCPR73KyFKqumvU1VqigX5r0a8CGe9FIXwutnmXb8IaHQ70kY8RFEVje3u8KgcS9zXdP7REREpJIoSFUFC96CmY+b6wOehrYXH9yQ1+ODrjdB/e5QmA1fjTn+dKayTusrVjy9b8NPZnF/sOxcBZ9fC1jQ6RroeQ90G2Nu++lfpi15ZfD54If7zfXTroTE1uU7j8MBPe4x1+e/abr6yfH5fPDbCzC+P2SmmCrpNdOg282HB9riSuG6aSd8mCIiIvL3oCBld8s+gykH3nT3vNfsVwSEuQ5syOvxQYgTBr8CoVGw5deDlasj8XkP2YR3SNnGUqsVVGtkplKt/7GsryQwcvfCR5ea0NjwLBjwlDnebaxpQ757Lfw5qXKee9mnsH2xaRhx9gMVO1fzAaYpQuF+E6bk2HJ2w8RLYPrD4PNA66Fwwy9Q97Qj37/Zuebr1t/ts6ZPRERETioKUna2/kf48kbAgs7XmjbbB7gPBKkCz4ENeas3hr6Pmes/PgK71x35nCnzIDsdwuMOTn8qLYfj4Oa8wZje5y2CT0eZ6Yvx9eHidw82egiPhbPuNNd//jcU5Qf2uQtzYcaj5vpZd5qW8BUREgI97jLX570a3Aqf3RXsh7d7m3WArnAY9AJc9I75HT6a2DqQ2Aawghf6RURE5KSmIGVXqQvh4yvAV2Q+fR/wTInpS/6KlPeQaXydrjZrnjz5JoAdaYpb8bS+U8o4ra9YcZBaNw08hWV/fEVMfQA2/WIqbyMmmcYNh+p8LcTUgcxU08ghkOa+DFnbIK4+dL05MOdsNRgSmkF+Biz8X2DOeTL66XETnmPrwXU/QcfRpVubVlyV0vQ+ERERqQQKUna0cxVMvNg0I2hyDgx5w1QwDuGvSBUdEqQcDrjwZdNEYtvvMOeFkuetyLS+YnU7QXQSFGSZUHOiLJpwcMri0DePvD4pNAJ63Wuuz342cFWerB2mQyDAuY9AaHhgzhvihLMOVKXmvmyqXlLStkUw/3Vz/YIXy7YurXid1Pofze++iIiISAApSNlNRgq8P9Q0IKjbCYZ/cMTKkftIFSmAuHoH1w3NfBLSlh28rSLT+oqFhECL88z11d+W7xxltWUufHe3uX72gwebXhxJ+8uhehPI3QNzA9QR76d/mVBbr4upDgZSm4sgvgHk7ILF7wb23FWd1wPf3gZY0OYS0+2wLOp1hvB4U/Hb+nslDFBERET+zhSk7CR7F7w/BPZvh5otYOSnEBZ1xLv6u/YVHaFDX7tLzdQ9X5GZ4lc8BW/Fl+Zreaf1FSue3rf6u8r/pD8jFT6+3LyWVoPNprbH4nTBOQcaQcx5qeKNBrYvhaUfmuv9nyxfu/NjcYbCmXeY67+9AJ6CwJ6/Kpv3qvkgIKIa9Hui7I93ug6GL03vExERkQBTkLKTtD9NRSouGS7/4uC+OEdQXJHalV3AQ18tZ03aIdPYHA4Y9DxEJkD6cpj1lAk8xXsslXdaX7GGZ5mqVs4uSF1QsXMdS2EOTBoBubvNZsCDXy1dkGk1xNy/cD/8+t/yP79lwbQHMRWRi6Fep/Kf61jaXwaxdWH/joOh7e9u32aYeSA89f0XRNcs33nUBl1EREQqiYKUnTTtDZd/Dld8BXF1j3nXBglRtKkbh9dn8f68LfR7/hcueWMu3/6x3bREj64FAw+EiF//a9bgHGdaX3aBh+kr03ls8kre/GUD2QVH2Y/JGQrN+5vrqyupe59lwVc3mYpEZA249KOjVucOExICvf/PXF/wFmRuK98YVn8Hm2ebTnHF56sMLjeccZu5/utzpjvh35llwXd3gSfPhPb2I8t/ria9AYf5kCJrR8CGKCIiIuKwLMsK9iCCLSsri7i4ODIzM4mNjQ32cErNsizmbtjD+/O2MG1lOl6f+VHWiHYzoksyI7rUp86MW8z+R8XaXQZDXgPA57NYuSOLWWt38cvaXSxO2UeR9+CvQ7XIUG7o2YQruzUgMsxV8slXfgOfXGHW99z2R2CnvPl88PMT8MszEBIKo76FBt3Kdg7LgvHnQcocOG2UaVRQFns2mGmWGVvgrLuh90Nle3xZFeXB821Mle/CV6FDBcJDVbfsM/j8GnC64aY5UKNpxc731jmmacUFL8NpVwRmjCIiInLSKm02UJCi6gapQ6Vl5vPRghQ+WpDCzv1mnU2IAy5oHsFTO2/AnbcTgIwhHzLD055f1u3i13W72ZNTsoV5g4RIujepwfyNe9i4OweAhKgwburVhJGnNyAizKzNojAHnm5sWq3f+KuZSldR3iLzJvrX52D3GnPsgpfgtCvLd76UefBOP3A4YcyC0r0htyz44yPT3KIox0y5GzMf3DHlG0NZ/PaC2XC2ehMYu9B09fu7yd0Lr3QxgfLsB6DnPyp+zp//DT8/CS0vgOHvV/x8IiIiclJTkCqDkyFIFSvy+pi+Mp33525h7kbTaKFXyBImhD1DhiOOznkvUcTB6lJUmJNuTWrQs3kNejSvSYMEM33O4/Xx9dLtvDBjHSl7TVvumjFubu7VhBFd6hMe6oRJI83Uvp73wtn/rMCg82DJB/Dbi5CZYo6548yb6O5jy39egA8vgXVTTbe9i8cf+775mTD5Dlj+ufm+wZkw9A3TCfFEKMiG5081HRuH/c909Pu7+XosLHnfNFu5YXbFmqIU27bIVKXCYuDeTQc3cRYRERE5AgWpMjiZgtSh1qXv54N5W/h88TZaFS5jHzGss+pxat1YejSrSY/mNTmtfjX/5r5HUuT18eXibbwwYx3bMvIASIoNZ8w5Tbk07FdCv7nZdFVrPcSsZ2l4VukbA+RnmY1z574COaZiRlRNs+Ft52vMeq6KSlsGr59prt/wC9Rud+T7pcyHL641zT4cThMMz7zjxFeFZj0DM/8FNVuaaW0hf6NljJt/hQkDzfWrfij7dM6j8fng2WamacmoydDorMCcV0RERE5KClJlcLIGqWI5BR6mrUwjxOHgjKY1qBHtLvM5Cj0+Pl2Uyss/rWdHZj4Ap8T5+Nq6hfDCfSXvXLOlebPa8EwTrP7afTBnj9lkdcEbpgoEplPhGbdBh8vNxrqB9Nk1sPwzaHouXP5Zydt8XvjlWdPZ0PKaNV/D/gfJnQM7htLKyzBrpQqyzB5ixa3mT3aeAnjtDNizDjpeZbpOBtKXN5opm91vhb6PBfbcIiIiclJRkCqDkz1IBVKBx8vHC02g2rm/gBhyOT92PVfX3UrTnCU4dq44/EGJp5pA1aA7pMyFRRPMBrcACc3grDtNe/HKmnK1Z4NZd+PzwOgp0PAMczwjFb643jSkALPp68D/QHiQfwd++pdptFG7HVw/K/B7V9nRzCdh1r8hOtGsZ4uID+z5l38On11tpgyOmR/Yc4uIiMhJRUGqDBSkyi6/yMvE+Sm8+vMGdmeb5haNa0Zx71k1OTdqHSGbfzWtw3etPvIJareDs+6CFuefmOlz394Oi8ZD8ulw9VRY+TV8e6upiIVFm1bx7YZX/jhKI2ePqUoV5cDIz6DZucEeUeXatcZUo3xFcNF4OHVo4J8jbx883cRUHW/7E6o1CPxziIiI/B34vCd9QywFqTJQkCq/3EIP783dwuuzNpCRa/Y/apEUw53nNufcVok4cnaZtS+bZ5suetG1oPstZn+fE1lpydoOL3YwXQYb9YRNs8zxuh1h2NtQvfGJG0tpTHsQ5rwE9brANdNO3qqUz2fWRaXMgWb94LKPK++1vjPAPM/A/0DnayvnOURERE5m898071G63gTnPARO1/EfUwUpSJWBglTF7c8vYvxvm3nrl43sP7CRb9t6cdzV9xR6NKuBww5BYPrDpsU4AA4zpbDX/fbs4rY/HV5oa4Lfld9A457BHlHlWDQBvr0NQiPNlLv4+pX3XLP/CzMeNZtJX/Zx5T2PiIjIychTCM+1MluUADQ4Ay56B2KSgjuuSlDabPA3agkmlSkmPJRbezdj9r1nM+bsJkSGOflzayaj3lnAJW/MZd6BVuxBdcbtpplEbD0Y9Q30ftieIQogJtFsJAww8wmzx9bJZn+6CbcA5zxYuSEKoFlf83XjLCjKr9znEhEROdmsmWJCVHi8WRax5Td4/SzYNDvYIwsaVaRQRaoy7M4u4PWfN/D+vC0UeHwAnNE0gfPa1MaywGdZeH3mYq6XPGZZFo1rRtP/1CSzZ1WgeArAGVY1psplboUXTwNvgZmOeMl7gW/CECyWBZ+OMmvVareDa3+q/OkBlgX/bQX7t8Pln0PTPpX7fCIiIoG0b7NZLtF2eHA+CH5/CGz4yaxxbzcCPrkSdq4ER4j5QPSMO06abVs0ta8MFKQqT3pWPq/MXM9HC1Io8pb9Vy023MWQDnW5tEt9Wtb+G/5s1k6DT0ebxhM1W8Bln1T9Rgk+H0y5y+wh5giB62ZCnfYn5rm/uRUWvwun3wgDnjoxz3kslmWmG+5PNy3fXWXfmkBERP4G1s+AT6+Cgkzo8Q8454ET+/z7NsMLB/bivHUpVG8Ehbnw3Z1mexEwa52HvH74tjdVkIJUGShIVb6t+3J5e/Ymtu7LwxkCzhAHIQ4HzhAHTocDh8NR4rgF/LJ2F1v35fnP0T45nhFdkjm/bR2i3Cfn4sYj2vEnTLwE9u+AqFpw2STTJKO8Ns6CHx+Bgv2m7XyHkRBXL2DDPSaf13RLXPIB4IALXzHPf6KsmgwfjzTNRW5dcuKe92j+mARf3mCun34TDPh3cMcjIiL2Ylmw4E344T6wzAwfIqrBHSsgLOrEjWPGYzD7WWh8Nlz5VcnxLX4PptxjZtDE1YdLJlTsfYoNKEiVgYKUPfl8Fr+u382khSlMW5GOx2d+VaPdLi5oX4cRnevTpl5ckEd5gmRug4nDIX0ZuCJg2Ftl36x3f7rptLPsk7/c4IAm58BpV8Ap51VeVcTrga9vhj8/NpWoIW9A20sC/jQbd2WzdV8eHRtUOzxwF+yHpxqZVuu3LIaEJgF//lLL2g6vdj24KTXApR9Bi/OCNyYREbEPb5EJKIvGm+/bjTD7ce7bDOc9C12uO0Hj8MBzrSE7DS6eAK2HHH6fHX/AJ6Ng3yazhKLfE6ZDblVYSnEEClJloCBlf7v2F/D54q1MWpDC5j25/uOn1o3l0s71GdimNtWiwoI4whOgYL8p66+fDjig77+g25jj/yPl85ppdDMeM1MCcJh/3Op2hKUfmtb0xSKqQ7tLocMVkNgqcGP3FpnNj1d8ASEu03L+SP8QV4BlWbw1eyP//n41PgtcIQ5Oa1CNs5rW4MxmNWhbLx5niAPevcC0v+//b9O+NRgsCz682Pws65wGyV1g/uvmU8Ybfz1xFUIREbGn3L1mDdLm2YADzn0Uut8KC9+GKXdDtYbmA8ETsZ/T6u9g0mUQWQPuXAWuo7zfysuAr8fA6snm+1MvgkEvgDu68scYYApSZaAgVXX4fBbzNu3howWpTF2eRqHX57+tbnwELWvH0qpOLK1qx9CqdhzJ1SPs0Xo9ULwe+P4f8Pv/zPedr4X+Tx29UcP2JTD5DvMVoHZ7OP85qHvawfvs2WAC1dKJZvpgsbodTaA6dRiEV+DvhacQPrvK/MMaEgqXvAstBpb/fEeQU+DhH5/9yXfLzPhrRLv9G0UXiw130b1JDa5zTaHjmmdNFe6KLwM6jlJb/D58MxacbrjhFzPV8H/nwo6lUL8bjJp80u7NISJSZut/hD8/gb6PQ3TNYI+m8u1aa6b079tkuuMNextOGWBuK8wx1aG8faYJVasLK388H14C66aaINf3sWPf17Jg7ssw/f/A8kKNU0yDp/jkyh9nAClIlYGCVNW0N6eQLxZv5ZPfU1mbnn3E+8S4XbSoHUMrf8CKo1lidGA7AZ5olgVzXzHT9LBMW++Lxpf8xCc/E376l/nkyvKBO9a0e+909dE/vfJ6TDeeJe/Bmu/BZ/YDIzQSWg+F02+A2m3LNtaifNOdb+0PJjQM/wCa9y3Xyz6ajbuyueH9RazbmY0rxMH/DWrF5V0bkLI3l9nrdvPrut3M2bCbrHzzeho7tvOT+24KcfGvU79nQIcmdGuSENAxHVNGKrzWHQqy4NxxcMZt5vjejfB6DyjcH5yFxCIidpS9E17uZP5f63C5WVt7Mju0qURcfbMuOrF1yfv89C/45Rmo2wmu/bFyp89lboXn25j3EmMXQY2mpXvclrnmQ9T9O6DhWTDq2yo1zU9BqgwUpKq+zLwiVu/IYuWOLFZuN1/XpWeXqFgdqk5cOI1qRtGoRhQNE6JoXDOKRjWiqVctglBn8Ft3erw+1qTv54/UTKpHhXFuq0QzLe1QK78x0+U8eZDUxnT0i6kNyz+Hqf+E7HRzv1Mvgn6Pl23DvOxd8OckUznZvebg8YZnmY53pww4/nSCojyYNBI2zABXOFw6EZr2Lv0YSmHaijTu+uQP9hd4qBXj5rXLT6Njg8O7BXl9Fn9uzeDXdbuZvW4Xz+4YRX3HTq4tvIsffR15elhbLul8Aj4tsyzTPnbjTKjXBa7+oeSf47LP4PNrAAdc+XXV3ojZsmD+G2Yuf59HIDT8xI9h7yazCLoo98AYIk78GESkYj6/7uDaXkcI3DwPap4S3DFVhuJ/M6feb0JLclfz4eORKnDZO+G5U01zh6unQv2ulTeun/8NPz9p/v8fPblsj927EV7tbt6nDHoBOo6ulCFWBgWpMlCQOjkVeX1s2JVtgtWBcLVyRxYZuUff3NYV4iC5eqQ/YNWrFkGtWDc1o93UjDGXaLcr4NMFd+7PZ0lKxoHLPv7cmklekdd/e6MaUdzUqwlDOtQtGfS2LoKPhpsN8mLqmE+KNv1ibktoahajNjm7/AOzLEhdAAveMHs+FVep4huYQNXh8iNP+yvMgY8uNWMJjYTLPoZGPco/jr/w+iye/3EtL/20HoDODavxysjTqBVTujfrhd/eRdiit/k1bhCXp4/A4YD/XNyOoadV8tqk398xUy1d4XDjb0f+ZO+bW8yb/+hEc5+qOo3ll2fMp6Zgfk8ueDlgn0b6fBb78z1Eup2Hf/Dh85ppQAvfhnXTgQP/xbUabCq3J8keJyJ/CxtmwvuDAYfZc3DHUtNoafgHQR5YgHmLzLqnRRPM9+1Hmmn4x2r+VLydxykDYcTEyhmXzwvPt4WsrTD0bWh7cdnPMfcV8+GuO9aE4Li6gR9nJVCQKgMFqb8Py7LYm1PIpt05/svmPTls3GW+5hcduYJ1qIhQpz9UFQesWjFuYiNCCQ8Nwe1y4naF4A4NIdzlxH3g2KG3bc3I84emJSkZbMvIO+x5Ytwu2tSLY9WOLPYdCH914yO4sVcTLu5Y7+D0xH1bTOOC4sqR0w097jZTxgLZgS9zm3lzumi8mZsNZu52h8uhy/UHO+AV7DfzqVPmmNtHfgYNugVsGBm5hdw2aSmz1u4CYHT3hjwwsGXZKonrpsOHF2HF1uOhRh/xwfxUQhzw3PD2XNi+kv6R37fZfDJXlAP9noRuNx/5foW58NbZsGu12TT4sk+r3pv/4sAIgAOwYOB/ofM1FT51ocfHiLfmsWiL+R10u0KIdruoG5bNYGZyfsH31PLt9N9/c8xpJGf/idPymL8T546r8BhE5AQoyjfToPduMP/HdLoGXutmqjXXzoB6nYI9wsA4rKnEOOh+y/E/eNq1Fl7pbB4zdiHUaBb4sR34v5KIanDn6vLNLPB54X99Ydvv0Lw/jJhUJab4KUiVgYKUgPmUO31/Ppt25bDxQMhKy8xn1/4CdmUXsGt/AdkFnkp5bocDTkmMoUP9eDokV6ND/Xia1IwmJMRBToGHifNTeOOXjf4GCrVi3FzfozGXnV6fyDCX6ZTz3V2mYtTn/0zzgspSmGtamM9/3bzZN6/A/APZ6WpTidi6ANxxZoFpcueAPfWK7Znc+MEiUvfmER4awpND2zCkQzmqSEV58FRD8OTju3EO//zNy6SFqThDHLw0ogPntakdsDEDZhPi9y4w/1HW7w6jvzt2OEpfacKUJ7/kOqqqYMVXZhNpLOhxjwnTP/6faTQy+juof3qFTv/UD6t57ecNB76z6OhYyxWu6QwIWYDbYf5+ZlhRfOLtxUTvOWy2ajMkZDbPhb1mHnL+89DpqgqNQUROgJlPwKynzJT1MfMhPA6+GgNLP6iSa26OqCAb3j3fNIQKi4Zh/4NT+pf+8RMvhbXfQ8erzKbugTZppGkU1fVm6P9k+c+zcxW8fpbZemTY/6DNRYEbYyVRkCoDBSkprdxCD7v3F7IrO5+dWQcD1s4sE7IKPF4KPD7yi8zXgiIf+R4vBUU+Cjxe8g98nxAVRvsDgalDcjxtk+OJPs4mw/lFXj5emMrrszawIzMfgISoMK45qxFXdG1ATHjoifgjOMiyzFqfea/BumklbwuPNxv21ekQsKf7cslW7vt8GQUeH8nVI3jj8k60qlOBv68fXmzG3edRfN1v457P/uTzxVtxhTh4deRp9G1dhjVlxzP/Tfj+HjPN8abfShd0fx8Pk2837eKvnlo1Pn3d+LP5c/UWmv/Yz3/OHP90NKz8ykxXvOGXsq3XO8S8jXsY8dY8Iqx8JnVNofW2T3HuWuG/Pat6WzY1upT1tfqS5XGRU+Bhb04RH87fwo3Wp9wR+jmWw4njsk+gWZ8Kv1ypIoryYPc62L3WXEIjTIXjRG5mKmWze52pRnkL4eJ3ofVgczwjFV46zRy//IuAr7s9obwemDTC/D8UmWCC4V+bShzP5t9gwnlmuvjtywM7FXx/Gvy3lem8d/N8qNWiYuf7+Sn4+QnzWscsgKgagRlnJVGQKgMFKTmRLMuq0BqrQo+PLxZv5dWfN5Cy1+ypFRvu4qozGnFJ52QSY9y4TnTDjN3rzCLZpRMhLNK0FU9qU+HT7szKZ+7GPUxfmc7kP01r857Na/LCpe2Jj6zgvmEL3jJz0hucAVdNweuzuPOTpXy9dDuhTgdvXtGJs1vUqvBrYM8GeP1M0/CgLBsoWpbpeLTiS4ivDzfMhoj4io+nsmxbDO8OgsJs0473ovEHG2kUZMPbfWDXKkg+3bR3P9o+JEeRmVfEgOd/ITprHZOin6N6UZq5wRVuPt3sdE3Jtv6HWLY1k+vfW8jdec8zzDkbjysK17VTA/I7elLKzzKL2UvbncsucvfCrjUHA9OuNWbKc0Yq/rVyxZK7wshPK7a1g1QOyzL/lmyebbrSXvZJycrTD/+Eea+YNVPX/Vz1pj6DeY3f3mbWOLkiTBOH8nxYZlnw1jmwfTH0vA/Ovj9wY5z9H5gxzvybfc2049//eDyF8GYv2LnCNMG66H8VP2clUpAqAwUpqYo8Xh/f/LGdl2euZ+OuHP9xh8NUqmr412+F+9dxFa/tqhXjpk58RMDbwKfv2UtOgYfaNRKICCv7ufdkFzBv417mbtzN3A172HDI6wK49Zym3Nan+eEdDMtj7yZ4sb25ntAMmvfD27Qvt8+N4NvluwhzhfD2lZ3o0bwCn/D5vDD+PEidZ5ptXPF12f7Tz8800yEytphmCRdPsOdUlt3r4J1+kLsHGvU0b1D/uj5vzwZ482zT0rfTNXD+f8v0FLd+tISsZVN4JewlosiD2HpmQ+r2I8z8/ePYuT+fW96fz2077qO7cyXZ7lpE3fwzjiqy8PmE2fq7mc6TnWb2jOn9f/be08xbBD89Bks+hNzdR79feLzp9JbQDFZ9a34P65xmph9HHt7pU4Jo6Ufw1Y0mYIyZD9UalLw9Zw+80M5sFXHRO2avw6qmuBmPI8Q0zqjI3orLvzAfukUmmKpUWGTFx+fzmf8fM7bA4Neg/WUVPyfAtkXmQzXLZ9ZKFe+NZUMKUmWgICVVmddn8cPyNF6ftYEV2zPxlfJvdJgrhA7J8XRrkkC3xgm0rx+P21W28JOZW8TcjXuYs2E3v67fXSLQVY8Ko058OHXiIqhbLYK68RHU8V/CqRHlJiu/iHkb9zJv4x7mbtjDmvT9Jc7vcEDrOrF0a5xA/1OTjtjavEK+udVsRuw7uPbNcsewyHUaH+1ryZyQDvxndB+6Ny3nFITibkVh0XDzXFNZKquti+CdvmaM5z9n1qGVRvE/7ZUdvLK2m4XEmalmw+fRk8Edc+T7rp0KE4cDlunid9oVpXqKrxZvZennT/GQ632cDstUEYd/UOY3wAUeL09+Po/LV1xL05DtbHU3pcYtMwiPji/TeWwhawcsfMt8Pfv+8v1u/dWSD810Um/hwWMNzzJvVqMDUJ0NtOydZtrolt8OHotLhhrNTWiq0cxsBlqjuZlGVPx3YftSsw1B3l5IPBWu+Krqdsc82eTuNXtG5e4xWxaceceR7zfraZj5uJkmPWYBOE/w1PaKWDoRvrrJXC/LLIWj8XrMdMeMLQFr6uPvluiOg7tWByacFZv2EMx50XQaHjPPrH2zIQWpMlCQkpOF12e6Eu7aX8DO/QcbZRy6nsus6conp9Bb4rHhoSF0bFCNbo0T6NYkgbb14g/rhJdf5GXRln38tn43v63fzbJtJYObwwGRoc7Dzn0kYa4Qirw+/vovUIukGLoeGEPXRgnERVbyf5D5meY/jbVTzVz1Qz7V9lkOltGE6h0GkXz6EEhqW/pgsnudmdLnya/4/hm/vQjTHzLT2K77yXyqnp1m5rBnbTcbHhZ/PfRYSKiZ7pbcxexbVa9jqao3pZa7F8YPME1HEpqatVzHm/de/AbIGQZX/WDGdAypuzKZ8/I1DHdMNwc6XA4Dnyvz1MBilmXx+Yzf6DV7BDUcWfwe2ol6N39NUrXo4z/YDtKWw9yXzZ5jvgNbOYTFmL3iTruyfMHZ6zEbfM8/0JCjxfmmxfR3d5mpmtFJcMm7lbtXTVmlLoRPrjC/52ExcMELpuFNadc9pa+E9y6EnJ0mbF35NcQGuMmMlN3XY2HJ+1CrlVlPebSAVJBtqlK5u8v2AVOwbfjJrCP1eeCM2+HcRwNz3vlvwPf/MMFy7O/H3+fxeD4dbaaVd74OBj4bkCH6FebC62eYPaY6jjb/P9qQglQZKEjJ341lWWzancPcA5WgeRv3sDu7sMR9IsOcdGpYna6Nzaf+v63fze+b91HgKdkivnHNKM5sWoPuTWrQrXECsREusvI9bM/IY3tGHtsOXLZn5PuPpWfl+wNY01rR/vB2eqPqJEQHsGV7Wfl8Zq752qn41vxASPqfJW93x0H1RuY/q+Kv1RqZ69FJB6ftHdrutUlvM32oApWhTbv245w0nPp7fqMIF6FUoHtkjeYmVCV3Nl9rtijfGoPCHHhvsOnQGFPbzKEvTVXE54OPL4c130FsXbh+1lGrAd7cfax4fghtC5fgw4HV+xGcZ94WkCrbH/Nm0PyHS4mgkM9C+tFk1Ot0CHTFM1Asy2xsPedl0+ClWP3u5g3Z1gXm+ya94YKXyrZPS+5e86Zp0yzzfc/7oOe95ndi11rzs9q9xjQ96fsvs39csKeX/j7evGn0Fprf5+EfQs3mZT/P7vWmm2bWNvP3eNQ3gansSflsmWM+mAG4etrxO3wWh4foJLh1SWCrJpUhbRm8M8BMSWxzMQx5M3Druwqy4bnWkJ9hqvUtB5X/XDm74T8tzAc1N/5aOWtJN/8KEw5MZxz1bUD3mQwUBakyUJCSvzvLsli/M7tEsNp3lI2LE2PdnNGkBmc0rUH3pgnUjoso8/MVeX2kZeYTfmBPLrvK35PKB++/Rf09v3JmyHIiHQVHvW9RSDiZ4XXYG1YXr8+iZdavFLli2DpiBvUblW1dl89nsSQ1g+kr0/lxVTrrd2ZTnSwmu/9JHcdeAAosFzutamS6EvDF1CYyoR416zYirmZ988l6TG1TTUhdYNa9bF1gPgH8K3cs1O1oKlc1W5rOTAnNjr1fiLcIPhoB66ebtSdX/wC1Wpb69ZGfZRZI71kHDc40HR7/+snzng3s/d9QquduJtdyk3P+G9TsPKT0z1EKuxZ8RsKUawnB4t/ey2k6+H4u6hjgTZkL9sP6GaZKmNDETDeLb1C6T4w9BabyNPcVs0AbzJqKVhdCt1tMNc/nhXmvwozHwFtgwv6Af0O7EccPPOkrTdewfZshNAqGvnH4G7CCbLNJ9IovzPeth5qw5g5CBc9TYBrELH7PfN9ykFm/cbSppKWxb7NpbJCRYqYFjvqmcrePqGqK8s2+cKnzTUe55C7m34uK/JkfiacQ3jjLVLdPGwUXvFiKxxSYaYAZKWYt31l3BnZMgZSRCv8711RQG55lPlwL5D6PYBpDzP5PxZtDFM+AqHMaXD/z+Pcvr8l3mN+tag3hprm2C8IKUmWgICVSks9nsSZ9P3M37GH+pj04cNCtSQJnNE2gSc3oCnUdrGryCr2MHr+AJZvSaehIo6EjjfqOnTRwpPsvdR27cTkO38z57qIb+Mzbk/DQEFokxdK6Tiyt68TRuk4spyTFlGj2kV/k5dd1u5m+Mp0Zq9NLVAhdIQ5Ob1ydgU0jqBuyh3k7Q5mZ6mPNzuzDpkbWqxZBl0bVOb1RdU5vlECDhMiDP6+c3bB14YFwtdAs/C3KPfxFO0LMm8maLcylVsuDC/WdYfDl9bDsU9PO/cqvzZurstq11oSpwv1w+k3mzX+xzb/i+WgkroIMtlvVWdHzTc4959yyP0cpFMx+CfeMBwG4sfB2ane7hHv7t6hYI5asHbBmirls+qXkmiMwf4YJTc2lRvMDl2bm4o4xVaJF403b/OwD3QlDo8zUva43mjcef7VrrVmgv22R+b75ALOvzNFaza/6Fr64wWwQHd8ARnx09NbLlmU+/Z/2gKmA1TjFfOpdnipQeWVuM1P5ti0CHND7YbN+JhD/FmVuM5WpPetNdWPUN+b3vbLk7jVdBWu1sm/XQK/HrB+d9ZSp2B3KEXIgVJ1+4NLF/A5V5GdR3CEusobZXLa06x//+Nj8exQeB7f9Edipy4GStw/e6W9CYs2W5oOnyujAuj8Nnm9j/r0pTUXvSCzLhNM962HQi9BxVODHWSw/C17tan6/uo0105NtREGqDBSkRORYcgo83PPZH8zbuJeIUCcRYU4iw5yEh5qv0aEWddhNHd8Okrw7qFm0nZ2OGrxd1J9VafvJPcKaMWeIgyY1o2hdJ47sAg+z1+0iv+hgGItxu+h5Sk3ObZVIr1NqERdx+FqBjNxCft+8jwWb9zJ/016Wb8vE+5duI7XjwunWOIGuB5qKJFc/5FM/rwd2rjTVqrRlsHO1aVGen3nkPwhHiHmjuX+7meo1YhI0q0DAWTUZPh5prg95E9oNhyUfYH17Ow5fEUt9jfm4ydM8cWWfygvvloU15R4cC98i3wplROGD7IxrywMDWzLg1KTSPa9lmQ0n13wHq6eY6aGHqt4EEluZTpF71pt1c0cTU9v8+RcH3JjaZjpdx9HHf/Pl9ZhF3D8/ad5MhcebxextLjr4Jtfng1+eNvcB02Xx4gmle+OaMs9MA9y/wzRQufCVg/v7VKbNv5rnzdllXtNF7wR+/6D96WbN1K5V5s38lV8FfkpT9k7z81n4P/PzdYSYZhf1ux64dIPYOoF9zrLy+WDV16aj3J715lhsXbM2cc8G8yFMZsrhj4tONIEq+XTTWr7uaaVfp7N3k3lD7ck/+O9AqcfrNZ1Nd64o35qjbYvNhx3tLi33/nbH5CmA94fCll/N3+Vrf4S4AFe9D/X1GFhyYGrf8A/K/vjiKXdh0XDXmsqvPK+dBhMvNn8XrvnxuGtmTyQFqTJQkBKRyuL1WWzek8OK7Vms2J7Jyu1ZrNiexd6cwsPuWycunD6tEjm3VSKnN0ogzFW2+fM5BR4Wp+xjwaa9zN+4l6WpGRR6S1bK6lWLoHuThAPdGmuQFPeXKXyWBdnp5G5bTsbmZRSmrSRs71riszcQ6TvYVfGH5o/RcdANFZ+a+dO/TCtgV7jZW2Sp+c9/srcrz4Tfxtd39Kn4nmHH4/PCpMtg7Q8U4SLdimefFY0vIoGG9RsQl1AbohJMe+HIGqahRmQNUy1aPcUEqH2bDzmhw+wJc8p5pq1xjeYlg0xmaskNYnevM9Mcs9MPniKxDXQfa6bSlbWxRvpKU53a8Yf5vuUg06AjNBy+vBFWTzbHu94M5z5Wtvbm2Tvhs6vNHj9gPknu88ixu6ZZlqlkFQfIsOjSVS8sy2z4Pe1BsyloYhu49IMjV+QCIWcPfDDE/LmFx8MVX5hpbBW1P/1ggPLkmWMR1Uyl4q/i65tAlXy6+VreNYxlVbwOb8a4g783EdXhrLug87Ulp/pmbTeBKnWBmfK344+DjU+KRVSDpn2gWT8Teo8W1C0LPrwI1v9oQv2VX5e9srXmB/houPk35NYlpQuj2btgxiMmdICprne9Cc64LXBd5Hw++OJaWP65aYhy9Q+QdGpgzn00O1eZUIoDbllkphOXxefXwbJPSj+9MhC+uB7+/NhU6274pdyNhAJNQaoMFKRE5ESyLIu0rHx/qApxQK9TatG6TmxAKy95hV4Wp+xjzgazL9efWzPx/KVi1ahGFF0bJ1AnLpwte3PZvDuHzXtyDms+AhY1yaB5yFb2W5H8aTUhzBnCwLa1Gd29Ie2S48s3SJ/XtERfP91/6AXPUF7wDuWDa7qVv/V8WRVkmzd0KXPL93inGxr3ghbnmWl1MYllP0dexoEqgMN8ol+R3wVvEfz6nJma5fMcCIEJJrg5w+D856HDyHKe2wM/jYPfDnTbqtHcnLsoz3wC78n/y9c8s29MMWcYRNU0gTSqprlEJhy8HlXTBNd5r5kppABtLjHdvSp7HUVehvk92LrQvPkd+Sk06Fa+c+1PM39Gv79zMETW7WgaejQ719yeOs9U+lLmmqqw9ZcpwuFx5jHxDUwTkbhkUyGKq2e+BuJNZ+oC+PFRUzUBE3S7jTX7tJVm6mFRnmkpnzrfnGvLryWr2o4Q09imeV8TrBJbH/zdLt4DyRlm1smUZxNoyzJT51LnHb8LnLcIFr4NM580e4mBqRjv3WCuR1Q7EB6vO/Y60dKY/rD5+Ye4zJqoxr0qdr7S+vBi04G2rPv15e41TSa8BXDdzKNucB5wOXvglS6mA2OgNxWuAAWpMlCQEpG/g5wCDws372Xuhj3M3biH5duOve9YjWg3jWpE0iAhikY1omiYEEXDGpGs35nNu3M2szglw3/f9snxjO7ekPPa1C5zJY28ffC/flj7NvOg7wY+zOvK9T0a88/zytDAIhAsy+zFkrOHXenbmDJ/Gdu2pVLdkU2SK5tONb3UDcvFkbvb/OfvCoNmfU3lqck5wWnAcDw7/jR71qQvN99HJ5kpP8mdK37uVd/ClzeZdW6VxHI4cfR7/MR2CyzYDxMvNYEgxGWm+NVuZ/ZJq9PerG06VqOArO3mDfSiCQcDVL3O5k1i095Hfx0F+02ASzkQrrYuPPIaxkNFJx4MVnH1zPQ0d4wJgWFR5ncy7MDFHW2OhUWbaXfpK81mxmummHM5w0yAOOvO429jcCzeA50ki7eU2Lmy5O2xdc3fmyZnw5R7TCW21/3Q677yP+eWuTC+PzicZl+pIwWyjbPg+3vN9E0wP9MBz5gpiau/M9W43WsOjLEenP1PM+WvLK3Ec/ea6trqybDya3NsyBvmPCfKptnw7vmmQnfHitL/LOe9Bj/cZ37fb5gdkL9vm3bn8NPqnQztUJdqUccI/cWBOiQUbph19PWaJ5CCVBkoSInI31FmXhELN+1l7sY9ZOYV0aB6JA1rmNDUICGSmPBj7+H159YMJszZzOQ/dvinENaMcXNZl/qMPL0+tWJL/4muVZTPTe/O5Yf1ubSqHcuXY7qXeYPoyjBn/W4e/Xalf7PolrVjeWRQK05vnHDUx+QXeUk5pLq3aXcuhR4fpyRF06p2HC1rx5SrzX9OgYc/t2ayNDWDJSn7/FM3L2hXhxFd6tOy9lH+//IUwpwXTEOKc8cFdr+krO2mbbUzzLxxc7nN19Dwkt+73OCKMBWX3N1mvVPOngNfzcXK3U3Gru1k7NqOu3Av+61Ivq17JzdfNYrIsDJMP6ygQo+PaUs3kjjtJjoXLjj8DiGhpgFLnfYmXNVub9745e4xVcDF75lP9cFM0et5rwnaZX1j6i0yVaq0ZWZBfubWg5esbcdea3c8rogDj7dMxaj9ZSboxSeX/5xHk5FiAtXaaWY9UvH0xmIJTeGmORXvYjdxOKz9AVoPMev+Dn3+aQ8eDDaRCaZZSYcrSoYkrwf++MisHyxusFGzpbnvKQOO/POzLPMhRXFo3LqwZFXxnIegx90Ve11lZVnwZi/YsRR6/RN63Vu6x7zazYTMgf8x0zkrNASLT35P5ZFvVpJX5KVetQjevKITreoc5d8oy4JJI8006XYjYMjrFXr+QFCQKgMFKRGR8tudXcBH81P4YP4W0rPMG8hQp4MBp9Y+0LABirwWHp+PIo9Fkc+Hx2tR5PXh8Vl4vD4278nls0VbcbtCmHzLmTRLDHB75QrweH18OD+F/05fS2aeWQtyftvaXHNmI3btL2Dznhw27zkQnHbnsCMr/7Buin+VGOumZe1YWtWONV/rxNIwIcrfJt/ns9iwK5slKRksORCc1qbvP2YFsX1yPJedXp/z29Y+ocGjonw+ix9XpfPKzxv4IzUDMJ0qQxwOCr0+2taL4+1RnagVU8GpVsexc38+E+en8OH8FHbtLwAs6jt2cqpjEx3DtnBufBrJ+Wtx5B9hbVOIC3AcXCtUv7t5A9uoZ+VU0izLBLdDg1VmqlnDVpBttj4ozDb7vR36ve8ve9C1uhDOfvDEdWAsyjMVk3XTYN1UM97Lv4CGZ1T83GnLzSboWHD9z2Z92W8vmnDryTOBsfO1ptJ0rO5+RXmw4C3TSTA/wxxL7mrWAjboZv48N806EJ6mm+Y7h6rV2kxjbHG+WSsZQF6fxd6cwuOvTV32GXx+jVnLefF4c8yyAOsIXzENRCbfYdaK3bW6QuvEMnOL+OeXy/hu2Q4A3K4QCjw+IkKdPHNxW85ve5Q1bFk7TKfI7rfaYp2UglQZKEiJiFRckdfHD8vTeHfOZn7fcoQ3m6Xw6AWtGdW9YWAHFiB7cwr5z7Q1fLQg5ZiBBkzXxYY1oswlIZJQZwir07JYuT2LzXuOPF0rItTJKUkxRIY5WbY1k/0Fh2+8XCcunPb14+mQXI329ePJL/IyaUEqU1ek+de/xbhdDO5QlxFd6h/9E2Ab8Hh9TP5zB6/+vJ616dkAhIeGcGnn+lzXozE7MvK47r3f2ZdbRN34CN4Z3ZlTkgIfsJemZjDht018t2wHRV7zZ1grxs0VXRtQPyGSV2YeHF+1CBd3dY3k4tq7ce9aZhotbF9qqmxg9kXrda/ZK8hu20RYlunmWBysXO7K6VRXlvFYvrJNnTue4sYFSW1NCMo40GGwwZkw4KmyNXvIyzBTNOe9drCKltjGTP87dEsDV4RZ/9TsXDNlsRKqetkFHj79PZUJczazZU8uwzsl8/CgVkS5j/KBidcDL7Y34bos2o+Ewa+We5wLNu3ljo+Xsi0jD1eIg7v6nsLwzsncNmkJs9eZvyM39WrC3X1PKdPeisGgIFUGClIiIoG1fFsm783dzJr0bEJDHLicDkKdIYQ6Q3CFmOsupwNXSAhhLvO1UY0orjqjoe33KVuxPZMnp6xm+fZMkqtF0iAhssQasoYJUVSPCjvq68gu8LAmLYuVO/azcnsWK3dksSYtq0T7ezDBqm29OH9w6lA/nsSjTJfctb+Azxdv5aMFKWw5JKi1S47nsi7JnN+2ztHfdJ1g+UVePl+8lddnbSB1r3mDGuN2cWX3Blx1RiNqHDLtcfPuHK6esJCNu3OIcbt49fLTOKtZzQqPodDj4/vlOxj/22aWHqiCAXRsUI1R3Rsy4NQkQp1mrZ/XZzH5z+08/+M6Nu3OAcz6wZt6NWHk6fUJd4WYKY5FuWYvsBMsv8jLiu2ZLEnJYFtGHjVj3NSOCycxNpzacREkxYYTERb8abInwv609US+cTpO68CHELF1oe9jpvtlef9dydoBs/4Ni9833SPBNP9o3s80z2h4ZsUbUxxF6t5c3p2zmY8Xph72wUrDhEieG96eDvWPUl1b/R3MfMJMEXU4AMcRvnLwe3esadRR1k5/mA9FXvxpPS//tA6fBQ0SInnx0g7+JkRen8XTP6zmjV/MpvA9m9fkxUs7EBd57OnjwaQgVQYKUiIiEkxen8Wm3Tms3JFFXqGHNnXjaZ4YjctZtsYdPp/F3I17mLgghWkr0vwVlmi3i94ta1Ez2k1sRCix4S7iIkOJDQ898H0osREu4iJCiQh1VkqY3Z1dwJeLt/HW7I3s3G+mgFaPCuOaMxtxedcGR9wrDWBfTiE3fLCIBZv24gxx8K/BpzKiS/1yjWFnVj4TFxw6fQ/CnCGc3850n2xbL/6oj/V4fXy5ZBsv/rTOHwCTYsMZc05ThndKLnuTlXKwLIut+/JYnLLPTPtM2cfKHVn+n/PRxEWEUjsunKS4cH/IqhnjJiLU7IfndoUQHuokPDQEt+vQr07coebDj+wCD9n5Hv/X/Qe+5hR62H/I8SKvj7jIUKpHhlEtKuzg1wPXY8JdhAS4GrEufT/vzd3C54u3Mtr7OTe4JvO+ty9pbW/mtgHtK75NA8Du9aaJRt2OJbc0CDDLsli0ZR/v/LaJH5an+avfjWtEcdWZjUiuFsE/v1jG9sx8nCEObj2nGWPOblLmfysCJXVvLrd/vJRFB2YhDDutHo9e2JroI3xw8/XSbdz7+Z/kF/lomBDJm1d2ormNpnEfSkGqDBSkRETkZLM7u4DPF5kq1dGmEx6JK8RBQnQYzWrF0CwxmuaJMTRPNNdjj9OABMwbwe2Z+Szflmn2TzvwNS3rYHOE2nHhXN+jMZd2rl+qakmBx8t9ny/jyyWmCcCNPZvwj36nlOoNucfrY9baXUxamMpPq3f6N60unr434vT6Japgx1Pk9fHp71t5+ad1bM80r6lufARXn9mIOnGm+hPldhEZ5iQqzHyNdLuIDHUedbyWZVHktSj0+ij0HHLxetmZVXBgnVwGS1P3HWFrAqgRHUaH+tVoVCOK3dkFpGflsyMznx0Z+eQVHb4heDA5QxzER4RSLSqMxFg3HRtUp2uj6pzWoBrhoaWvnHl9FjNWpfPu3M38tn6P/3izWtE0rhnF1BVmX7YYt4tbezdjVPeGJyTslleR18eUZTt459dN/LH1YPv4s5rV4OozGtGzeU3/709mXhEPfbWcb/4w67NOqx/Pc8Pb0yAh6oSO+Zs/tvPAF8vYX+Ahxu3iX0NO5cL2dY/5mOXbMrnh/UVsy8gjKszJf4e3p1/rIE4xPQoFqTJQkBIRkZOVz2cxb9MelqRkkJVXRFZ+EVl5ngNfi8jMKyIr30NWXtFh+4z9Ve24cJolxtC8VjTNk0zAina7WLnjYGBavj2TjNyiIz6+RVIMV5/RiMEd6pb5Ta1lWbwwYx3P/7gOgPPaJPHfS9of9c13yp5cPvk9lU8XpfqboMDB6Xv9WydV6I11gcesT3tl5np/he14wkNDiApzEeYK8YelggPhqbRCnQ5a1YmjQ3I8HerHc1r9atSrFnHEKqJlWWTle0jLzCctK5+0zDx2ZOaTlpnP7uxCCjxeCop85B/yNb/IS4HH5/9a/C4xxGEqm9FuF9HhxV9DiTlwLOrA8dAQB5l5RezNLWRfTiF7c4vYl2OuH2ndX7EwZwjtk+Pp2rg6XRsn0KF+tSOG7H05hXz8eyrvz93Ctow8/9jObZXIqG4N6dYkAYfDwaIte3n025X8eSCUNK4RxUPnt+LsFrVK/WddVoUeH1n55u9UToEHj8/Csiy8PhP8LMvCa1n4LPP30uuz8FkW63Zm8/7cLf4PG8JcIQxpX5erz2x0zHWBXy/dxoNfLmd/gYeoMCf/d0FrLu5Yr8wVZcuyyC7wEOYKIcwZctzHZxd4eOSbFXy2aCtggtwLl3YguXrp9nnbk13AmImLmbdxLwC39W7Gbb2bBbxSWREKUmWgICUiIn93lmWRV+QlK8/Djsw81qVnsyZ9P2vT97MuPbtERel4XCEOmtaK5tS6cbSuE8updeNoWTv2iNN9yurLJVv5x2d/UuS1aJ8cz9ujOvkrSvlFXqatTOfjhSklqhTVo8IY2qEuwzsnB7wjZH6Rlw/mbWH2ut3kFHjILfSSW+ghp9BLXqGXnELPcbs4/pUzxEGYM4QwVwixES7a1jWhqUP9arSuE1umyk1FWJapknl9VkCmfBZ6fGTkFrI3t5C9OYVs3p3Lgk1mX7tDwy6YwGiCVQJdGycQE+7iw3kpfLV0GwUHgmd8ZCiXdq7P5V3rU6/a4W/ifT6LzxZv5ekf1rA725y/1yk1eXBgK5rWKt2+bz6fRcreXJZty2Tjrhwy8grNhw955gOJzAMfRmTmFVW4+lcj2s2V3Row8vT6pd4iYeu+XO785A8WbDKhpH/rJJ4c2uaY+zZZlukKOn/TXhYcuOw4UF11hjiIDHX6K6sRoU4iw8z3kWFOIsNcLE7Zx5Y9uYQ4YOzZTbm1d7MyTy0s8vp4/LtVTJizGYA+LRN5bni74267caIoSJWBgpSIiMixZeYVsS59P2vTs0242rmfNWnZZBcU0SIpllPrxtK6jglOzRNjKvXN/vyNe7j+/UVk5hVRr1oE4y5szex1u/lyyTZ/NczhgDOb1uDSzvXp06pW0PYlsyyL/CIfuYUmZOUUeij0+Pyf/oe5zMXtdPqv272jWaBZlsWWPbnM27jnwGXvMYN76zqxjOrekAva1SnV79n+/CJenrmed37dRJHXwhXiYHT3htzSu1mJtXlmrWI2y7dlsXxbJsu2ZbJye9YxK2lHEhPuIsbtwul04HSYVv4hIea6w2HCijPEgcPhwOmAKLeLwe3rcn672uX6PfX6LN78ZSP/nb6GIq9FrRg3/7mknb8xi9dnsTotiwWb9jJ/414Wbt7LnpzDp4iWRZ24cJ4b3v6Ye+qVxqe/p/LAV8sp9PhoWiuaN6/oSOOawd/cXEGqDBSkREREqpYNu7K5esLCEl0KwUw/vLhTMhd3rFfqqUZiL5ZlqkDFoWruhj3sySmg/6m1Gd29AafVr1au6tim3Tn8a/JKZqzeCUBCVBhXndGQ3dmFLN+WycodWeQWHl5VCnOF0DIphhZJsVSPDiMuIpS4A01aiq/HRZiGLTHhoUELwsu3ZXLbpCVs2GW6Sw7tUJeMvCIWbt7L/vySYdDtCuG0+tXo0qg6pzeqTtvkeHyWZaqoByqreUVe87XQQ06Bl9wicz3UGcLQDvUC1nVvaWoGN76/iLSsfC7qWI9nL24XkPNWhIJUGShIiYiIVD17cwq58YNFLN6yjz4tExneJZkezWr+7So6JzvLsrAsAraG5uc1O3ls8kp/4DhURKiTVnViObVOLK3rxtGmbhxNa0X72+HbXV6hlye/X8V7c7eUOB7tdtGp4cHg1KZuvK2ab+zcn8+zU9fwf4Na22KrBgWpMlCQEhERqZosy6LA4zth64bk5FDk9fnXtjVMiKJNvVhOrRNH45rRJ0UQn7V2F1NXpNGkZjSnN6pOy9qxJ8XrOlEUpMpAQUpERERERKD02cA+NT0REREREZEqQkFKRERERESkjBSkREREREREykhBSkREREREpIwUpERERERERMpIQUpERERERKSMFKRERERERETKSEFKRERERESkjBSkREREREREykhBSkREREREpIwUpERERERERMpIQUpERERERKSMFKRERERERETKSEFKRERERESkjBSkREREREREyuj/27vT2KjKv43j19R2hmlZWii0U3ZCZbUNtFDHQoy0AapBwKqYVFP0BSkMCC4JSIRiXEpcUDFYBAVMIFRLUgRCwcpSI2EtW5FaQSsQS6lElqGyhbmfF4SJI8jj/LWeGfx+kpPMnPvQ/tqLSc6VM3NKkQIAAACAIFGkAAAAACBIFCkAAAAACFKk1QOEAmOMJOn8+fMWTwIAAADASjc6wY2O8GcoUpK8Xq8kqXPnzhZPAgAAACAUeL1etWnT5k/Xbeb/q1r/AT6fT/X19WrVqpVsNpuls5w/f16dO3fWiRMn1Lp1a0tnwV9HbuGJ3MITuYUncgtP5BaeyO3vMcbI6/UqKSlJERF//kkorkhJioiIUKdOnaweI0Dr1q35jx+GyC08kVt4IrfwRG7hidzCE7n97253JeoGbjYBAAAAAEGiSAEAAABAkChSIcbhcKiwsFAOh8PqURAEcgtP5BaeyC08kVt4IrfwRG7/Dm42AQAAAABB4ooUAAAAAASJIgUAAAAAQaJIAQAAAECQKFIAAAAAECSKVAhZsGCBunXrphYtWigjI0O7du2yeiT8wddff61Ro0YpKSlJNptNq1evDlg3xmj27NlyuVxyOp3Kzs7WkSNHrBkWkqSioiINGjRIrVq1UocOHTRmzBjV1tYGHHPp0iV5PB61a9dOLVu2VG5urk6dOmXRxJCk4uJipaSk+P+YpNvtVnl5uX+dzMLD3LlzZbPZNG3aNP8+sgtNc+bMkc1mC9h69+7tXye30PXzzz/rySefVLt27eR0OnXPPfdoz549/nXOTZoPRSpEfPbZZ3r++edVWFiovXv3KjU1VSNGjFBjY6PVo+F3mpqalJqaqgULFtxy/c0339T8+fO1cOFC7dy5UzExMRoxYoQuXbr0L0+KGyorK+XxeLRjxw5VVFTo6tWrGj58uJqamvzHPPfcc1q7dq1KS0tVWVmp+vp6PfLIIxZOjU6dOmnu3LmqqqrSnj17NGzYMI0ePVrffvutJDILB7t379ZHH32klJSUgP1kF7r69eunkydP+rdvvvnGv0ZuoenMmTPKzMxUVFSUysvLdfjwYb3zzjuKi4vzH8O5STMyCAmDBw82Ho/H//zatWsmKSnJFBUVWTgVbkeSKSsr8z/3+XwmMTHRvPXWW/59Z8+eNQ6Hw6xcudKCCXErjY2NRpKprKw0xlzPKCoqypSWlvqPqampMZLM9u3brRoTtxAXF2c+/vhjMgsDXq/XJCcnm4qKCnP//febqVOnGmN4vYWywsJCk5qaess1cgtd06dPN0OGDPnTdc5NmhdXpELAlStXVFVVpezsbP++iIgIZWdna/v27RZOhmDU1dWpoaEhIMc2bdooIyODHEPIuXPnJElt27aVJFVVVenq1asBufXu3VtdunQhtxBx7do1lZSUqKmpSW63m8zCgMfj0UMPPRSQkcTrLdQdOXJESUlJ6tGjh/Ly8nT8+HFJ5BbK1qxZo/T0dD322GPq0KGDBgwYoMWLF/vXOTdpXhSpEHD69Gldu3ZNCQkJAfsTEhLU0NBg0VQI1o2syDF0+Xw+TZs2TZmZmerfv7+k67nZ7XbFxsYGHEtu1quurlbLli3lcDhUUFCgsrIy9e3bl8xCXElJifbu3auioqKb1sgudGVkZGjZsmXasGGDiouLVVdXp6FDh8rr9ZJbCPvxxx9VXFys5ORkbdy4URMnTtSzzz6rTz/9VBLnJs0t0uoBAODf4vF4dOjQoYD3/SN09erVS/v379e5c+e0atUq5efnq7Ky0uqxcBsnTpzQ1KlTVVFRoRYtWlg9DoKQk5Pjf5ySkqKMjAx17dpVn3/+uZxOp4WT4XZ8Pp/S09P1xhtvSJIGDBigQ4cOaeHChcrPz7d4ujsfV6RCQHx8vO66666b7n5z6tQpJSYmWjQVgnUjK3IMTZMnT9a6deu0ZcsWderUyb8/MTFRV65c0dmzZwOOJzfr2e129ezZU2lpaSoqKlJqaqref/99MgthVVVVamxs1MCBAxUZGanIyEhVVlZq/vz5ioyMVEJCAtmFidjYWN199906evQor7kQ5nK51Ldv34B9ffr08b8tk3OT5kWRCgF2u11paWnatGmTf5/P59OmTZvkdrstnAzB6N69uxITEwNyPH/+vHbu3EmOFjLGaPLkySorK9PmzZvVvXv3gPW0tDRFRUUF5FZbW6vjx4+TW4jx+Xy6fPkymYWwrKwsVVdXa//+/f4tPT1deXl5/sdkFx4uXLigH374QS6Xi9dcCMvMzLzpT3p8//336tq1qyTOTZqd1Xe7wHUlJSXG4XCYZcuWmcOHD5sJEyaY2NhY09DQYPVo+B2v12v27dtn9u3bZySZefPmmX379pljx44ZY4yZO3euiY2NNV988YU5ePCgGT16tOnevbu5ePGixZP/d02cONG0adPGbN261Zw8edK//fbbb/5jCgoKTJcuXczmzZvNnj17jNvtNm6328KpMWPGDFNZWWnq6urMwYMHzYwZM4zNZjNffvmlMYbMwsnv79pnDNmFqhdeeMFs3brV1NXVmW3btpns7GwTHx9vGhsbjTHkFqp27dplIiMjzeuvv26OHDliVqxYYaKjo83y5cv9x3Bu0nwoUiHkgw8+MF26dDF2u90MHjzY7Nixw+qR8Adbtmwxkm7a8vPzjTHXbzM6a9Ysk5CQYBwOh8nKyjK1tbXWDv0fd6u8JJmlS5f6j7l48aKZNGmSiYuLM9HR0Wbs2LHm5MmT1g0N88wzz5iuXbsau91u2rdvb7KysvwlyhgyCyd/LFJkF5rGjRtnXC6XsdvtpmPHjmbcuHHm6NGj/nVyC11r1641/fv3Nw6Hw/Tu3dssWrQoYJ1zk+ZjM8YYa66FAQAAAEB44jNSAAAAABAkihQAAAAABIkiBQAAAABBokgBAAAAQJAoUgAAAAAQJIoUAAAAAASJIgUAAAAAQaJIAQAAAECQKFIAAATJZrNp9erVVo8BALAQRQoAEFbGjx8vm8120zZy5EirRwMA/IdEWj0AAADBGjlypJYuXRqwz+FwWDQNAOC/iCtSAICw43A4lJiYGLDFxcVJuv62u+LiYuXk5MjpdKpHjx5atWpVwL+vrq7WsGHD5HQ61a5dO02YMEEXLlwIOGbJkiXq16+fHA6HXC6XJk+eHLB++vRpjR07VtHR0UpOTtaaNWv8a2fOnFFeXp7at28vp9Op5OTkm4ofACC8UaQAAHecWbNmKTc3VwcOHFBeXp6eeOIJ1dTUSJKampo0YsQIxcXFaffu3SotLdVXX30VUJSKi4vl8Xg0YcIEVVdXa82aNerZs2fA93jllVf0+OOP6+DBg3rwwQeVl5enX3/91f/9Dx8+rPLyctXU1Ki4uFjx8fH/3i8AANDsbMYYY/UQAAD8VePHj9fy5cvVokWLgP0zZ87UzJkzZbPZVFBQoOLiYv/avffeq4EDB+rDDz/U4sWLNX36dJ04cUIxMTGSpPXr12vUqFGqr69XQkKCOnbsqKefflqvvfbaLWew2Wx6+eWX9eqrr0q6Xs5atmyp8vJyjRw5Ug8//LDi4+O1ZMmSZvotAACsxmekAABh54EHHggoSpLUtm1b/2O32x2w5na7tX//fklSTU2NUlNT/SVKkjIzM+Xz+VRbWyubzab6+nplZWXddoaUlBT/45iYGLVu3VqNjY2SpIkTJyo3N1d79+7V8OHDNWbMGN13333/088KAAhNFCkAQNiJiYm56a12/xSn0/mXjouKigp4brPZ5PP5JEk5OTk6duyY1q9fr4qKCmVlZcnj8ejtt9/+x+cFAFiDz0gBAO44O3bsuOl5nz59JEl9+vTRgQMH1NTU5F/ftm2bIiIi1KtXL7Vq1UrdunXTpk2b/tYM7du3V35+vpYvX6733ntPixYt+ltfDwAQWrgiBQAIO5cvX1ZDQ0PAvsjISP8NHUpLS5Wenq4hQ4ZoxYoV2rVrlz755BNJUl5engoLC5Wfn685c+bol19+0ZQpU/TUU08pISFBkjRnzhwVFBSoQ4cOysnJkdfr1bZt2zRlypS/NN/s2bOVlpamfv366fLly1q3bp2/yAEA7gwUKQBA2NmwYYNcLlfAvl69eum7776TdP2OeiUlJZo0aZJcLpdWrlypvn37SpKio6O1ceNGTZ06VYMGDVJ0dLRyc3M1b948/9fKz8/XpUuX9O677+rFF19UfHy8Hn300b88n91u10svvaSffvpJTqdTQ4cOVUlJyT/wkwMAQgV37QMA3FFsNpvKyso0ZswYq0cBANzB+IwUAAAAAASJIgUAAAAAQeIzUgCAOwrvWAcA/Bu4IgUAAAAAQaJIAQAAAECQKFIAAAAAECSKFAAAAAAEiSIFAAAAAEGiSAEAAABAkChSAAAAABAkihQAAAAABOn/ANpBrpdCDe2SAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# テストデータセット上で予測を行う\\npredictions = model.predict(test_data)\\n\\n# 予測結果を出力する\\nfor i, prediction in enumerate(predictions):\\n    print(f\"予測された住宅価格: {prediction[0]:.2f}, 実際の住宅価格: {test_labels[i]}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 同一パラメータでのモデルの選択"
      ],
      "metadata": {
        "id": "8K42qkL3_skT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## code"
      ],
      "metadata": {
        "id": "40hr_SKPZB90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import sys\n",
        "\n",
        "\n",
        "# データの読み込み\n",
        "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()\n",
        "## データの確認\n",
        "# print(\"train data\")\n",
        "# print(f\"data shape{train_data.shape}\")\n",
        "# print(f\"data type:{type(train_data)}\")\n",
        "# print(f\"data ex:{train_data}\")\n",
        "# print(f\"Number of test data:{len(test_data)}\")\n",
        "# print(test_data.shape)\n",
        "# print(f\"Number of train data:{len(train_data)}\")\n",
        "# print(train_data.shape)\n",
        "\n",
        "num_rows,num_cols=train_data.shape\n",
        "print(f\"行数:{num_rows},列数:{num_cols}\")\n",
        "print(train_data.shape[1])\n",
        "# モデルの定義\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "#input_shape:データ列数のタプル※単一次元なので(,)つき\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1))  # 出力層\n",
        "\n",
        "# モデルのコンパイル\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# 過学習の防止 Early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "## EarlyStoppingコールバックを作成\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# モデルの学習\n",
        "history=model.fit(train_data, train_labels, epochs=100, batch_size=8, validation_split=0.2, callbacks=[early_stopping_callback])\n",
        "\n",
        "# モデルの評価\n",
        "test_loss, test_mae = model.evaluate(test_data, test_labels)\n",
        "# test_loss, test_mae = model.evaluate(test_data, test_labels,verbose=1)\n",
        "print(f\"Test Loss:{test_loss:.3f}\")\n",
        "print(f\"Test MAE: {test_mae:.2f}\")\n",
        "\n",
        "# 最適モデルの選択\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# トレーニングと検証の損失をプロット\n",
        "print(type(history.history))\n",
        "print(f\"loss :{history.history['loss']}\")\n",
        "print(f\"loss numb:{len(history.history['loss'])}\")\n",
        "print(f\"val loss :{history.history['val_loss']}\")\n",
        "print(f\"val_loss numb:{len(history.history['val_loss'])}\")\n",
        "# モデルの学習曲線をプロット\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training vs. Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "# テストデータセット上で予測を行う\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "# 予測結果を出力する\n",
        "for i, prediction in enumerate(predictions):\n",
        "    print(f\"予測された住宅価格: {prediction[0]:.2f}, 実際の住宅価格: {test_labels[i]}\")\n",
        "'''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X09jlFXF_yb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 修正版"
      ],
      "metadata": {
        "id": "3zlPrSlk1_MK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## code"
      ],
      "metadata": {
        "id": "9UXDT9RN2DB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# データの読み込み\n",
        "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()\n",
        "\n",
        "# 特徴エンジニアリング\n",
        "scaler = StandardScaler()\n",
        "train_data_scaled = scaler.fit_transform(train_data)\n",
        "test_data_scaled = scaler.transform(test_data)\n",
        "\n",
        "# モデルの定義\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "model.add(Dense(1))  # 出力層\n",
        "\n",
        "# モデルのコンパイル\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# データの分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_data_scaled, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# モデルの学習\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_val, y_val))\n",
        "\n",
        "# テストデータで予測\n",
        "predictions = model.predict(test_data_scaled)\n",
        "\n",
        "# 予測結果の表示\n",
        "for i in range(len(predictions)):\n",
        "    print(f\"Predicted price for test sample {i+1}: {predictions[i][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9zz_Cvk1-4i",
        "outputId": "19b3c64a-1f53-4aa7-dd02-6e86a24120a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "21/21 [==============================] - 1s 13ms/step - loss: 578.0020 - mae: 21.9834 - val_loss: 399.1860 - val_mae: 18.4708\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 484.7554 - mae: 19.6662 - val_loss: 300.9702 - val_mae: 15.6599\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 335.5976 - mae: 15.6595 - val_loss: 164.1272 - val_mae: 11.0418\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 153.3750 - mae: 9.8638 - val_loss: 58.3031 - val_mae: 6.1396\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 62.4075 - mae: 5.8590 - val_loss: 36.7153 - val_mae: 4.7353\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 42.9342 - mae: 4.6946 - val_loss: 27.6430 - val_mae: 4.0705\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 32.4276 - mae: 4.0021 - val_loss: 24.0610 - val_mae: 3.6930\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 28.0417 - mae: 3.6698 - val_loss: 23.0387 - val_mae: 3.6242\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 25.9049 - mae: 3.5357 - val_loss: 22.3060 - val_mae: 3.5917\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 23.4770 - mae: 3.3487 - val_loss: 21.2027 - val_mae: 3.5192\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 22.0600 - mae: 3.2479 - val_loss: 20.1475 - val_mae: 3.4213\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 20.8972 - mae: 3.1537 - val_loss: 19.3747 - val_mae: 3.3464\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 19.8783 - mae: 3.0873 - val_loss: 18.4593 - val_mae: 3.2480\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 18.8336 - mae: 2.9755 - val_loss: 17.3007 - val_mae: 3.1351\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 18.1218 - mae: 2.9101 - val_loss: 16.4590 - val_mae: 3.0461\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 17.3144 - mae: 2.8778 - val_loss: 16.3655 - val_mae: 3.0206\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 16.5654 - mae: 2.7895 - val_loss: 14.8323 - val_mae: 2.8614\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 16.0819 - mae: 2.7446 - val_loss: 14.8060 - val_mae: 2.8565\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 15.4694 - mae: 2.6541 - val_loss: 14.1117 - val_mae: 2.7838\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 15.6883 - mae: 2.7629 - val_loss: 15.4016 - val_mae: 2.9112\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 14.5278 - mae: 2.6178 - val_loss: 13.4928 - val_mae: 2.7055\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 13.9181 - mae: 2.5441 - val_loss: 13.0635 - val_mae: 2.6468\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 13.6271 - mae: 2.5395 - val_loss: 13.6865 - val_mae: 2.7212\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 13.4380 - mae: 2.4860 - val_loss: 13.0674 - val_mae: 2.6375\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 13.0598 - mae: 2.4782 - val_loss: 12.9986 - val_mae: 2.6200\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 12.6555 - mae: 2.3955 - val_loss: 12.7075 - val_mae: 2.5725\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 12.3425 - mae: 2.3760 - val_loss: 12.5832 - val_mae: 2.5912\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 12.5069 - mae: 2.3562 - val_loss: 12.6821 - val_mae: 2.5958\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 11.8489 - mae: 2.3134 - val_loss: 12.9019 - val_mae: 2.6493\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 11.5972 - mae: 2.3051 - val_loss: 12.6572 - val_mae: 2.6087\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 11.5068 - mae: 2.2785 - val_loss: 12.9778 - val_mae: 2.6385\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 11.1695 - mae: 2.2650 - val_loss: 12.5700 - val_mae: 2.6038\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 11.0566 - mae: 2.2328 - val_loss: 12.1594 - val_mae: 2.5407\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 10.8795 - mae: 2.2408 - val_loss: 12.4095 - val_mae: 2.5827\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 10.6142 - mae: 2.2108 - val_loss: 12.4228 - val_mae: 2.5854\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 10.5359 - mae: 2.2065 - val_loss: 12.4992 - val_mae: 2.5803\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 10.4398 - mae: 2.2045 - val_loss: 12.4510 - val_mae: 2.5937\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 10.4016 - mae: 2.1758 - val_loss: 12.4290 - val_mae: 2.5657\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 10.2271 - mae: 2.1470 - val_loss: 12.8468 - val_mae: 2.6081\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 10.3209 - mae: 2.1952 - val_loss: 12.4466 - val_mae: 2.5936\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 10.0148 - mae: 2.1416 - val_loss: 12.0209 - val_mae: 2.5417\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 9.9502 - mae: 2.1318 - val_loss: 12.6049 - val_mae: 2.5903\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 10.0109 - mae: 2.1194 - val_loss: 12.7476 - val_mae: 2.5880\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 9.7236 - mae: 2.1081 - val_loss: 12.5443 - val_mae: 2.5888\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 9.6287 - mae: 2.0981 - val_loss: 13.2483 - val_mae: 2.7015\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 9.5518 - mae: 2.1124 - val_loss: 13.0009 - val_mae: 2.6402\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 9.3334 - mae: 2.0626 - val_loss: 12.7514 - val_mae: 2.5857\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 9.2313 - mae: 2.0403 - val_loss: 12.8554 - val_mae: 2.6076\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 9.2700 - mae: 2.0589 - val_loss: 13.0664 - val_mae: 2.6049\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 9.1939 - mae: 2.0491 - val_loss: 12.9366 - val_mae: 2.6146\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 9.1649 - mae: 2.0299 - val_loss: 13.9363 - val_mae: 2.6930\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 9.3070 - mae: 2.0922 - val_loss: 13.0771 - val_mae: 2.6003\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 9.0353 - mae: 2.0107 - val_loss: 12.8446 - val_mae: 2.5844\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 9.0452 - mae: 2.0420 - val_loss: 12.9635 - val_mae: 2.5963\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 8.7500 - mae: 1.9952 - val_loss: 13.0761 - val_mae: 2.5934\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 8.6880 - mae: 1.9949 - val_loss: 13.1563 - val_mae: 2.5942\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 8.6257 - mae: 1.9673 - val_loss: 13.7110 - val_mae: 2.6702\n",
            "Epoch 58/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 8.7037 - mae: 2.0079 - val_loss: 13.0701 - val_mae: 2.6017\n",
            "Epoch 59/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 8.4105 - mae: 1.9796 - val_loss: 13.6740 - val_mae: 2.6548\n",
            "Epoch 60/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 8.3735 - mae: 1.9519 - val_loss: 13.7464 - val_mae: 2.6393\n",
            "Epoch 61/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 8.3966 - mae: 1.9727 - val_loss: 13.2478 - val_mae: 2.6117\n",
            "Epoch 62/100\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 8.3044 - mae: 1.9541 - val_loss: 13.3721 - val_mae: 2.6145\n",
            "Epoch 63/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 8.2493 - mae: 1.9372 - val_loss: 13.9133 - val_mae: 2.6409\n",
            "Epoch 64/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 8.2846 - mae: 1.9681 - val_loss: 13.3567 - val_mae: 2.6136\n",
            "Epoch 65/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 8.3255 - mae: 1.9359 - val_loss: 13.6932 - val_mae: 2.6316\n",
            "Epoch 66/100\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 8.0132 - mae: 1.9024 - val_loss: 13.8471 - val_mae: 2.6297\n",
            "Epoch 67/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 8.0457 - mae: 1.9063 - val_loss: 13.5207 - val_mae: 2.6350\n",
            "Epoch 68/100\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 8.1140 - mae: 1.9532 - val_loss: 13.6257 - val_mae: 2.6266\n",
            "Epoch 69/100\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 8.1046 - mae: 1.9142 - val_loss: 14.6541 - val_mae: 2.7550\n",
            "Epoch 70/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 8.2495 - mae: 1.9641 - val_loss: 13.4056 - val_mae: 2.5942\n",
            "Epoch 71/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 7.9984 - mae: 1.8854 - val_loss: 14.7820 - val_mae: 2.7334\n",
            "Epoch 72/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 7.7514 - mae: 1.8913 - val_loss: 13.4202 - val_mae: 2.5865\n",
            "Epoch 73/100\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 7.6880 - mae: 1.8652 - val_loss: 13.8022 - val_mae: 2.6292\n",
            "Epoch 74/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 7.6727 - mae: 1.8653 - val_loss: 14.5165 - val_mae: 2.6974\n",
            "Epoch 75/100\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 7.7495 - mae: 1.9071 - val_loss: 13.3720 - val_mae: 2.5696\n",
            "Epoch 76/100\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 7.5479 - mae: 1.8700 - val_loss: 13.1910 - val_mae: 2.5975\n",
            "Epoch 77/100\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 7.6716 - mae: 1.8538 - val_loss: 14.3337 - val_mae: 2.6897\n",
            "Epoch 78/100\n",
            "21/21 [==============================] - 0s 12ms/step - loss: 7.3997 - mae: 1.8299 - val_loss: 13.8281 - val_mae: 2.6120\n",
            "Epoch 79/100\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 7.3809 - mae: 1.8473 - val_loss: 13.8316 - val_mae: 2.6691\n",
            "Epoch 80/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 7.3412 - mae: 1.8015 - val_loss: 14.4676 - val_mae: 2.6770\n",
            "Epoch 81/100\n",
            "21/21 [==============================] - 0s 11ms/step - loss: 7.9495 - mae: 1.9421 - val_loss: 14.6092 - val_mae: 2.6464\n",
            "Epoch 82/100\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 7.2200 - mae: 1.8175 - val_loss: 14.2865 - val_mae: 2.6320\n",
            "Epoch 83/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 7.2748 - mae: 1.7876 - val_loss: 13.9440 - val_mae: 2.6309\n",
            "Epoch 84/100\n",
            "21/21 [==============================] - 0s 11ms/step - loss: 7.0434 - mae: 1.8031 - val_loss: 13.8460 - val_mae: 2.6240\n",
            "Epoch 85/100\n",
            "21/21 [==============================] - 0s 14ms/step - loss: 7.1842 - mae: 1.8228 - val_loss: 14.0155 - val_mae: 2.6417\n",
            "Epoch 86/100\n",
            "21/21 [==============================] - 0s 13ms/step - loss: 6.9540 - mae: 1.7702 - val_loss: 14.4414 - val_mae: 2.6657\n",
            "Epoch 87/100\n",
            "21/21 [==============================] - 0s 14ms/step - loss: 6.8378 - mae: 1.7519 - val_loss: 14.8992 - val_mae: 2.7481\n",
            "Epoch 88/100\n",
            "21/21 [==============================] - 0s 16ms/step - loss: 6.8610 - mae: 1.7432 - val_loss: 14.2303 - val_mae: 2.6616\n",
            "Epoch 89/100\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 6.8983 - mae: 1.7573 - val_loss: 14.3615 - val_mae: 2.6466\n",
            "Epoch 90/100\n",
            "21/21 [==============================] - 0s 11ms/step - loss: 6.8121 - mae: 1.7251 - val_loss: 15.4060 - val_mae: 2.7319\n",
            "Epoch 91/100\n",
            "21/21 [==============================] - 0s 13ms/step - loss: 7.0003 - mae: 1.7867 - val_loss: 14.2525 - val_mae: 2.6205\n",
            "Epoch 92/100\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 6.9444 - mae: 1.7532 - val_loss: 14.1340 - val_mae: 2.6534\n",
            "Epoch 93/100\n",
            "21/21 [==============================] - 0s 12ms/step - loss: 6.6249 - mae: 1.7156 - val_loss: 14.8006 - val_mae: 2.7057\n",
            "Epoch 94/100\n",
            "21/21 [==============================] - 0s 13ms/step - loss: 6.6197 - mae: 1.7142 - val_loss: 14.1131 - val_mae: 2.6229\n",
            "Epoch 95/100\n",
            "21/21 [==============================] - 0s 14ms/step - loss: 6.5290 - mae: 1.6864 - val_loss: 15.1116 - val_mae: 2.7396\n",
            "Epoch 96/100\n",
            "21/21 [==============================] - 0s 17ms/step - loss: 6.6230 - mae: 1.7417 - val_loss: 14.4862 - val_mae: 2.6547\n",
            "Epoch 97/100\n",
            "21/21 [==============================] - 0s 14ms/step - loss: 6.4647 - mae: 1.6713 - val_loss: 14.9593 - val_mae: 2.7124\n",
            "Epoch 98/100\n",
            "21/21 [==============================] - 0s 13ms/step - loss: 6.5036 - mae: 1.7239 - val_loss: 14.4354 - val_mae: 2.6495\n",
            "Epoch 99/100\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 6.4223 - mae: 1.6858 - val_loss: 15.4082 - val_mae: 2.7473\n",
            "Epoch 100/100\n",
            "21/21 [==============================] - 0s 11ms/step - loss: 6.3896 - mae: 1.6832 - val_loss: 15.2181 - val_mae: 2.6943\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Predicted price for test sample 1: 9.21\n",
            "Predicted price for test sample 2: 19.00\n",
            "Predicted price for test sample 3: 21.57\n",
            "Predicted price for test sample 4: 34.75\n",
            "Predicted price for test sample 5: 25.35\n",
            "Predicted price for test sample 6: 20.63\n",
            "Predicted price for test sample 7: 26.19\n",
            "Predicted price for test sample 8: 21.71\n",
            "Predicted price for test sample 9: 19.09\n",
            "Predicted price for test sample 10: 23.17\n",
            "Predicted price for test sample 11: 17.75\n",
            "Predicted price for test sample 12: 18.82\n",
            "Predicted price for test sample 13: 16.48\n",
            "Predicted price for test sample 14: 42.12\n",
            "Predicted price for test sample 15: 20.21\n",
            "Predicted price for test sample 16: 20.79\n",
            "Predicted price for test sample 17: 26.48\n",
            "Predicted price for test sample 18: 19.34\n",
            "Predicted price for test sample 19: 19.03\n",
            "Predicted price for test sample 20: 26.12\n",
            "Predicted price for test sample 21: 11.59\n",
            "Predicted price for test sample 22: 14.36\n",
            "Predicted price for test sample 23: 20.43\n",
            "Predicted price for test sample 24: 17.97\n",
            "Predicted price for test sample 25: 20.26\n",
            "Predicted price for test sample 26: 27.41\n",
            "Predicted price for test sample 27: 28.92\n",
            "Predicted price for test sample 28: 31.71\n",
            "Predicted price for test sample 29: 11.66\n",
            "Predicted price for test sample 30: 20.86\n",
            "Predicted price for test sample 31: 19.43\n",
            "Predicted price for test sample 32: 15.45\n",
            "Predicted price for test sample 33: 33.87\n",
            "Predicted price for test sample 34: 24.42\n",
            "Predicted price for test sample 35: 17.84\n",
            "Predicted price for test sample 36: 7.52\n",
            "Predicted price for test sample 37: 16.62\n",
            "Predicted price for test sample 38: 18.58\n",
            "Predicted price for test sample 39: 18.62\n",
            "Predicted price for test sample 40: 25.86\n",
            "Predicted price for test sample 41: 31.41\n",
            "Predicted price for test sample 42: 27.56\n",
            "Predicted price for test sample 43: 14.69\n",
            "Predicted price for test sample 44: 42.69\n",
            "Predicted price for test sample 45: 31.94\n",
            "Predicted price for test sample 46: 25.08\n",
            "Predicted price for test sample 47: 27.19\n",
            "Predicted price for test sample 48: 16.26\n",
            "Predicted price for test sample 49: 26.06\n",
            "Predicted price for test sample 50: 22.35\n",
            "Predicted price for test sample 51: 36.77\n",
            "Predicted price for test sample 52: 19.26\n",
            "Predicted price for test sample 53: 12.32\n",
            "Predicted price for test sample 54: 17.14\n",
            "Predicted price for test sample 55: 35.58\n",
            "Predicted price for test sample 56: 27.87\n",
            "Predicted price for test sample 57: 12.18\n",
            "Predicted price for test sample 58: 49.20\n",
            "Predicted price for test sample 59: 35.20\n",
            "Predicted price for test sample 60: 23.63\n",
            "Predicted price for test sample 61: 28.25\n",
            "Predicted price for test sample 62: 18.02\n",
            "Predicted price for test sample 63: 15.59\n",
            "Predicted price for test sample 64: 19.27\n",
            "Predicted price for test sample 65: 23.52\n",
            "Predicted price for test sample 66: 21.32\n",
            "Predicted price for test sample 67: 12.65\n",
            "Predicted price for test sample 68: 22.19\n",
            "Predicted price for test sample 69: 13.88\n",
            "Predicted price for test sample 70: 6.57\n",
            "Predicted price for test sample 71: 25.28\n",
            "Predicted price for test sample 72: 30.41\n",
            "Predicted price for test sample 73: 27.93\n",
            "Predicted price for test sample 74: 13.64\n",
            "Predicted price for test sample 75: 26.13\n",
            "Predicted price for test sample 76: 18.04\n",
            "Predicted price for test sample 77: 19.97\n",
            "Predicted price for test sample 78: 23.39\n",
            "Predicted price for test sample 79: 35.61\n",
            "Predicted price for test sample 80: 11.32\n",
            "Predicted price for test sample 81: 20.31\n",
            "Predicted price for test sample 82: 38.22\n",
            "Predicted price for test sample 83: 17.11\n",
            "Predicted price for test sample 84: 13.91\n",
            "Predicted price for test sample 85: 17.38\n",
            "Predicted price for test sample 86: 17.97\n",
            "Predicted price for test sample 87: 23.85\n",
            "Predicted price for test sample 88: 21.69\n",
            "Predicted price for test sample 89: 22.88\n",
            "Predicted price for test sample 90: 37.61\n",
            "Predicted price for test sample 91: 20.44\n",
            "Predicted price for test sample 92: 20.66\n",
            "Predicted price for test sample 93: 25.01\n",
            "Predicted price for test sample 94: 41.64\n",
            "Predicted price for test sample 95: 36.90\n",
            "Predicted price for test sample 96: 21.37\n",
            "Predicted price for test sample 97: 35.77\n",
            "Predicted price for test sample 98: 52.04\n",
            "Predicted price for test sample 99: 26.59\n",
            "Predicted price for test sample 100: 48.80\n",
            "Predicted price for test sample 101: 30.57\n",
            "Predicted price for test sample 102: 21.38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optuna"
      ],
      "metadata": {
        "id": "Jz5BrPp5dwZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.pip"
      ],
      "metadata": {
        "id": "NhcyY9lzeNUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna tensorflow\n",
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpy_hhY3eR2q",
        "outputId": "a231ad64-3bfc-4200-a69c-f0da426143fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.29)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.3 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## :optuna example"
      ],
      "metadata": {
        "id": "VH8y4OqBeh1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### code"
      ],
      "metadata": {
        "id": "nvjM2lhdw6wO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 合成回帰データセットを生成\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# データをスケーリング\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 目的関数を定義\n",
        "def objective(trial):\n",
        "    # ハイパーパラメータの値を提案\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
        "    n_units = trial.suggest_int('n_units', 32, 128)\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
        "\n",
        "    # 提案されたハイパーパラメータでKerasモデルを構築\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(Dense(n_units, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for _ in range(n_layers - 1):\n",
        "        model.add(Dense(n_units, activation='relu'))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # モデルをコンパイル\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "\n",
        "    # モデルを訓練\n",
        "    model.fit(X_train, y_train, validation_split=0.2, epochs=50, verbose=0)\n",
        "\n",
        "    # テストセットでモデルを評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    # 損失を返す\n",
        "    return loss\n",
        "\n",
        "# Studyオブジェクトを作成し、最小化方向を指定\n",
        "study = optuna.create_study(direction='minimize')\n",
        "\n",
        "# Studyを最適化\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "# 結果を出力\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:')\n",
        "trial = study.best_trial\n",
        "\n",
        "print('  Value: {}'.format(trial.value))\n",
        "print('  Params: ')\n",
        "for key, value in trial.params.items():\n",
        "    print('    {}: {}'.format(key, value))\n",
        "\n",
        "\n",
        "# # モデルを保存\n",
        "# model.save('optimized_regression_model.h5')\n",
        "\n"
      ],
      "metadata": {
        "id": "WtCN8_hi2KME",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "outputId": "73c59db1-b191-48b5-f2c6-1c6be02048d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-01 21:21:30,467] A new study created in memory with name: no-name-91d4f8a2-37b1-4f5f-a494-978cbdcdb7b3\n",
            "<ipython-input-8-ea325fbe88c8>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
            "[I 2024-04-01 21:21:35,805] Trial 0 finished with value: 36478.60546875 and parameters: {'n_layers': 1, 'n_units': 82, 'learning_rate': 0.00018212888032280843}. Best is trial 0 with value: 36478.60546875.\n",
            "[I 2024-04-01 21:21:39,919] Trial 1 finished with value: 1613.10595703125 and parameters: {'n_layers': 1, 'n_units': 53, 'learning_rate': 0.0013627935533831665}. Best is trial 1 with value: 1613.10595703125.\n",
            "[I 2024-04-01 21:21:47,042] Trial 2 finished with value: 54.0294189453125 and parameters: {'n_layers': 2, 'n_units': 108, 'learning_rate': 0.026647599662789928}. Best is trial 2 with value: 54.0294189453125.\n",
            "[I 2024-04-01 21:21:53,238] Trial 3 finished with value: 6655.318359375 and parameters: {'n_layers': 2, 'n_units': 89, 'learning_rate': 0.0001726143140898167}. Best is trial 2 with value: 54.0294189453125.\n",
            "[I 2024-04-01 21:21:59,184] Trial 4 finished with value: 38610.5859375 and parameters: {'n_layers': 1, 'n_units': 81, 'learning_rate': 3.476738549250522e-05}. Best is trial 2 with value: 54.0294189453125.\n",
            "[I 2024-04-01 21:22:05,453] Trial 5 finished with value: 441.53070068359375 and parameters: {'n_layers': 3, 'n_units': 102, 'learning_rate': 0.00014845415609825266}. Best is trial 2 with value: 54.0294189453125.\n",
            "[I 2024-04-01 21:22:11,849] Trial 6 finished with value: 86.25220489501953 and parameters: {'n_layers': 2, 'n_units': 96, 'learning_rate': 0.0013801946904217343}. Best is trial 2 with value: 54.0294189453125.\n",
            "[I 2024-04-01 21:22:16,678] Trial 7 finished with value: 38367.734375 and parameters: {'n_layers': 1, 'n_units': 64, 'learning_rate': 6.095911107893006e-05}. Best is trial 2 with value: 54.0294189453125.\n",
            "[I 2024-04-01 21:22:22,724] Trial 8 finished with value: 34224.00390625 and parameters: {'n_layers': 2, 'n_units': 67, 'learning_rate': 9.08942030746521e-05}. Best is trial 2 with value: 54.0294189453125.\n",
            "[I 2024-04-01 21:22:26,970] Trial 9 finished with value: 82.17162322998047 and parameters: {'n_layers': 2, 'n_units': 32, 'learning_rate': 0.004540612467980775}. Best is trial 2 with value: 54.0294189453125.\n",
            "[I 2024-04-01 21:22:33,262] Trial 10 finished with value: 30.813617706298828 and parameters: {'n_layers': 3, 'n_units': 127, 'learning_rate': 0.08334032121924854}. Best is trial 10 with value: 30.813617706298828.\n",
            "[I 2024-04-01 21:22:38,331] Trial 11 finished with value: 62.52128982543945 and parameters: {'n_layers': 3, 'n_units': 122, 'learning_rate': 0.07960241520631386}. Best is trial 10 with value: 30.813617706298828.\n",
            "[I 2024-04-01 21:22:43,171] Trial 12 finished with value: 26.751893997192383 and parameters: {'n_layers': 3, 'n_units': 128, 'learning_rate': 0.08517677125452669}. Best is trial 12 with value: 26.751893997192383.\n",
            "[I 2024-04-01 21:22:49,602] Trial 13 finished with value: 201.59591674804688 and parameters: {'n_layers': 3, 'n_units': 125, 'learning_rate': 0.09480172014909673}. Best is trial 12 with value: 26.751893997192383.\n",
            "[I 2024-04-01 21:22:54,530] Trial 14 finished with value: 27.698640823364258 and parameters: {'n_layers': 3, 'n_units': 115, 'learning_rate': 0.012798689470748328}. Best is trial 12 with value: 26.751893997192383.\n",
            "[I 2024-04-01 21:23:00,725] Trial 15 finished with value: 43.42918014526367 and parameters: {'n_layers': 3, 'n_units': 113, 'learning_rate': 0.012369284053274778}. Best is trial 12 with value: 26.751893997192383.\n",
            "[I 2024-04-01 21:23:06,930] Trial 16 finished with value: 35.92045974731445 and parameters: {'n_layers': 3, 'n_units': 109, 'learning_rate': 0.011936484366311714}. Best is trial 12 with value: 26.751893997192383.\n",
            "[I 2024-04-01 21:23:13,136] Trial 17 finished with value: 69.18685913085938 and parameters: {'n_layers': 3, 'n_units': 116, 'learning_rate': 0.0039093612081899124}. Best is trial 12 with value: 26.751893997192383.\n",
            "[I 2024-04-01 21:23:18,526] Trial 18 finished with value: 11.832169532775879 and parameters: {'n_layers': 3, 'n_units': 96, 'learning_rate': 0.025769125750312247}. Best is trial 18 with value: 11.832169532775879.\n",
            "[I 2024-04-01 21:23:24,746] Trial 19 finished with value: 8.756564140319824 and parameters: {'n_layers': 3, 'n_units': 96, 'learning_rate': 0.036609891284943595}. Best is trial 19 with value: 8.756564140319824.\n",
            "[I 2024-04-01 21:23:29,113] Trial 20 finished with value: 188.56263732910156 and parameters: {'n_layers': 2, 'n_units': 96, 'learning_rate': 0.0004199792886522151}. Best is trial 19 with value: 8.756564140319824.\n",
            "[I 2024-04-01 21:23:34,332] Trial 21 finished with value: 30.969470977783203 and parameters: {'n_layers': 3, 'n_units': 70, 'learning_rate': 0.0317535967068813}. Best is trial 19 with value: 8.756564140319824.\n",
            "[I 2024-04-01 21:23:39,157] Trial 22 finished with value: 38495.1953125 and parameters: {'n_layers': 3, 'n_units': 92, 'learning_rate': 1.3412165894102466e-05}. Best is trial 19 with value: 8.756564140319824.\n",
            "[I 2024-04-01 21:23:44,127] Trial 23 finished with value: 39.18966293334961 and parameters: {'n_layers': 3, 'n_units': 103, 'learning_rate': 0.02587185201060558}. Best is trial 19 with value: 8.756564140319824.\n",
            "[I 2024-04-01 21:23:50,061] Trial 24 finished with value: 56.139320373535156 and parameters: {'n_layers': 3, 'n_units': 74, 'learning_rate': 0.004049797579175035}. Best is trial 19 with value: 8.756564140319824.\n",
            "[I 2024-04-01 21:23:57,830] Trial 25 finished with value: 195.02899169921875 and parameters: {'n_layers': 2, 'n_units': 47, 'learning_rate': 0.041368017192747374}. Best is trial 19 with value: 8.756564140319824.\n",
            "[I 2024-04-01 21:24:04,471] Trial 26 finished with value: 46.984779357910156 and parameters: {'n_layers': 3, 'n_units': 87, 'learning_rate': 0.0077623817820099035}. Best is trial 19 with value: 8.756564140319824.\n",
            "[I 2024-04-01 21:24:10,899] Trial 27 finished with value: 145.41799926757812 and parameters: {'n_layers': 3, 'n_units': 100, 'learning_rate': 0.049697429196936725}. Best is trial 19 with value: 8.756564140319824.\n",
            "[I 2024-04-01 21:24:16,492] Trial 28 finished with value: 49.08823776245117 and parameters: {'n_layers': 2, 'n_units': 120, 'learning_rate': 0.017326415794040876}. Best is trial 19 with value: 8.756564140319824.\n",
            "[I 2024-04-01 21:24:22,453] Trial 29 finished with value: 324.0056457519531 and parameters: {'n_layers': 3, 'n_units': 83, 'learning_rate': 0.047893098414511046}. Best is trial 19 with value: 8.756564140319824.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 30\n",
            "Best trial:\n",
            "  Value: 8.756564140319824\n",
            "  Params: \n",
            "    n_layers: 3\n",
            "    n_units: 96\n",
            "    learning_rate: 0.036609891284943595\n",
            "Model summary\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ea325fbe88c8>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model summary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# モデルを保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'optimized_regression_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# 最適化されたモデルの詳細を表示\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 各層を最適化"
      ],
      "metadata": {
        "id": "CrxXlkQry1z3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " #### ⇒ トライアルエラーなし"
      ],
      "metadata": {
        "id": "p3qR83hIz4uw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### code"
      ],
      "metadata": {
        "id": "2rgIgDhOy5SM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 合成回帰データセットを生成\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# データをスケーリング\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 目的関数を定義\n",
        "def objective(trial):\n",
        "    # ハイパーパラメータの値を提案\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
        "    n_units_per_layer = [trial.suggest_int(f'n_units_layer{i}', 32, 128) for i in range(n_layers)]\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
        "\n",
        "    # 提案されたハイパーパラメータでKerasモデルを構築\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(Dense(n_units_per_layer[0], activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for units in n_units_per_layer[1:]:\n",
        "        model.add(Dense(units, activation='relu'))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # モデルをコンパイル\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "\n",
        "    # モデルを訓練\n",
        "    model.fit(X_train, y_train, validation_split=0.2, epochs=50, verbose=0)\n",
        "\n",
        "    # テストセットでモデルを評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    # 損失を返す\n",
        "    return loss\n",
        "\n",
        "# Studyオブジェクトを作成し、最小化方向を指定\n",
        "study = optuna.create_study(direction='minimize')\n",
        "\n",
        "# Studyを最適化\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "# 結果を出力\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:')\n",
        "trial = study.best_trial\n",
        "print('  Value: {}'.format(trial.value))\n",
        "print('  Params: ')\n",
        "for key, value in trial.params.items():\n",
        "    print('    {}: {}'.format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWqQ4DkdkEOi",
        "outputId": "489e5c68-4c5d-4240-c1e7-0f594d2f2584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-03 21:10:13,924] A new study created in memory with name: no-name-5eff137b-e9d6-4340-833f-c230f9fac97f\n",
            "<ipython-input-2-e2de25f02db3>:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
            "[I 2024-04-03 21:10:20,042] Trial 0 finished with value: 38733.63671875 and parameters: {'n_layers': 1, 'n_units_layer0': 42, 'learning_rate': 1.3542432485941736e-05}. Best is trial 0 with value: 38733.63671875.\n",
            "[I 2024-04-03 21:10:26,260] Trial 1 finished with value: 64.08811950683594 and parameters: {'n_layers': 3, 'n_units_layer0': 68, 'n_units_layer1': 118, 'n_units_layer2': 120, 'learning_rate': 0.03019929299557947}. Best is trial 1 with value: 64.08811950683594.\n",
            "[I 2024-04-03 21:10:31,741] Trial 2 finished with value: 81.33654022216797 and parameters: {'n_layers': 2, 'n_units_layer0': 122, 'n_units_layer1': 44, 'learning_rate': 0.0016108879694893678}. Best is trial 1 with value: 64.08811950683594.\n",
            "[I 2024-04-03 21:10:37,753] Trial 3 finished with value: 54.487754821777344 and parameters: {'n_layers': 2, 'n_units_layer0': 92, 'n_units_layer1': 128, 'learning_rate': 0.0023840957874369357}. Best is trial 3 with value: 54.487754821777344.\n",
            "[I 2024-04-03 21:10:42,779] Trial 4 finished with value: 14.861751556396484 and parameters: {'n_layers': 2, 'n_units_layer0': 100, 'n_units_layer1': 72, 'learning_rate': 0.026292721517134215}. Best is trial 4 with value: 14.861751556396484.\n",
            "[I 2024-04-03 21:10:48,950] Trial 5 finished with value: 5.409884452819824 and parameters: {'n_layers': 2, 'n_units_layer0': 41, 'n_units_layer1': 38, 'learning_rate': 0.076758806009666}. Best is trial 5 with value: 5.409884452819824.\n",
            "[I 2024-04-03 21:10:55,832] Trial 6 finished with value: 28824.01171875 and parameters: {'n_layers': 1, 'n_units_layer0': 85, 'learning_rate': 0.00035023716374810317}. Best is trial 5 with value: 5.409884452819824.\n",
            "[I 2024-04-03 21:11:02,806] Trial 7 finished with value: 25.30728530883789 and parameters: {'n_layers': 3, 'n_units_layer0': 61, 'n_units_layer1': 34, 'n_units_layer2': 61, 'learning_rate': 0.031042871973652963}. Best is trial 5 with value: 5.409884452819824.\n",
            "[I 2024-04-03 21:11:10,590] Trial 8 finished with value: 84.29804992675781 and parameters: {'n_layers': 3, 'n_units_layer0': 51, 'n_units_layer1': 85, 'n_units_layer2': 122, 'learning_rate': 0.005122381689074713}. Best is trial 5 with value: 5.409884452819824.\n",
            "[I 2024-04-03 21:11:16,571] Trial 9 finished with value: 289.12139892578125 and parameters: {'n_layers': 1, 'n_units_layer0': 84, 'learning_rate': 0.003703976384711873}. Best is trial 5 with value: 5.409884452819824.\n",
            "[I 2024-04-03 21:11:21,998] Trial 10 finished with value: 21642.39453125 and parameters: {'n_layers': 2, 'n_units_layer0': 34, 'n_units_layer1': 64, 'learning_rate': 0.00019064179629851632}. Best is trial 5 with value: 5.409884452819824.\n",
            "[I 2024-04-03 21:11:26,602] Trial 11 finished with value: 12.899496078491211 and parameters: {'n_layers': 2, 'n_units_layer0': 110, 'n_units_layer1': 79, 'learning_rate': 0.09968686146539692}. Best is trial 5 with value: 5.409884452819824.\n",
            "[I 2024-04-03 21:11:31,882] Trial 12 finished with value: 7.427377700805664 and parameters: {'n_layers': 2, 'n_units_layer0': 114, 'n_units_layer1': 97, 'learning_rate': 0.07669698820840355}. Best is trial 5 with value: 5.409884452819824.\n",
            "[I 2024-04-03 21:11:37,903] Trial 13 finished with value: 397.00897216796875 and parameters: {'n_layers': 2, 'n_units_layer0': 128, 'n_units_layer1': 98, 'learning_rate': 0.07838289679539491}. Best is trial 5 with value: 5.409884452819824.\n",
            "[I 2024-04-03 21:11:43,869] Trial 14 finished with value: 35.330787658691406 and parameters: {'n_layers': 3, 'n_units_layer0': 68, 'n_units_layer1': 103, 'n_units_layer2': 33, 'learning_rate': 0.010370638107733374}. Best is trial 5 with value: 5.409884452819824.\n",
            "[I 2024-04-03 21:11:49,893] Trial 15 finished with value: 19494.619140625 and parameters: {'n_layers': 1, 'n_units_layer0': 105, 'learning_rate': 0.00046521842615526303}. Best is trial 5 with value: 5.409884452819824.\n",
            "[I 2024-04-03 21:11:54,223] Trial 16 finished with value: 37528.890625 and parameters: {'n_layers': 2, 'n_units_layer0': 55, 'n_units_layer1': 58, 'learning_rate': 6.323094328652057e-05}. Best is trial 5 with value: 5.409884452819824.\n",
            "[I 2024-04-03 21:12:00,793] Trial 17 finished with value: 36.40834045410156 and parameters: {'n_layers': 3, 'n_units_layer0': 117, 'n_units_layer1': 97, 'n_units_layer2': 86, 'learning_rate': 0.013735560336372635}. Best is trial 5 with value: 5.409884452819824.\n",
            "[I 2024-04-03 21:12:07,270] Trial 18 finished with value: 4.805978775024414 and parameters: {'n_layers': 1, 'n_units_layer0': 73, 'learning_rate': 0.057697414836332166}. Best is trial 18 with value: 4.805978775024414.\n",
            "[I 2024-04-03 21:12:13,397] Trial 19 finished with value: 49.58293533325195 and parameters: {'n_layers': 1, 'n_units_layer0': 74, 'learning_rate': 0.008769073388907271}. Best is trial 18 with value: 4.805978775024414.\n",
            "[I 2024-04-03 21:12:19,338] Trial 20 finished with value: 9454.009765625 and parameters: {'n_layers': 1, 'n_units_layer0': 41, 'learning_rate': 0.001006711599500571}. Best is trial 18 with value: 4.805978775024414.\n",
            "[I 2024-04-03 21:12:26,478] Trial 21 finished with value: 10.238384246826172 and parameters: {'n_layers': 2, 'n_units_layer0': 91, 'n_units_layer1': 47, 'learning_rate': 0.0591316078405287}. Best is trial 18 with value: 4.805978775024414.\n",
            "[I 2024-04-03 21:12:34,748] Trial 22 finished with value: 7.0693511962890625 and parameters: {'n_layers': 1, 'n_units_layer0': 74, 'learning_rate': 0.04125469536056789}. Best is trial 18 with value: 4.805978775024414.\n",
            "[I 2024-04-03 21:12:40,677] Trial 23 finished with value: 7.506608963012695 and parameters: {'n_layers': 1, 'n_units_layer0': 77, 'learning_rate': 0.020247971050977358}. Best is trial 18 with value: 4.805978775024414.\n",
            "[I 2024-04-03 21:12:46,640] Trial 24 finished with value: 5.792586803436279 and parameters: {'n_layers': 1, 'n_units_layer0': 59, 'learning_rate': 0.03661585225180384}. Best is trial 18 with value: 4.805978775024414.\n",
            "[I 2024-04-03 21:12:50,632] Trial 25 finished with value: 123.40547943115234 and parameters: {'n_layers': 1, 'n_units_layer0': 51, 'learning_rate': 0.007499513456743903}. Best is trial 18 with value: 4.805978775024414.\n",
            "[I 2024-04-03 21:12:56,522] Trial 26 finished with value: 15.520111083984375 and parameters: {'n_layers': 1, 'n_units_layer0': 60, 'learning_rate': 0.014492451797584401}. Best is trial 18 with value: 4.805978775024414.\n",
            "[I 2024-04-03 21:13:01,334] Trial 27 finished with value: 6.845058441162109 and parameters: {'n_layers': 1, 'n_units_layer0': 32, 'learning_rate': 0.04320004993316064}. Best is trial 18 with value: 4.805978775024414.\n",
            "[I 2024-04-03 21:13:07,216] Trial 28 finished with value: 373.9682922363281 and parameters: {'n_layers': 1, 'n_units_layer0': 44, 'learning_rate': 0.004598835951492842}. Best is trial 18 with value: 4.805978775024414.\n",
            "[I 2024-04-03 21:13:12,087] Trial 29 finished with value: 15.35357666015625 and parameters: {'n_layers': 1, 'n_units_layer0': 42, 'learning_rate': 0.01812116530773697}. Best is trial 18 with value: 4.805978775024414.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 30\n",
            "Best trial:\n",
            "  Value: 4.805978775024414\n",
            "  Params: \n",
            "    n_layers: 1\n",
            "    n_units_layer0: 73\n",
            "    learning_rate: 0.057697414836332166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 最適化パラメータ増加(各層最適化)"
      ],
      "metadata": {
        "id": "mX6o8oM40Tq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# データセットの準備（ここでは合成データセットを使用）\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# データのスケーリング\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 目的関数の定義\n",
        "def objective(trial):\n",
        "    # オプティマイザの選択\n",
        "    # optimizer_options = ['Adam', 'SGD', 'RMSprop']\n",
        "    # optimizer_name = trial.suggest_categorical('optimizer', optimizer_options)\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "\n",
        "    # モデルの構築\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.Input(shape=(X_train.shape[1],)))\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 5)\n",
        "    for i in range(n_layers):\n",
        "        num_hidden = trial.suggest_int('n_units_l{}'.format(i), 4, 128, log=True)\n",
        "        model.add(Dense(num_hidden, activation='relu'))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # オプティマイザの設定\n",
        "    # if optimizer_name == 'Adam':\n",
        "    #     optimizer = Adam(lr=lr)\n",
        "    # elif optimizer_name == 'SGD':\n",
        "    #     optimizer = SGD(lr=lr)\n",
        "    # else:\n",
        "    #     optimizer = RMSprop(lr=lr)\n",
        "\n",
        "    # モデルのコンパイル\n",
        "    # model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='mean_squared_error')\n",
        "\n",
        "    # モデルの訓練\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return loss\n",
        "\n",
        "# Studyオブジェクトの作成\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "# 最適化されたハイパーパラメータの出力\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:')\n",
        "trial = study.best_trial\n",
        "print('Value: {}'.format(trial.value))\n",
        "print('Params: ')\n",
        "for key, value in trial.params.items():\n",
        "    print('    {}: {}'.format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X9pL4_L0XrZ",
        "outputId": "abe6588b-cdfb-4e5a-fb12-0864c2580dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-03 21:18:37,669] A new study created in memory with name: no-name-1acd171a-927e-49b9-8774-cd955fd5c651\n",
            "[I 2024-04-03 21:18:56,123] Trial 0 finished with value: 38683.11328125 and parameters: {'lr': 1.8107443832589656e-05, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 8, 'n_units_l2': 7, 'n_units_l3': 67}. Best is trial 0 with value: 38683.11328125.\n",
            "[I 2024-04-03 21:19:05,093] Trial 1 finished with value: 338.6212463378906 and parameters: {'lr': 0.0022848219721061614, 'n_layers': 1, 'n_units_l0': 29}. Best is trial 1 with value: 338.6212463378906.\n",
            "[I 2024-04-03 21:19:14,720] Trial 2 finished with value: 14110.8515625 and parameters: {'lr': 7.338369732511298e-05, 'n_layers': 4, 'n_units_l0': 13, 'n_units_l1': 19, 'n_units_l2': 54, 'n_units_l3': 6}. Best is trial 1 with value: 338.6212463378906.\n",
            "[I 2024-04-03 21:19:37,759] Trial 3 finished with value: 2586.99267578125 and parameters: {'lr': 9.608392140469601e-05, 'n_layers': 5, 'n_units_l0': 10, 'n_units_l1': 91, 'n_units_l2': 12, 'n_units_l3': 12, 'n_units_l4': 125}. Best is trial 1 with value: 338.6212463378906.\n",
            "[I 2024-04-03 21:19:48,241] Trial 4 finished with value: 25728.466796875 and parameters: {'lr': 0.00015024190988874482, 'n_layers': 2, 'n_units_l0': 10, 'n_units_l1': 28}. Best is trial 1 with value: 338.6212463378906.\n",
            "[I 2024-04-03 21:19:58,805] Trial 5 finished with value: 7.923958778381348 and parameters: {'lr': 0.02336197779894699, 'n_layers': 4, 'n_units_l0': 55, 'n_units_l1': 30, 'n_units_l2': 8, 'n_units_l3': 7}. Best is trial 5 with value: 7.923958778381348.\n",
            "[I 2024-04-03 21:20:09,680] Trial 6 finished with value: 153.43031311035156 and parameters: {'lr': 0.0034996676809645267, 'n_layers': 1, 'n_units_l0': 28}. Best is trial 5 with value: 7.923958778381348.\n",
            "[I 2024-04-03 21:20:21,289] Trial 7 finished with value: 37758.109375 and parameters: {'lr': 3.5625055275397275e-05, 'n_layers': 5, 'n_units_l0': 23, 'n_units_l1': 10, 'n_units_l2': 4, 'n_units_l3': 18, 'n_units_l4': 94}. Best is trial 5 with value: 7.923958778381348.\n",
            "[I 2024-04-03 21:20:32,962] Trial 8 finished with value: 72.29058074951172 and parameters: {'lr': 0.0003901690279353939, 'n_layers': 5, 'n_units_l0': 109, 'n_units_l1': 8, 'n_units_l2': 9, 'n_units_l3': 80, 'n_units_l4': 8}. Best is trial 5 with value: 7.923958778381348.\n",
            "[I 2024-04-03 21:20:43,940] Trial 9 finished with value: 3167.51708984375 and parameters: {'lr': 0.002076468488557033, 'n_layers': 1, 'n_units_l0': 4}. Best is trial 5 with value: 7.923958778381348.\n",
            "[I 2024-04-03 21:20:53,346] Trial 10 finished with value: 18.331247329711914 and parameters: {'lr': 0.07139608987377197, 'n_layers': 3, 'n_units_l0': 88, 'n_units_l1': 56, 'n_units_l2': 36}. Best is trial 5 with value: 7.923958778381348.\n",
            "[I 2024-04-03 21:21:04,980] Trial 11 finished with value: 23.64929962158203 and parameters: {'lr': 0.09640164578549865, 'n_layers': 3, 'n_units_l0': 92, 'n_units_l1': 63, 'n_units_l2': 37}. Best is trial 5 with value: 7.923958778381348.\n",
            "[I 2024-04-03 21:21:16,406] Trial 12 finished with value: 15.558250427246094 and parameters: {'lr': 0.04536400342999742, 'n_layers': 3, 'n_units_l0': 58, 'n_units_l1': 38, 'n_units_l2': 119}. Best is trial 5 with value: 7.923958778381348.\n",
            "[I 2024-04-03 21:21:27,841] Trial 13 finished with value: 9.708740234375 and parameters: {'lr': 0.016821825037128844, 'n_layers': 4, 'n_units_l0': 53, 'n_units_l1': 29, 'n_units_l2': 115, 'n_units_l3': 4}. Best is trial 5 with value: 7.923958778381348.\n",
            "[I 2024-04-03 21:21:39,257] Trial 14 finished with value: 7.013655185699463 and parameters: {'lr': 0.013398323198560191, 'n_layers': 4, 'n_units_l0': 45, 'n_units_l1': 17, 'n_units_l2': 127, 'n_units_l3': 4}. Best is trial 14 with value: 7.013655185699463.\n",
            "[I 2024-04-03 21:21:50,687] Trial 15 finished with value: 9.183675765991211 and parameters: {'lr': 0.011942496478826309, 'n_layers': 4, 'n_units_l0': 44, 'n_units_l1': 16, 'n_units_l2': 18, 'n_units_l3': 8}. Best is trial 14 with value: 7.013655185699463.\n",
            "[I 2024-04-03 21:22:00,098] Trial 16 finished with value: 8.98854923248291 and parameters: {'lr': 0.008997549104527732, 'n_layers': 2, 'n_units_l0': 59, 'n_units_l1': 5}. Best is trial 14 with value: 7.013655185699463.\n",
            "[I 2024-04-03 21:22:10,600] Trial 17 finished with value: 11.334996223449707 and parameters: {'lr': 0.0194258544274944, 'n_layers': 4, 'n_units_l0': 127, 'n_units_l1': 14, 'n_units_l2': 4, 'n_units_l3': 4}. Best is trial 14 with value: 7.013655185699463.\n",
            "[I 2024-04-03 21:22:19,164] Trial 18 finished with value: 17852.892578125 and parameters: {'lr': 0.0007788194131868326, 'n_layers': 2, 'n_units_l0': 35, 'n_units_l1': 4}. Best is trial 14 with value: 7.013655185699463.\n",
            "[I 2024-04-03 21:22:41,423] Trial 19 finished with value: 16270.2138671875 and parameters: {'lr': 0.00543636331043804, 'n_layers': 5, 'n_units_l0': 15, 'n_units_l1': 43, 'n_units_l2': 18, 'n_units_l3': 35, 'n_units_l4': 4}. Best is trial 14 with value: 7.013655185699463.\n",
            "[I 2024-04-03 21:22:54,973] Trial 20 finished with value: 8.566184997558594 and parameters: {'lr': 0.030077778283263155, 'n_layers': 4, 'n_units_l0': 79, 'n_units_l1': 118, 'n_units_l2': 49, 'n_units_l3': 9}. Best is trial 14 with value: 7.013655185699463.\n",
            "[I 2024-04-03 21:23:17,218] Trial 21 finished with value: 7.304346084594727 and parameters: {'lr': 0.03716916100521272, 'n_layers': 4, 'n_units_l0': 71, 'n_units_l1': 121, 'n_units_l2': 67, 'n_units_l3': 9}. Best is trial 14 with value: 7.013655185699463.\n",
            "[I 2024-04-03 21:23:28,343] Trial 22 finished with value: 58.008155822753906 and parameters: {'lr': 0.029898341815904474, 'n_layers': 3, 'n_units_l0': 68, 'n_units_l1': 24, 'n_units_l2': 74}. Best is trial 14 with value: 7.013655185699463.\n",
            "[I 2024-04-03 21:23:50,097] Trial 23 finished with value: 37.10688400268555 and parameters: {'lr': 0.00643164485146078, 'n_layers': 4, 'n_units_l0': 39, 'n_units_l1': 72, 'n_units_l2': 80, 'n_units_l3': 6}. Best is trial 14 with value: 7.013655185699463.\n",
            "[I 2024-04-03 21:24:01,486] Trial 24 finished with value: 39.4297981262207 and parameters: {'lr': 0.05097471772193478, 'n_layers': 3, 'n_units_l0': 50, 'n_units_l1': 12, 'n_units_l2': 29}. Best is trial 14 with value: 7.013655185699463.\n",
            "[I 2024-04-03 21:24:12,640] Trial 25 finished with value: 4.1024980545043945 and parameters: {'lr': 0.01999771053782922, 'n_layers': 5, 'n_units_l0': 19, 'n_units_l1': 43, 'n_units_l2': 79, 'n_units_l3': 16, 'n_units_l4': 26}. Best is trial 25 with value: 4.1024980545043945.\n",
            "[I 2024-04-03 21:24:24,161] Trial 26 finished with value: 107.51412963867188 and parameters: {'lr': 0.0009423986959101682, 'n_layers': 5, 'n_units_l0': 19, 'n_units_l1': 122, 'n_units_l2': 79, 'n_units_l3': 19, 'n_units_l4': 26}. Best is trial 25 with value: 4.1024980545043945.\n",
            "[I 2024-04-03 21:24:35,483] Trial 27 finished with value: 173.02923583984375 and parameters: {'lr': 0.010602481782974682, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 46, 'n_units_l2': 124, 'n_units_l3': 31, 'n_units_l4': 25}. Best is trial 25 with value: 4.1024980545043945.\n",
            "[I 2024-04-03 21:24:47,094] Trial 28 finished with value: 43.60625076293945 and parameters: {'lr': 0.003140739172566395, 'n_layers': 5, 'n_units_l0': 18, 'n_units_l1': 79, 'n_units_l2': 58, 'n_units_l3': 13, 'n_units_l4': 47}. Best is trial 25 with value: 4.1024980545043945.\n",
            "[I 2024-04-03 21:24:58,740] Trial 29 finished with value: 8.81119155883789 and parameters: {'lr': 0.046347971720498614, 'n_layers': 4, 'n_units_l0': 28, 'n_units_l1': 18, 'n_units_l2': 90, 'n_units_l3': 12}. Best is trial 25 with value: 4.1024980545043945.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 30\n",
            "Best trial:\n",
            "Value: 4.1024980545043945\n",
            "Params: \n",
            "    lr: 0.01999771053782922\n",
            "    n_layers: 5\n",
            "    n_units_l0: 19\n",
            "    n_units_l1: 43\n",
            "    n_units_l2: 79\n",
            "    n_units_l3: 16\n",
            "    n_units_l4: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 最適化パラメータ増加(各層最適化+オプティマイザ選択)\n"
      ],
      "metadata": {
        "id": "94HxqHwMsIIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  ⇒ Trial error発生"
      ],
      "metadata": {
        "id": "zck2PC060MSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### code"
      ],
      "metadata": {
        "id": "qB4j8-n9saU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# データセットの準備（ここでは合成データセットを使用）\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# データのスケーリング\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 目的関数の定義\n",
        "def objective(trial):\n",
        "    # オプティマイザの選択\n",
        "    optimizer_options = ['Adam', 'SGD', 'RMSprop']\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', optimizer_options)\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "\n",
        "    # モデルの構築\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.Input(shape=(X_train.shape[1],)))\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 5)\n",
        "    for i in range(n_layers):\n",
        "        num_hidden = trial.suggest_int('n_units_l{}'.format(i), 4, 128, log=True)\n",
        "        model.add(Dense(num_hidden, activation='relu'))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # オプティマイザの設定\n",
        "    if optimizer_name == 'Adam':\n",
        "        optimizer = Adam(lr=lr)\n",
        "    elif optimizer_name == 'SGD':\n",
        "        optimizer = SGD(lr=lr)\n",
        "    else:\n",
        "        optimizer = RMSprop(lr=lr)\n",
        "\n",
        "    # モデルのコンパイル\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # モデルの訓練\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return loss\n",
        "\n",
        "# Studyオブジェクトの作成\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=1000)\n",
        "\n",
        "# 最適化されたハイパーパラメータの出力\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:')\n",
        "trial = study.best_trial\n",
        "print('Value: {}'.format(trial.value))\n",
        "print('Params: ')\n",
        "for key, value in trial.params.items():\n",
        "    print('    {}: {}'.format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDlZpjBcsPWw",
        "outputId": "05d5803f-e7de-4f6f-fcf3-fd229099aab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-03 21:25:58,621] A new study created in memory with name: no-name-8faddc5c-0452-46df-9575-b7a03a369be9\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:26:08,692] Trial 0 finished with value: 24.583168029785156 and parameters: {'optimizer': 'RMSprop', 'lr': 7.726432658063651e-05, 'n_layers': 2, 'n_units_l0': 52, 'n_units_l1': 4}. Best is trial 0 with value: 24.583168029785156.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:26:18,175] Trial 1 failed with parameters: {'optimizer': 'SGD', 'lr': 0.025963533703286915, 'n_layers': 4, 'n_units_l0': 5, 'n_units_l1': 73, 'n_units_l2': 87, 'n_units_l3': 24} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:26:18,177] Trial 1 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:26:29,109] Trial 2 finished with value: 387.6996154785156 and parameters: {'optimizer': 'Adam', 'lr': 0.06928211251272774, 'n_layers': 1, 'n_units_l0': 106}. Best is trial 0 with value: 24.583168029785156.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:26:38,765] Trial 3 finished with value: 206.1129150390625 and parameters: {'optimizer': 'Adam', 'lr': 1.4253791904788047e-05, 'n_layers': 2, 'n_units_l0': 17, 'n_units_l1': 15}. Best is trial 0 with value: 24.583168029785156.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:26:48,843] Trial 4 finished with value: 63.2545280456543 and parameters: {'optimizer': 'Adam', 'lr': 5.7319503804517417e-05, 'n_layers': 3, 'n_units_l0': 58, 'n_units_l1': 100, 'n_units_l2': 36}. Best is trial 0 with value: 24.583168029785156.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:26:57,304] Trial 5 finished with value: 125.30561828613281 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0033821790397994284, 'n_layers': 2, 'n_units_l0': 24, 'n_units_l1': 5}. Best is trial 0 with value: 24.583168029785156.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:27:09,183] Trial 6 finished with value: 96.6014175415039 and parameters: {'optimizer': 'Adam', 'lr': 0.03320550543669773, 'n_layers': 4, 'n_units_l0': 97, 'n_units_l1': 112, 'n_units_l2': 109, 'n_units_l3': 38}. Best is trial 0 with value: 24.583168029785156.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:27:20,257] Trial 7 failed with parameters: {'optimizer': 'SGD', 'lr': 0.023081590734017114, 'n_layers': 3, 'n_units_l0': 91, 'n_units_l1': 40, 'n_units_l2': 20} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:27:20,259] Trial 7 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:27:31,623] Trial 8 finished with value: 87.41566467285156 and parameters: {'optimizer': 'Adam', 'lr': 0.0016841644486562518, 'n_layers': 3, 'n_units_l0': 27, 'n_units_l1': 26, 'n_units_l2': 9}. Best is trial 0 with value: 24.583168029785156.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:27:42,535] Trial 9 failed with parameters: {'optimizer': 'SGD', 'lr': 1.732512226880684e-05, 'n_layers': 3, 'n_units_l0': 106, 'n_units_l1': 20, 'n_units_l2': 14} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:27:42,537] Trial 9 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:27:51,370] Trial 10 finished with value: 407.2254943847656 and parameters: {'optimizer': 'RMSprop', 'lr': 0.02726887751840681, 'n_layers': 2, 'n_units_l0': 7, 'n_units_l1': 7}. Best is trial 0 with value: 24.583168029785156.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:28:02,754] Trial 11 finished with value: 3.4071731567382812 and parameters: {'optimizer': 'Adam', 'lr': 0.00029466688682049775, 'n_layers': 4, 'n_units_l0': 5, 'n_units_l1': 77, 'n_units_l2': 7, 'n_units_l3': 63}. Best is trial 11 with value: 3.4071731567382812.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:28:15,070] Trial 12 finished with value: 70.4570083618164 and parameters: {'optimizer': 'Adam', 'lr': 0.04965230109089195, 'n_layers': 3, 'n_units_l0': 17, 'n_units_l1': 31, 'n_units_l2': 33}. Best is trial 11 with value: 3.4071731567382812.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:28:25,046] Trial 13 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0002453595437700741, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 53, 'n_units_l2': 4, 'n_units_l3': 95, 'n_units_l4': 59} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:28:25,048] Trial 13 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:28:35,085] Trial 14 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0004385901784730157, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 53, 'n_units_l2': 4, 'n_units_l3': 119, 'n_units_l4': 74} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:28:35,086] Trial 14 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:28:45,366] Trial 15 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0004839031931717899, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 51, 'n_units_l2': 4, 'n_units_l3': 118, 'n_units_l4': 42} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:28:45,368] Trial 15 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:28:55,355] Trial 16 failed with parameters: {'optimizer': 'SGD', 'lr': 0.000510036973838205, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 57, 'n_units_l2': 4, 'n_units_l3': 121, 'n_units_l4': 4} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:28:55,357] Trial 16 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:29:05,331] Trial 17 failed with parameters: {'optimizer': 'SGD', 'lr': 0.00029023052643971814, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 55, 'n_units_l2': 4, 'n_units_l3': 115, 'n_units_l4': 49} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:29:05,333] Trial 17 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:29:15,558] Trial 18 failed with parameters: {'optimizer': 'SGD', 'lr': 0.00035794722982715146, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 57, 'n_units_l2': 4, 'n_units_l3': 125, 'n_units_l4': 8} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:29:15,560] Trial 18 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:29:26,215] Trial 19 failed with parameters: {'optimizer': 'SGD', 'lr': 0.000386204772190019, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 53, 'n_units_l2': 4, 'n_units_l3': 118, 'n_units_l4': 14} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:29:26,217] Trial 19 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[I 2024-04-03 21:29:36,129] Trial 20 finished with value: 38740.6171875 and parameters: {'optimizer': 'SGD', 'lr': 0.00032654051904447553, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 51, 'n_units_l2': 4, 'n_units_l3': 108, 'n_units_l4': 94}. Best is trial 11 with value: 3.4071731567382812.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:29:46,107] Trial 21 finished with value: 77.30036926269531 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00020475808281091387, 'n_layers': 5, 'n_units_l0': 44, 'n_units_l1': 11, 'n_units_l2': 10, 'n_units_l3': 5, 'n_units_l4': 4}. Best is trial 11 with value: 3.4071731567382812.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:29:55,423] Trial 22 failed with parameters: {'optimizer': 'SGD', 'lr': 5.9992430427885646e-05, 'n_layers': 4, 'n_units_l0': 9, 'n_units_l1': 4, 'n_units_l2': 4, 'n_units_l3': 53} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:29:55,425] Trial 22 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[I 2024-04-03 21:30:05,175] Trial 23 finished with value: 38751.484375 and parameters: {'optimizer': 'SGD', 'lr': 9.532001637639478e-05, 'n_layers': 4, 'n_units_l0': 8, 'n_units_l1': 4, 'n_units_l2': 4, 'n_units_l3': 55}. Best is trial 11 with value: 3.4071731567382812.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:30:16,034] Trial 24 finished with value: 416.9476318359375 and parameters: {'optimizer': 'RMSprop', 'lr': 1.281423415147094e-05, 'n_layers': 1, 'n_units_l0': 50}. Best is trial 11 with value: 3.4071731567382812.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:30:25,652] Trial 25 finished with value: 19.653911590576172 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0005820614356398417, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 53, 'n_units_l2': 12, 'n_units_l3': 9}. Best is trial 11 with value: 3.4071731567382812.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:30:36,920] Trial 26 failed with parameters: {'optimizer': 'SGD', 'lr': 0.005992315259868898, 'n_layers': 4, 'n_units_l0': 5, 'n_units_l1': 57, 'n_units_l2': 12, 'n_units_l3': 10} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:30:36,922] Trial 26 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:30:46,296] Trial 27 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0060024462217144105, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 56, 'n_units_l2': 14, 'n_units_l3': 10} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:30:46,298] Trial 27 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:30:55,569] Trial 28 failed with parameters: {'optimizer': 'SGD', 'lr': 0.006136264994227599, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 60, 'n_units_l2': 11, 'n_units_l3': 9} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:30:55,571] Trial 28 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:31:06,565] Trial 29 failed with parameters: {'optimizer': 'SGD', 'lr': 0.006038719590091968, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 60, 'n_units_l2': 12, 'n_units_l3': 8} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:31:06,567] Trial 29 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:31:17,613] Trial 30 failed with parameters: {'optimizer': 'SGD', 'lr': 0.005416857511813472, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 58, 'n_units_l2': 12, 'n_units_l3': 8} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:31:17,614] Trial 30 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:31:26,954] Trial 31 failed with parameters: {'optimizer': 'SGD', 'lr': 0.005343872141401994, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 55, 'n_units_l2': 12, 'n_units_l3': 7} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:31:26,957] Trial 31 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:31:38,337] Trial 32 failed with parameters: {'optimizer': 'SGD', 'lr': 0.005856837126123353, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 54, 'n_units_l2': 12, 'n_units_l3': 8} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:31:38,338] Trial 32 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:31:47,567] Trial 33 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0061583585262326625, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 52, 'n_units_l2': 12, 'n_units_l3': 10} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:31:47,569] Trial 33 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:31:56,849] Trial 34 failed with parameters: {'optimizer': 'SGD', 'lr': 0.004452645114238234, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 53, 'n_units_l2': 12, 'n_units_l3': 9} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:31:56,851] Trial 34 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:32:07,861] Trial 35 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0006758936574138106, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 57, 'n_units_l2': 12, 'n_units_l3': 10} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:32:07,863] Trial 35 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:32:18,899] Trial 36 failed with parameters: {'optimizer': 'SGD', 'lr': 0.006094080784079471, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 55, 'n_units_l2': 11, 'n_units_l3': 11} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:32:18,901] Trial 36 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[I 2024-04-03 21:32:30,152] Trial 37 finished with value: 38748.0390625 and parameters: {'optimizer': 'SGD', 'lr': 0.006679536908031433, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 56, 'n_units_l2': 11, 'n_units_l3': 9}. Best is trial 11 with value: 3.4071731567382812.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:32:41,309] Trial 38 finished with value: 33.420265197753906 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0006487903697950686, 'n_layers': 4, 'n_units_l0': 8, 'n_units_l1': 58, 'n_units_l2': 19, 'n_units_l3': 15}. Best is trial 11 with value: 3.4071731567382812.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:32:52,556] Trial 39 finished with value: 14.65433120727539 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0009349624683755671, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 38, 'n_units_l2': 7, 'n_units_l3': 22, 'n_units_l4': 14}. Best is trial 11 with value: 3.4071731567382812.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:33:05,262] Trial 40 finished with value: 44.578006744384766 and parameters: {'optimizer': 'Adam', 'lr': 0.008153647295981753, 'n_layers': 5, 'n_units_l0': 11, 'n_units_l1': 38, 'n_units_l2': 6, 'n_units_l3': 33, 'n_units_l4': 11}. Best is trial 11 with value: 3.4071731567382812.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:33:16,438] Trial 41 failed with parameters: {'optimizer': 'SGD', 'lr': 0.001184108538189564, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 85, 'n_units_l2': 6, 'n_units_l3': 107, 'n_units_l4': 28} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:33:16,439] Trial 41 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:33:27,628] Trial 42 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0012658473454064249, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 18, 'n_units_l2': 6, 'n_units_l3': 124, 'n_units_l4': 33} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:33:27,635] Trial 42 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:33:37,733] Trial 43 failed with parameters: {'optimizer': 'SGD', 'lr': 0.002251840141713899, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 80, 'n_units_l2': 21, 'n_units_l3': 125, 'n_units_l4': 32} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:33:37,736] Trial 43 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:33:47,511] Trial 44 failed with parameters: {'optimizer': 'SGD', 'lr': 0.00193799194872375, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 19, 'n_units_l2': 6, 'n_units_l3': 85, 'n_units_l4': 30} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:33:47,512] Trial 44 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:33:58,637] Trial 45 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0014714972690391891, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 79, 'n_units_l2': 6, 'n_units_l3': 107, 'n_units_l4': 31} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:33:58,639] Trial 45 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:34:09,746] Trial 46 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0016999651871517044, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 86, 'n_units_l2': 6, 'n_units_l3': 120, 'n_units_l4': 31} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:34:09,748] Trial 46 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:34:19,554] Trial 47 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0022262890907721353, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 83, 'n_units_l2': 6, 'n_units_l3': 125, 'n_units_l4': 30} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:34:19,556] Trial 47 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:34:30,638] Trial 48 failed with parameters: {'optimizer': 'SGD', 'lr': 0.001954058310173157, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 17, 'n_units_l2': 20, 'n_units_l3': 98, 'n_units_l4': 31} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:34:30,640] Trial 48 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:34:39,582] Trial 49 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0017742073037982963, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 81, 'n_units_l2': 6, 'n_units_l3': 123, 'n_units_l4': 27} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:34:39,584] Trial 49 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:34:50,957] Trial 50 failed with parameters: {'optimizer': 'SGD', 'lr': 0.001403900339039423, 'n_layers': 5, 'n_units_l0': 11, 'n_units_l1': 83, 'n_units_l2': 6, 'n_units_l3': 126, 'n_units_l4': 28} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:34:50,959] Trial 50 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:35:00,685] Trial 51 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0014164447213276042, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 88, 'n_units_l2': 6, 'n_units_l3': 112, 'n_units_l4': 31} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:35:00,687] Trial 51 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:35:10,591] Trial 52 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0015198085592847972, 'n_layers': 5, 'n_units_l0': 12, 'n_units_l1': 84, 'n_units_l2': 6, 'n_units_l3': 112, 'n_units_l4': 30} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:35:10,593] Trial 52 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[I 2024-04-03 21:35:20,406] Trial 53 finished with value: 38747.7109375 and parameters: {'optimizer': 'SGD', 'lr': 0.0014487899217574102, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 85, 'n_units_l2': 6, 'n_units_l3': 107, 'n_units_l4': 28}. Best is trial 11 with value: 3.4071731567382812.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:35:31,391] Trial 54 finished with value: 66.81735229492188 and parameters: {'optimizer': 'Adam', 'lr': 3.236735309770273e-05, 'n_layers': 5, 'n_units_l0': 11, 'n_units_l1': 18, 'n_units_l2': 19, 'n_units_l3': 56, 'n_units_l4': 21}. Best is trial 11 with value: 3.4071731567382812.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:35:40,489] Trial 55 finished with value: 59.4532356262207 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0005859489455750099, 'n_layers': 4, 'n_units_l0': 5, 'n_units_l1': 75, 'n_units_l2': 12, 'n_units_l3': 14}. Best is trial 11 with value: 3.4071731567382812.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:35:49,902] Trial 56 finished with value: 2.123854875564575 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0001706092118640273, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 40, 'n_units_l2': 7, 'n_units_l3': 6}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:36:00,926] Trial 57 finished with value: 54.885704040527344 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0001777184620375333, 'n_layers': 3, 'n_units_l0': 11, 'n_units_l1': 37, 'n_units_l2': 6}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:36:12,204] Trial 58 finished with value: 10.462815284729004 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0002072056516232147, 'n_layers': 5, 'n_units_l0': 5, 'n_units_l1': 24, 'n_units_l2': 7, 'n_units_l3': 4, 'n_units_l4': 7}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:36:21,868] Trial 59 finished with value: 49.786930084228516 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00027638729222834, 'n_layers': 4, 'n_units_l0': 5, 'n_units_l1': 24, 'n_units_l2': 16, 'n_units_l3': 4}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:36:31,147] Trial 60 finished with value: 42.03998565673828 and parameters: {'optimizer': 'RMSprop', 'lr': 3.074390703776838e-05, 'n_layers': 5, 'n_units_l0': 10, 'n_units_l1': 12, 'n_units_l2': 30, 'n_units_l3': 7, 'n_units_l4': 4}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:36:40,589] Trial 61 finished with value: 16.733600616455078 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0001498629189354507, 'n_layers': 4, 'n_units_l0': 5, 'n_units_l1': 77, 'n_units_l2': 4, 'n_units_l3': 4}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:36:49,573] Trial 62 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0003995535098483453, 'n_layers': 4, 'n_units_l0': 14, 'n_units_l1': 18, 'n_units_l2': 8, 'n_units_l3': 6} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:36:49,575] Trial 62 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:36:58,816] Trial 63 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0003560088693833808, 'n_layers': 4, 'n_units_l0': 18, 'n_units_l1': 125, 'n_units_l2': 8, 'n_units_l3': 8} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:36:58,818] Trial 63 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[I 2024-04-03 21:37:09,814] Trial 64 finished with value: 38748.20703125 and parameters: {'optimizer': 'SGD', 'lr': 0.00038443216601883424, 'n_layers': 4, 'n_units_l0': 15, 'n_units_l1': 19, 'n_units_l2': 8, 'n_units_l3': 6}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:37:21,078] Trial 65 finished with value: 84.53693389892578 and parameters: {'optimizer': 'Adam', 'lr': 8.227741835970281e-05, 'n_layers': 3, 'n_units_l0': 32, 'n_units_l1': 27, 'n_units_l2': 58}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:37:32,374] Trial 66 finished with value: 13.095256805419922 and parameters: {'optimizer': 'RMSprop', 'lr': 5.2303649364163126e-05, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 44, 'n_units_l2': 5, 'n_units_l3': 12, 'n_units_l4': 7}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:37:41,459] Trial 67 finished with value: 15.165325164794922 and parameters: {'optimizer': 'RMSprop', 'lr': 3.56256947391154e-05, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 49, 'n_units_l2': 5, 'n_units_l3': 11, 'n_units_l4': 8}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:37:51,261] Trial 68 finished with value: 12.35384750366211 and parameters: {'optimizer': 'RMSprop', 'lr': 0.000105651124363541, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 67, 'n_units_l2': 5, 'n_units_l3': 6, 'n_units_l4': 8}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:38:02,508] Trial 69 finished with value: 44.13850402832031 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00012046286039049001, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 67, 'n_units_l2': 14, 'n_units_l3': 6, 'n_units_l4': 26}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:38:13,606] Trial 70 finished with value: 39.564353942871094 and parameters: {'optimizer': 'RMSprop', 'lr': 1.9462633685675284e-05, 'n_layers': 4, 'n_units_l0': 8, 'n_units_l1': 93, 'n_units_l2': 8, 'n_units_l3': 4}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:38:25,486] Trial 71 finished with value: 67.56282043457031 and parameters: {'optimizer': 'Adam', 'lr': 7.853863384611714e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 121, 'n_units_l2': 5}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:38:36,129] Trial 72 finished with value: 763.3922729492188 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00023717136429251103, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 65, 'n_units_l2': 7, 'n_units_l3': 8, 'n_units_l4': 6}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:38:47,612] Trial 73 finished with value: 69.57401275634766 and parameters: {'optimizer': 'Adam', 'lr': 0.002031190387037285, 'n_layers': 4, 'n_units_l0': 13, 'n_units_l1': 30, 'n_units_l2': 9, 'n_units_l3': 5}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:38:57,579] Trial 74 finished with value: 62.4117546081543 and parameters: {'optimizer': 'Adam', 'lr': 0.0004608628531909561, 'n_layers': 3, 'n_units_l0': 80, 'n_units_l1': 15, 'n_units_l2': 119}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:39:08,668] Trial 75 finished with value: 19635.181640625 and parameters: {'optimizer': 'RMSprop', 'lr': 5.5107474757803755e-05, 'n_layers': 1, 'n_units_l0': 7}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:39:20,071] Trial 76 finished with value: 106.88182830810547 and parameters: {'optimizer': 'Adam', 'lr': 0.0009296777272021925, 'n_layers': 2, 'n_units_l0': 21, 'n_units_l1': 125}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:39:31,625] Trial 77 finished with value: 11.692829132080078 and parameters: {'optimizer': 'RMSprop', 'lr': 5.051516027017247e-05, 'n_layers': 5, 'n_units_l0': 5, 'n_units_l1': 39, 'n_units_l2': 5, 'n_units_l3': 19, 'n_units_l4': 7}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:39:42,913] Trial 78 finished with value: 30.38823699951172 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00016666525959479597, 'n_layers': 5, 'n_units_l0': 5, 'n_units_l1': 41, 'n_units_l2': 5, 'n_units_l3': 19, 'n_units_l4': 12}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:39:53,095] Trial 79 finished with value: 29.086990356445312 and parameters: {'optimizer': 'RMSprop', 'lr': 2.0752807636009838e-05, 'n_layers': 5, 'n_units_l0': 9, 'n_units_l1': 31, 'n_units_l2': 7, 'n_units_l3': 69, 'n_units_l4': 6}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:40:03,476] Trial 80 finished with value: 44.726112365722656 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00011250933086826453, 'n_layers': 5, 'n_units_l0': 7, 'n_units_l1': 101, 'n_units_l2': 71, 'n_units_l3': 29, 'n_units_l4': 54}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:40:13,330] Trial 81 finished with value: 65.3473129272461 and parameters: {'optimizer': 'RMSprop', 'lr': 5.0938346054924116e-05, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 22, 'n_units_l2': 4, 'n_units_l3': 5}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:40:22,926] Trial 82 finished with value: 24.560914993286133 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00026931387933182814, 'n_layers': 5, 'n_units_l0': 5, 'n_units_l1': 65, 'n_units_l2': 9, 'n_units_l3': 46, 'n_units_l4': 9}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:40:33,147] Trial 83 finished with value: 99.39825439453125 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00011223100320598634, 'n_layers': 5, 'n_units_l0': 7, 'n_units_l1': 34, 'n_units_l2': 6, 'n_units_l3': 24, 'n_units_l4': 15}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:40:42,832] Trial 84 failed with parameters: {'optimizer': 'SGD', 'lr': 0.000360749609050702, 'n_layers': 4, 'n_units_l0': 6, 'n_units_l1': 46, 'n_units_l2': 5, 'n_units_l3': 7} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:40:42,834] Trial 84 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:40:52,410] Trial 85 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0003891857213629995, 'n_layers': 4, 'n_units_l0': 6, 'n_units_l1': 47, 'n_units_l2': 5, 'n_units_l3': 85} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:40:52,415] Trial 85 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:41:01,546] Trial 86 failed with parameters: {'optimizer': 'SGD', 'lr': 0.00035999563262162425, 'n_layers': 4, 'n_units_l0': 6, 'n_units_l1': 47, 'n_units_l2': 5, 'n_units_l3': 7} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:41:01,549] Trial 86 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:41:12,631] Trial 87 failed with parameters: {'optimizer': 'SGD', 'lr': 0.00034363069566486067, 'n_layers': 4, 'n_units_l0': 6, 'n_units_l1': 49, 'n_units_l2': 27, 'n_units_l3': 75} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:41:12,636] Trial 87 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:41:21,682] Trial 88 failed with parameters: {'optimizer': 'SGD', 'lr': 0.00036569111028908886, 'n_layers': 4, 'n_units_l0': 6, 'n_units_l1': 45, 'n_units_l2': 28, 'n_units_l3': 7} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:41:21,683] Trial 88 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:41:30,959] Trial 89 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0003967057430378013, 'n_layers': 4, 'n_units_l0': 6, 'n_units_l1': 49, 'n_units_l2': 5, 'n_units_l3': 88} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:41:30,961] Trial 89 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[I 2024-04-03 21:41:41,973] Trial 90 finished with value: 38753.2734375 and parameters: {'optimizer': 'SGD', 'lr': 0.0003877887020978182, 'n_layers': 4, 'n_units_l0': 6, 'n_units_l1': 45, 'n_units_l2': 24, 'n_units_l3': 7}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:41:52,309] Trial 91 finished with value: 163.22950744628906 and parameters: {'optimizer': 'Adam', 'lr': 7.621727846554836e-05, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 27, 'n_units_l2': 4, 'n_units_l3': 79}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:42:01,938] Trial 92 finished with value: 74.1767807006836 and parameters: {'optimizer': 'RMSprop', 'lr': 1.1022365431611085e-05, 'n_layers': 5, 'n_units_l0': 36, 'n_units_l1': 6, 'n_units_l2': 10, 'n_units_l3': 5, 'n_units_l4': 5}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:42:13,524] Trial 93 finished with value: 8571.8056640625 and parameters: {'optimizer': 'RMSprop', 'lr': 4.448814081826545e-05, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 47, 'n_units_l2': 5, 'n_units_l3': 11, 'n_units_l4': 7}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:42:25,217] Trial 94 finished with value: 22.67022705078125 and parameters: {'optimizer': 'RMSprop', 'lr': 2.0294498196497127e-05, 'n_layers': 5, 'n_units_l0': 5, 'n_units_l1': 57, 'n_units_l2': 5, 'n_units_l3': 14, 'n_units_l4': 9}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:42:36,972] Trial 95 finished with value: 79.55323791503906 and parameters: {'optimizer': 'RMSprop', 'lr': 5.8471775020443394e-05, 'n_layers': 5, 'n_units_l0': 119, 'n_units_l1': 45, 'n_units_l2': 7, 'n_units_l3': 18, 'n_units_l4': 5}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:42:48,660] Trial 96 finished with value: 118.2962417602539 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00018635829428966116, 'n_layers': 5, 'n_units_l0': 9, 'n_units_l1': 74, 'n_units_l2': 6, 'n_units_l3': 11, 'n_units_l4': 8}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:42:59,795] Trial 97 finished with value: 23.9990291595459 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00013022052213756738, 'n_layers': 4, 'n_units_l0': 7, 'n_units_l1': 33, 'n_units_l2': 8, 'n_units_l3': 29}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[I 2024-04-03 21:43:09,614] Trial 98 finished with value: 38742.98828125 and parameters: {'optimizer': 'SGD', 'lr': 7.333441080838935e-05, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 41, 'n_units_l2': 4, 'n_units_l3': 6, 'n_units_l4': 17}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:43:20,601] Trial 99 finished with value: 2.683406352996826 and parameters: {'optimizer': 'RMSprop', 'lr': 2.6720449209250884e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 57, 'n_units_l2': 12}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:43:30,518] Trial 100 finished with value: 22.794082641601562 and parameters: {'optimizer': 'Adam', 'lr': 2.616217516178007e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 87, 'n_units_l2': 13}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:43:39,140] Trial 101 finished with value: 46.20136260986328 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0006894091970733099, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 54, 'n_units_l2': 11}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:43:50,424] Trial 102 finished with value: 50.439945220947266 and parameters: {'optimizer': 'RMSprop', 'lr': 1.6096499402534046e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 107, 'n_units_l2': 10}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:44:01,407] Trial 103 finished with value: 83.31165313720703 and parameters: {'optimizer': 'RMSprop', 'lr': 3.436337892393506e-05, 'n_layers': 2, 'n_units_l0': 5, 'n_units_l1': 63}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:44:11,476] Trial 104 finished with value: 14.778063774108887 and parameters: {'optimizer': 'RMSprop', 'lr': 4.312954215487886e-05, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 37, 'n_units_l2': 6, 'n_units_l3': 9, 'n_units_l4': 10}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:44:22,596] Trial 105 finished with value: 24.75335121154785 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00021012039126410418, 'n_layers': 4, 'n_units_l0': 8, 'n_units_l1': 78, 'n_units_l2': 8, 'n_units_l3': 17}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:44:34,254] Trial 106 finished with value: 58.564659118652344 and parameters: {'optimizer': 'RMSprop', 'lr': 6.341227417241408e-05, 'n_layers': 3, 'n_units_l0': 64, 'n_units_l1': 52, 'n_units_l2': 15}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:44:45,498] Trial 107 finished with value: 9.516779899597168 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00010474592145150531, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 9, 'n_units_l2': 7, 'n_units_l3': 37}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:44:55,393] Trial 108 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0003192842790669156, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 9, 'n_units_l2': 7, 'n_units_l3': 41} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:44:55,395] Trial 108 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:45:06,510] Trial 109 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0003172340651993971, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 10, 'n_units_l2': 7, 'n_units_l3': 43} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:45:06,512] Trial 109 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[I 2024-04-03 21:45:17,655] Trial 110 finished with value: 38740.38671875 and parameters: {'optimizer': 'SGD', 'lr': 0.00031518699147710865, 'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 13, 'n_units_l2': 7, 'n_units_l3': 44}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:45:27,096] Trial 111 finished with value: 26.834117889404297 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00010148888605519177, 'n_layers': 4, 'n_units_l0': 5, 'n_units_l1': 10, 'n_units_l2': 9, 'n_units_l3': 92}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:45:37,260] Trial 112 finished with value: 124.76873016357422 and parameters: {'optimizer': 'Adam', 'lr': 0.07711169442616254, 'n_layers': 3, 'n_units_l0': 20, 'n_units_l1': 9, 'n_units_l2': 6}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:45:48,397] Trial 113 finished with value: 74.65223693847656 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0001587754758257476, 'n_layers': 4, 'n_units_l0': 25, 'n_units_l1': 4, 'n_units_l2': 17, 'n_units_l3': 59}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:45:57,344] Trial 114 finished with value: 282.7592468261719 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0004287179508067318, 'n_layers': 2, 'n_units_l0': 7, 'n_units_l1': 18}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:46:08,581] Trial 115 finished with value: 17807.9921875 and parameters: {'optimizer': 'RMSprop', 'lr': 8.653604188319773e-05, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 24, 'n_units_l2': 5, 'n_units_l3': 25, 'n_units_l4': 6}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:46:19,888] Trial 116 finished with value: 17797.349609375 and parameters: {'optimizer': 'RMSprop', 'lr': 2.7360508943682366e-05, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 8, 'n_units_l2': 6, 'n_units_l3': 128, 'n_units_l4': 4}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:46:31,030] Trial 117 finished with value: 89.68121337890625 and parameters: {'optimizer': 'RMSprop', 'lr': 0.02040475207528046, 'n_layers': 4, 'n_units_l0': 5, 'n_units_l1': 5, 'n_units_l2': 7, 'n_units_l3': 37}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:46:39,659] Trial 118 finished with value: 17801.171875 and parameters: {'optimizer': 'RMSprop', 'lr': 3.99299044052356e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 59, 'n_units_l2': 5}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:46:50,329] Trial 119 finished with value: 27.431333541870117 and parameters: {'optimizer': 'Adam', 'lr': 0.00014116508061409839, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 70, 'n_units_l2': 8, 'n_units_l3': 48, 'n_units_l4': 40}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:46:59,817] Trial 120 finished with value: 77.16696166992188 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0002414912682399587, 'n_layers': 4, 'n_units_l0': 9, 'n_units_l1': 16, 'n_units_l2': 11, 'n_units_l3': 7}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:47:09,680] Trial 121 finished with value: 46.90804672241211 and parameters: {'optimizer': 'RMSprop', 'lr': 6.561461884620526e-05, 'n_layers': 5, 'n_units_l0': 13, 'n_units_l1': 82, 'n_units_l2': 4, 'n_units_l3': 4, 'n_units_l4': 7}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:47:20,779] Trial 122 finished with value: 22.410253524780273 and parameters: {'optimizer': 'RMSprop', 'lr': 9.075980595248731e-05, 'n_layers': 4, 'n_units_l0': 5, 'n_units_l1': 42, 'n_units_l2': 24, 'n_units_l3': 9}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:47:42,753] Trial 123 finished with value: 20254.4296875 and parameters: {'optimizer': 'Adam', 'lr': 1.6580378606185784e-05, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 93, 'n_units_l2': 40, 'n_units_l3': 5, 'n_units_l4': 5}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:47:51,460] Trial 124 finished with value: 43.179012298583984 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0012327528579850029, 'n_layers': 3, 'n_units_l0': 8, 'n_units_l1': 29, 'n_units_l2': 10}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:48:02,713] Trial 125 finished with value: 100.86906433105469 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0022798620192045144, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 36, 'n_units_l2': 7, 'n_units_l3': 15, 'n_units_l4': 13}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:48:13,973] Trial 126 finished with value: 56.576107025146484 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0005055688876576276, 'n_layers': 5, 'n_units_l0': 7, 'n_units_l1': 41, 'n_units_l2': 5, 'n_units_l3': 35, 'n_units_l4': 16}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:48:24,059] Trial 127 finished with value: 11.457474708557129 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0008507736951476011, 'n_layers': 5, 'n_units_l0': 5, 'n_units_l1': 49, 'n_units_l2': 9, 'n_units_l3': 22, 'n_units_l4': 11}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:48:35,367] Trial 128 finished with value: 394.9271545410156 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0007126005166370789, 'n_layers': 5, 'n_units_l0': 5, 'n_units_l1': 50, 'n_units_l2': 8, 'n_units_l3': 21, 'n_units_l4': 10}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:48:44,979] Trial 129 failed with parameters: {'optimizer': 'SGD', 'lr': 0.00328194629739266, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 59, 'n_units_l2': 6, 'n_units_l3': 12, 'n_units_l4': 127} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:48:44,982] Trial 129 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:48:56,255] Trial 130 failed with parameters: {'optimizer': 'SGD', 'lr': 0.005108900607368241, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 60, 'n_units_l2': 12, 'n_units_l3': 12, 'n_units_l4': 88} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:48:56,258] Trial 130 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:49:05,403] Trial 131 failed with parameters: {'optimizer': 'SGD', 'lr': 0.004063256710964742, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 60, 'n_units_l2': 12, 'n_units_l3': 12, 'n_units_l4': 82} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:49:05,407] Trial 131 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:49:16,559] Trial 132 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0032135515534025285, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 60, 'n_units_l2': 6, 'n_units_l3': 12, 'n_units_l4': 119} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:49:16,560] Trial 132 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[I 2024-04-03 21:49:27,677] Trial 133 finished with value: 38751.89453125 and parameters: {'optimizer': 'SGD', 'lr': 5.192770396058993e-05, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 62, 'n_units_l2': 6, 'n_units_l3': 28, 'n_units_l4': 7}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:49:38,941] Trial 134 finished with value: 23.779935836791992 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00030631822654633977, 'n_layers': 5, 'n_units_l0': 5, 'n_units_l1': 71, 'n_units_l2': 9, 'n_units_l3': 21, 'n_units_l4': 111}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:49:48,845] Trial 135 finished with value: 96.65792083740234 and parameters: {'optimizer': 'RMSprop', 'lr': 0.004984600886001355, 'n_layers': 4, 'n_units_l0': 30, 'n_units_l1': 57, 'n_units_l2': 12, 'n_units_l3': 13}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:49:58,460] Trial 136 finished with value: 18446.94921875 and parameters: {'optimizer': 'RMSprop', 'lr': 2.4718553484259035e-05, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 45, 'n_units_l2': 7, 'n_units_l3': 6, 'n_units_l4': 11}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:50:10,189] Trial 137 finished with value: 98.2168197631836 and parameters: {'optimizer': 'Adam', 'lr': 0.00013913210786841283, 'n_layers': 5, 'n_units_l0': 17, 'n_units_l1': 48, 'n_units_l2': 9, 'n_units_l3': 42, 'n_units_l4': 19}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:50:19,417] Trial 138 finished with value: 128.2102508544922 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00021049307027249948, 'n_layers': 4, 'n_units_l0': 10, 'n_units_l1': 32, 'n_units_l2': 8, 'n_units_l3': 12}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:50:30,689] Trial 139 finished with value: 108.2560806274414 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0008411740945777499, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 21, 'n_units_l2': 6, 'n_units_l3': 16, 'n_units_l4': 13}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:50:40,614] Trial 140 finished with value: 31.326431274414062 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00118580474802372, 'n_layers': 5, 'n_units_l0': 7, 'n_units_l1': 36, 'n_units_l2': 11, 'n_units_l3': 24, 'n_units_l4': 8}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:50:51,850] Trial 141 finished with value: 15.082371711730957 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0019029926721865012, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 29, 'n_units_l2': 7, 'n_units_l3': 19, 'n_units_l4': 14}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:51:01,879] Trial 142 finished with value: 19.121618270874023 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0025337874295171046, 'n_layers': 5, 'n_units_l0': 5, 'n_units_l1': 53, 'n_units_l2': 89, 'n_units_l3': 64, 'n_units_l4': 24}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:51:13,135] Trial 143 finished with value: 157.0545654296875 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0003613079069221431, 'n_layers': 5, 'n_units_l0': 93, 'n_units_l1': 39, 'n_units_l2': 5, 'n_units_l3': 27, 'n_units_l4': 11}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:51:22,300] Trial 144 finished with value: 39.93299865722656 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00011507394341671819, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 25, 'n_units_l2': 10, 'n_units_l3': 33, 'n_units_l4': 6}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:51:34,841] Trial 145 finished with value: 93.74791717529297 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0005678656008840616, 'n_layers': 5, 'n_units_l0': 38, 'n_units_l1': 45, 'n_units_l2': 7, 'n_units_l3': 10, 'n_units_l4': 9}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:51:46,218] Trial 146 failed with parameters: {'optimizer': 'SGD', 'lr': 4.816535936283038e-05, 'n_layers': 4, 'n_units_l0': 8, 'n_units_l1': 35, 'n_units_l2': 9, 'n_units_l3': 8} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:51:46,219] Trial 146 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[I 2024-04-03 21:51:55,691] Trial 147 finished with value: 38744.1484375 and parameters: {'optimizer': 'SGD', 'lr': 0.0001842522224044468, 'n_layers': 4, 'n_units_l0': 5, 'n_units_l1': 34, 'n_units_l2': 9, 'n_units_l3': 8}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:52:06,137] Trial 148 finished with value: 173.87704467773438 and parameters: {'optimizer': 'Adam', 'lr': 0.0034532706056334683, 'n_layers': 3, 'n_units_l0': 8, 'n_units_l1': 22, 'n_units_l2': 13}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:52:17,475] Trial 149 finished with value: 20296.849609375 and parameters: {'optimizer': 'RMSprop', 'lr': 4.8384921024044517e-05, 'n_layers': 5, 'n_units_l0': 46, 'n_units_l1': 61, 'n_units_l2': 6, 'n_units_l3': 32, 'n_units_l4': 4}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:52:27,975] Trial 150 finished with value: 19.877765655517578 and parameters: {'optimizer': 'RMSprop', 'lr': 3.7877367089083594e-05, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 38, 'n_units_l2': 8, 'n_units_l3': 7, 'n_units_l4': 10}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:52:38,487] Trial 151 finished with value: 168.78964233398438 and parameters: {'optimizer': 'RMSprop', 'lr': 7.138062664273894e-05, 'n_layers': 5, 'n_units_l0': 7, 'n_units_l1': 42, 'n_units_l2': 6, 'n_units_l3': 8, 'n_units_l4': 7}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:52:47,859] Trial 152 finished with value: 65.37126922607422 and parameters: {'optimizer': 'RMSprop', 'lr': 9.53091612691641e-05, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 27, 'n_units_l2': 5, 'n_units_l3': 10, 'n_units_l4': 8}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:52:58,124] Trial 153 finished with value: 98.3274917602539 and parameters: {'optimizer': 'RMSprop', 'lr': 2.9955796879003394e-05, 'n_layers': 5, 'n_units_l0': 61, 'n_units_l1': 67, 'n_units_l2': 6, 'n_units_l3': 23, 'n_units_l4': 12}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:53:09,412] Trial 154 finished with value: 31.788942337036133 and parameters: {'optimizer': 'RMSprop', 'lr': 4.075964579971738e-05, 'n_layers': 5, 'n_units_l0': 5, 'n_units_l1': 35, 'n_units_l2': 4, 'n_units_l3': 76, 'n_units_l4': 9}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:53:20,649] Trial 155 finished with value: 92.48844909667969 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0014599438818730349, 'n_layers': 4, 'n_units_l0': 19, 'n_units_l1': 48, 'n_units_l2': 8, 'n_units_l3': 6}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:53:30,853] Trial 156 finished with value: 46.15678787231445 and parameters: {'optimizer': 'RMSprop', 'lr': 5.6173900870970384e-05, 'n_layers': 5, 'n_units_l0': 13, 'n_units_l1': 54, 'n_units_l2': 7, 'n_units_l3': 5, 'n_units_l4': 5}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:53:41,882] Trial 157 finished with value: 121.83478546142578 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00026155975104505245, 'n_layers': 3, 'n_units_l0': 6, 'n_units_l1': 13, 'n_units_l2': 9}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:53:53,286] Trial 158 finished with value: 72.19131469726562 and parameters: {'optimizer': 'Adam', 'lr': 1.2669213709767687e-05, 'n_layers': 4, 'n_units_l0': 5, 'n_units_l1': 38, 'n_units_l2': 39, 'n_units_l3': 9}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:54:01,103] Trial 159 finished with value: 26846.634765625 and parameters: {'optimizer': 'RMSprop', 'lr': 2.2709879478635554e-05, 'n_layers': 1, 'n_units_l0': 4}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:54:12,548] Trial 160 finished with value: 10.162047386169434 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0019942057619698147, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 29, 'n_units_l2': 7, 'n_units_l3': 17, 'n_units_l4': 15}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:54:23,221] Trial 161 finished with value: 17.120410919189453 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0001221522798330809, 'n_layers': 5, 'n_units_l0': 7, 'n_units_l1': 30, 'n_units_l2': 6, 'n_units_l3': 13, 'n_units_l4': 20}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:54:34,497] Trial 162 finished with value: 23.26813316345215 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0008487444534740473, 'n_layers': 5, 'n_units_l0': 9, 'n_units_l1': 32, 'n_units_l2': 7, 'n_units_l3': 16, 'n_units_l4': 17}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:54:45,805] Trial 163 finished with value: 23.309179306030273 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0016295031970414283, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 40, 'n_units_l2': 10, 'n_units_l3': 20, 'n_units_l4': 10}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:54:55,650] Trial 164 finished with value: 17.017574310302734 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00015417922257431984, 'n_layers': 5, 'n_units_l0': 8, 'n_units_l1': 20, 'n_units_l2': 5, 'n_units_l3': 18, 'n_units_l4': 12}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:55:06,924] Trial 165 finished with value: 21.32107925415039 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0030935989384820437, 'n_layers': 5, 'n_units_l0': 5, 'n_units_l1': 25, 'n_units_l2': 8, 'n_units_l3': 53, 'n_units_l4': 7}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:55:18,165] Trial 166 finished with value: 25.256977081298828 and parameters: {'optimizer': 'RMSprop', 'lr': 8.436244040532742e-05, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 45, 'n_units_l2': 50, 'n_units_l3': 14, 'n_units_l4': 6}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:55:26,907] Trial 167 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0010360263267907251, 'n_layers': 5, 'n_units_l0': 7, 'n_units_l1': 23, 'n_units_l2': 6, 'n_units_l3': 40, 'n_units_l4': 14} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:55:26,909] Trial 167 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:55:38,387] Trial 168 finished with value: 33.44871520996094 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0010439163447636228, 'n_layers': 5, 'n_units_l0': 10, 'n_units_l1': 28, 'n_units_l2': 18, 'n_units_l3': 17, 'n_units_l4': 8}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:55:47,501] Trial 169 failed with parameters: {'optimizer': 'SGD', 'lr': 4.753586213110751e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 79, 'n_units_l2': 31} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:55:47,503] Trial 169 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 21:55:56,549] Trial 170 failed with parameters: {'optimizer': 'SGD', 'lr': 4.491116380023324e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 50, 'n_units_l2': 7} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 21:55:56,551] Trial 170 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[I 2024-04-03 21:56:07,486] Trial 171 finished with value: 38736.0859375 and parameters: {'optimizer': 'SGD', 'lr': 6.550923763767085e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 6, 'n_units_l2': 7}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:56:16,798] Trial 172 finished with value: 749.840087890625 and parameters: {'optimizer': 'Adam', 'lr': 0.014267223845344165, 'n_layers': 2, 'n_units_l0': 5, 'n_units_l1': 50}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:56:26,878] Trial 173 finished with value: 31.702863693237305 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0016333316822471334, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 30, 'n_units_l2': 7, 'n_units_l3': 22, 'n_units_l4': 14}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:56:36,973] Trial 174 finished with value: 32.11384201049805 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0037877654085226387, 'n_layers': 5, 'n_units_l0': 7, 'n_units_l1': 34, 'n_units_l2': 6, 'n_units_l3': 19, 'n_units_l4': 15}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:56:48,299] Trial 175 finished with value: 69.92430877685547 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0011524273460160209, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 23, 'n_units_l2': 8, 'n_units_l3': 26, 'n_units_l4': 11}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:56:58,075] Trial 176 finished with value: 198.05152893066406 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0018514068900566615, 'n_layers': 5, 'n_units_l0': 5, 'n_units_l1': 78, 'n_units_l2': 9, 'n_units_l3': 19, 'n_units_l4': 13}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:57:09,302] Trial 177 finished with value: 18.70547103881836 and parameters: {'optimizer': 'RMSprop', 'lr': 4.594184473264072e-05, 'n_layers': 5, 'n_units_l0': 6, 'n_units_l1': 42, 'n_units_l2': 7, 'n_units_l3': 12, 'n_units_l4': 31}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:57:19,356] Trial 178 finished with value: 94.02169799804688 and parameters: {'optimizer': 'RMSprop', 'lr': 0.002177315090756446, 'n_layers': 5, 'n_units_l0': 8, 'n_units_l1': 26, 'n_units_l2': 21, 'n_units_l3': 30, 'n_units_l4': 18}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:57:29,275] Trial 179 finished with value: 767.798095703125 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0024936074224389563, 'n_layers': 4, 'n_units_l0': 5, 'n_units_l1': 37, 'n_units_l2': 6, 'n_units_l3': 15}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:57:40,752] Trial 180 finished with value: 6.791219711303711 and parameters: {'optimizer': 'RMSprop', 'lr': 3.3354838928742636e-05, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 58, 'n_units_l2': 30, 'n_units_l3': 22, 'n_units_l4': 15}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:57:52,105] Trial 181 finished with value: 90.13382720947266 and parameters: {'optimizer': 'RMSprop', 'lr': 3.281702661318318e-05, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 56, 'n_units_l2': 25, 'n_units_l3': 10, 'n_units_l4': 70}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:58:03,364] Trial 182 finished with value: 37.424842834472656 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00022004645864974785, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 71, 'n_units_l2': 5, 'n_units_l3': 93, 'n_units_l4': 10}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:58:14,689] Trial 183 finished with value: 119.09558868408203 and parameters: {'optimizer': 'RMSprop', 'lr': 1.9396626620794937e-05, 'n_layers': 5, 'n_units_l0': 69, 'n_units_l1': 62, 'n_units_l2': 31, 'n_units_l3': 21, 'n_units_l4': 15}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:58:24,864] Trial 184 finished with value: 27.653783798217773 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00010224448460870448, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 87, 'n_units_l2': 26, 'n_units_l3': 23, 'n_units_l4': 24}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:58:36,106] Trial 185 finished with value: 14.475285530090332 and parameters: {'optimizer': 'RMSprop', 'lr': 2.7864310743148592e-05, 'n_layers': 5, 'n_units_l0': 5, 'n_units_l1': 51, 'n_units_l2': 36, 'n_units_l3': 40, 'n_units_l4': 14}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:58:45,859] Trial 186 finished with value: 77.1200942993164 and parameters: {'optimizer': 'RMSprop', 'lr': 2.862468344576148e-05, 'n_layers': 5, 'n_units_l0': 23, 'n_units_l1': 51, 'n_units_l2': 46, 'n_units_l3': 36, 'n_units_l4': 9}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:58:57,256] Trial 187 finished with value: 14.473071098327637 and parameters: {'optimizer': 'RMSprop', 'lr': 3.681755376274735e-05, 'n_layers': 5, 'n_units_l0': 5, 'n_units_l1': 45, 'n_units_l2': 33, 'n_units_l3': 40, 'n_units_l4': 16}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:59:08,551] Trial 188 finished with value: 2.447680950164795 and parameters: {'optimizer': 'RMSprop', 'lr': 1.7261022841184598e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 58, 'n_units_l2': 38}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:59:22,029] Trial 189 finished with value: 7.16799259185791 and parameters: {'optimizer': 'RMSprop', 'lr': 1.8334911419856468e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 65, 'n_units_l2': 36}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 21:59:32,205] Trial 190 finished with value: 59.242923736572266 and parameters: {'optimizer': 'Adam', 'lr': 1.1332872269808374e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 66, 'n_units_l2': 31}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:59:41,782] Trial 191 finished with value: 4.782846450805664 and parameters: {'optimizer': 'RMSprop', 'lr': 1.6312673898138057e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 57, 'n_units_l2': 40}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 21:59:51,471] Trial 192 finished with value: 13.471070289611816 and parameters: {'optimizer': 'RMSprop', 'lr': 1.4681439862947942e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 59, 'n_units_l2': 42}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:00:01,205] Trial 193 finished with value: 6.664194107055664 and parameters: {'optimizer': 'RMSprop', 'lr': 1.569943268752705e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 59, 'n_units_l2': 43}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:00:11,173] Trial 194 finished with value: 8.68043041229248 and parameters: {'optimizer': 'RMSprop', 'lr': 1.7461711083989852e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 72, 'n_units_l2': 50}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:00:22,349] Trial 195 finished with value: 45.58595275878906 and parameters: {'optimizer': 'RMSprop', 'lr': 1.930272457781118e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 72, 'n_units_l2': 54}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:00:32,571] Trial 196 finished with value: 4.012575626373291 and parameters: {'optimizer': 'RMSprop', 'lr': 1.5733477285744195e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 79, 'n_units_l2': 62}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:00:42,253] Trial 197 finished with value: 8.152369499206543 and parameters: {'optimizer': 'RMSprop', 'lr': 1.4693594120773396e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 79, 'n_units_l2': 68}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:00:51,703] Trial 198 finished with value: 5.594851493835449 and parameters: {'optimizer': 'RMSprop', 'lr': 1.3586239566843917e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 94, 'n_units_l2': 65}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:01:02,755] Trial 199 finished with value: 7.718103408813477 and parameters: {'optimizer': 'RMSprop', 'lr': 1.5888958753152306e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 94, 'n_units_l2': 69}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:01:12,745] Trial 200 finished with value: 13.921536445617676 and parameters: {'optimizer': 'RMSprop', 'lr': 1.6771212175513594e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 95, 'n_units_l2': 63}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:01:21,974] Trial 201 finished with value: 362.6451416015625 and parameters: {'optimizer': 'RMSprop', 'lr': 1.0521036854977584e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 83, 'n_units_l2': 79}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:01:31,583] Trial 202 failed with parameters: {'optimizer': 'SGD', 'lr': 1.4684752011415967e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 113, 'n_units_l2': 64} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:01:31,585] Trial 202 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:01:42,529] Trial 203 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2724961628040743e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 121, 'n_units_l2': 66} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:01:42,530] Trial 203 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:01:53,480] Trial 204 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2910644010058459e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 78, 'n_units_l2': 62} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:01:53,484] Trial 204 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:02:04,427] Trial 205 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2922866993668892e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 113, 'n_units_l2': 66} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:02:04,429] Trial 205 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:02:14,570] Trial 206 finished with value: 83.17637634277344 and parameters: {'optimizer': 'RMSprop', 'lr': 1.3873065151966288e-05, 'n_layers': 3, 'n_units_l0': 15, 'n_units_l1': 113, 'n_units_l2': 60}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:02:25,588] Trial 207 finished with value: 14.66711139678955 and parameters: {'optimizer': 'RMSprop', 'lr': 1.6765476877640908e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 105, 'n_units_l2': 44}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:02:36,660] Trial 208 finished with value: 44.64580535888672 and parameters: {'optimizer': 'RMSprop', 'lr': 1.2574772233623309e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 77, 'n_units_l2': 76}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:02:47,812] Trial 209 finished with value: 20.735353469848633 and parameters: {'optimizer': 'RMSprop', 'lr': 2.170416517551471e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 89, 'n_units_l2': 66}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:02:56,928] Trial 210 finished with value: 13.000421524047852 and parameters: {'optimizer': 'RMSprop', 'lr': 1.4884176078241772e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 95, 'n_units_l2': 53}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:03:07,920] Trial 211 finished with value: 8.167031288146973 and parameters: {'optimizer': 'RMSprop', 'lr': 1.7912155050860413e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 81, 'n_units_l2': 36}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:03:17,163] Trial 212 failed with parameters: {'optimizer': 'SGD', 'lr': 1.8152646812934103e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 75, 'n_units_l2': 37} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:03:17,165] Trial 212 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:03:27,181] Trial 213 failed with parameters: {'optimizer': 'SGD', 'lr': 2.3665742923896943e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 81, 'n_units_l2': 48} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:03:27,183] Trial 213 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:03:38,221] Trial 214 failed with parameters: {'optimizer': 'SGD', 'lr': 1.8480252291582586e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 81, 'n_units_l2': 46} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:03:38,223] Trial 214 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:03:46,599] Trial 215 failed with parameters: {'optimizer': 'SGD', 'lr': 1.0219936129388901e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 82, 'n_units_l2': 39} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:03:46,600] Trial 215 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:03:55,903] Trial 216 finished with value: 33.19537353515625 and parameters: {'optimizer': 'RMSprop', 'lr': 1.0547082796957654e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 80, 'n_units_l2': 37}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:04:06,814] Trial 217 failed with parameters: {'optimizer': 'SGD', 'lr': 1.900396652291587e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 73, 'n_units_l2': 48} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:04:06,816] Trial 217 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:04:15,918] Trial 218 failed with parameters: {'optimizer': 'SGD', 'lr': 1.8642597962817237e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 100, 'n_units_l2': 28} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:04:15,919] Trial 218 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:04:24,372] Trial 219 failed with parameters: {'optimizer': 'SGD', 'lr': 1.861662020863408e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 115, 'n_units_l2': 28} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:04:24,374] Trial 219 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:04:33,788] Trial 220 failed with parameters: {'optimizer': 'SGD', 'lr': 1.811570053414535e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 114, 'n_units_l2': 48} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:04:33,790] Trial 220 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:04:43,192] Trial 221 finished with value: 35.89697265625 and parameters: {'optimizer': 'RMSprop', 'lr': 1.7879763705037774e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 74, 'n_units_l2': 28}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:04:52,389] Trial 222 failed with parameters: {'optimizer': 'SGD', 'lr': 2.3839708376208152e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 101, 'n_units_l2': 49} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:04:52,391] Trial 222 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:05:03,332] Trial 223 failed with parameters: {'optimizer': 'SGD', 'lr': 2.3137183642245737e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 99, 'n_units_l2': 47} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:05:03,334] Trial 223 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:05:12,475] Trial 224 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3191237644638481e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 113, 'n_units_l2': 49} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:05:12,476] Trial 224 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:05:21,897] Trial 225 failed with parameters: {'optimizer': 'SGD', 'lr': 2.3573292373479637e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 67, 'n_units_l2': 47} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:05:21,898] Trial 225 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:05:31,266] Trial 226 failed with parameters: {'optimizer': 'SGD', 'lr': 2.2926982001317323e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 100, 'n_units_l2': 48} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:05:31,267] Trial 226 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:05:42,200] Trial 227 failed with parameters: {'optimizer': 'SGD', 'lr': 2.3878090459591987e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 65, 'n_units_l2': 48} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:05:42,202] Trial 227 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:05:50,785] Trial 228 failed with parameters: {'optimizer': 'SGD', 'lr': 2.503684164979356e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 68, 'n_units_l2': 47} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:05:50,787] Trial 228 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:05:59,477] Trial 229 failed with parameters: {'optimizer': 'SGD', 'lr': 2.5031115359964756e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 66, 'n_units_l2': 49} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:05:59,479] Trial 229 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:06:10,404] Trial 230 failed with parameters: {'optimizer': 'SGD', 'lr': 2.410316560961339e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 98, 'n_units_l2': 35} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:06:10,406] Trial 230 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:06:20,095] Trial 231 failed with parameters: {'optimizer': 'SGD', 'lr': 2.4161532648900658e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 101, 'n_units_l2': 46} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:06:20,097] Trial 231 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:06:29,878] Trial 232 failed with parameters: {'optimizer': 'SGD', 'lr': 2.4204941301976402e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 68, 'n_units_l2': 48} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:06:29,880] Trial 232 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:06:38,729] Trial 233 failed with parameters: {'optimizer': 'SGD', 'lr': 2.18500756257443e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 116, 'n_units_l2': 46} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:06:38,731] Trial 233 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:06:49,796] Trial 234 failed with parameters: {'optimizer': 'SGD', 'lr': 2.4337655715796128e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 69, 'n_units_l2': 34} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:06:49,799] Trial 234 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:06:59,623] Trial 235 failed with parameters: {'optimizer': 'SGD', 'lr': 2.4131853827943447e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 67, 'n_units_l2': 48} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:06:59,626] Trial 235 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:07:08,956] Trial 236 failed with parameters: {'optimizer': 'SGD', 'lr': 2.2396340531935685e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 67, 'n_units_l2': 34} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:07:08,957] Trial 236 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:07:18,064] Trial 237 failed with parameters: {'optimizer': 'SGD', 'lr': 2.5027722354140133e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 68, 'n_units_l2': 48} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:07:18,067] Trial 237 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:07:29,211] Trial 238 failed with parameters: {'optimizer': 'SGD', 'lr': 2.327632957154207e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 100, 'n_units_l2': 86} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:07:29,214] Trial 238 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:07:38,695] Trial 239 failed with parameters: {'optimizer': 'SGD', 'lr': 2.401723999372854e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 68, 'n_units_l2': 49} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:07:38,699] Trial 239 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:07:48,012] Trial 240 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3165189244533606e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 68, 'n_units_l2': 47} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:07:48,013] Trial 240 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:07:57,648] Trial 241 failed with parameters: {'optimizer': 'SGD', 'lr': 2.491598182009096e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 113, 'n_units_l2': 70} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:07:57,650] Trial 241 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:08:07,279] Trial 242 finished with value: 13.503290176391602 and parameters: {'optimizer': 'RMSprop', 'lr': 2.2368764514441398e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 115, 'n_units_l2': 49}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:08:16,482] Trial 243 finished with value: 35.3328857421875 and parameters: {'optimizer': 'RMSprop', 'lr': 1.4327462230082306e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 101, 'n_units_l2': 68}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:08:27,433] Trial 244 failed with parameters: {'optimizer': 'SGD', 'lr': 2.343578356800379e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 68, 'n_units_l2': 33} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:08:27,436] Trial 244 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:08:38,453] Trial 245 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2842471740652756e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 70, 'n_units_l2': 84} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:08:38,454] Trial 245 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 22:08:48,927] Trial 246 finished with value: 62.14212417602539 and parameters: {'optimizer': 'Adam', 'lr': 2.377432965757491e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 65, 'n_units_l2': 34}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:08:59,865] Trial 247 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3301688638269848e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 85, 'n_units_l2': 75} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:08:59,866] Trial 247 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:09:08,629] Trial 248 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2544369707293478e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 85, 'n_units_l2': 38} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:09:08,632] Trial 248 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:09:19,914] Trial 249 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3451210097074934e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 85, 'n_units_l2': 73} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:09:19,916] Trial 249 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:09:29,410] Trial 250 failed with parameters: {'optimizer': 'SGD', 'lr': 1.1855601569128364e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 90, 'n_units_l2': 58} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:09:29,411] Trial 250 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:09:40,380] Trial 251 failed with parameters: {'optimizer': 'SGD', 'lr': 1.832335867138699e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 86, 'n_units_l2': 89} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:09:40,383] Trial 251 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:09:52,461] Trial 252 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2526321145049222e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 85, 'n_units_l2': 40} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:09:52,463] Trial 252 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:10:03,644] Trial 253 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2657625776918622e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 84, 'n_units_l2': 93} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:10:03,646] Trial 253 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:10:14,691] Trial 254 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2792116794932192e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 69, 'n_units_l2': 41} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:10:14,693] Trial 254 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:10:25,100] Trial 255 finished with value: 9.683058738708496 and parameters: {'optimizer': 'RMSprop', 'lr': 1.8571655069450133e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 85, 'n_units_l2': 58}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:10:36,079] Trial 256 failed with parameters: {'optimizer': 'SGD', 'lr': 1.281708928885948e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 88, 'n_units_l2': 57} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:10:36,081] Trial 256 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:10:45,486] Trial 257 finished with value: 4.939863681793213 and parameters: {'optimizer': 'RMSprop', 'lr': 1.2527741224049858e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 85, 'n_units_l2': 57}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:10:57,227] Trial 258 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2728812341381671e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 93, 'n_units_l2': 57} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:10:57,229] Trial 258 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:11:08,485] Trial 259 failed with parameters: {'optimizer': 'SGD', 'lr': 1.227384628104111e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 84, 'n_units_l2': 58} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:11:08,490] Trial 259 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:11:18,080] Trial 260 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2041821523175436e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 68, 'n_units_l2': 57} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:11:18,082] Trial 260 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:11:29,156] Trial 261 finished with value: 8.190918922424316 and parameters: {'optimizer': 'RMSprop', 'lr': 1.2487584950181038e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 84, 'n_units_l2': 57}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:11:40,236] Trial 262 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2429680798387035e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 91, 'n_units_l2': 93} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:11:40,243] Trial 262 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:11:51,257] Trial 263 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2020114064788846e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 91, 'n_units_l2': 90} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:11:51,259] Trial 263 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:12:02,039] Trial 264 finished with value: 5.445541858673096 and parameters: {'optimizer': 'RMSprop', 'lr': 1.2450751334002627e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 90, 'n_units_l2': 83}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:12:11,630] Trial 265 failed with parameters: {'optimizer': 'SGD', 'lr': 1.1787082114754708e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 92, 'n_units_l2': 81} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:12:11,632] Trial 265 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:12:21,954] Trial 266 finished with value: 16.551450729370117 and parameters: {'optimizer': 'RMSprop', 'lr': 1.0085490357054904e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 91, 'n_units_l2': 86}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:12:32,997] Trial 267 finished with value: 8.123759269714355 and parameters: {'optimizer': 'RMSprop', 'lr': 1.2606958378894544e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 81, 'n_units_l2': 72}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:12:44,094] Trial 268 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2753807613987528e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 82, 'n_units_l2': 76} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:12:44,097] Trial 268 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:12:54,136] Trial 269 failed with parameters: {'optimizer': 'SGD', 'lr': 1.1882783750173692e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 97, 'n_units_l2': 94} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:12:54,140] Trial 269 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:13:05,132] Trial 270 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3144800805071775e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 101, 'n_units_l2': 76} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:13:05,133] Trial 270 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:13:14,651] Trial 271 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3878284182961973e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 98, 'n_units_l2': 101} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:13:14,654] Trial 271 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:13:24,224] Trial 272 finished with value: 12.072495460510254 and parameters: {'optimizer': 'RMSprop', 'lr': 1.2220842061239498e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 99, 'n_units_l2': 101}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:13:34,047] Trial 273 failed with parameters: {'optimizer': 'SGD', 'lr': 1.325784936848941e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 81, 'n_units_l2': 74} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:13:34,049] Trial 273 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:13:44,996] Trial 274 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3533816946400208e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 80, 'n_units_l2': 71} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:13:44,998] Trial 274 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:13:54,357] Trial 275 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3848957757930207e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 80, 'n_units_l2': 71} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:13:54,358] Trial 275 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:14:03,420] Trial 276 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3722063859182438e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 79, 'n_units_l2': 70} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:14:03,422] Trial 276 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:14:14,814] Trial 277 failed with parameters: {'optimizer': 'SGD', 'lr': 1.371367512598336e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 82, 'n_units_l2': 74} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:14:14,818] Trial 277 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:14:24,958] Trial 278 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3633190158554308e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 82, 'n_units_l2': 74} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:14:24,960] Trial 278 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:14:34,477] Trial 279 failed with parameters: {'optimizer': 'SGD', 'lr': 1.4172661869017766e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 82, 'n_units_l2': 76} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:14:34,479] Trial 279 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:14:44,327] Trial 280 failed with parameters: {'optimizer': 'SGD', 'lr': 1.4787836877165292e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 82, 'n_units_l2': 73} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:14:44,329] Trial 280 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:14:53,857] Trial 281 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3119837119581723e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 82, 'n_units_l2': 75} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:14:53,859] Trial 281 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:15:04,894] Trial 282 finished with value: 24.461454391479492 and parameters: {'optimizer': 'RMSprop', 'lr': 1.3456332881151818e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 83, 'n_units_l2': 77}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:15:16,099] Trial 283 failed with parameters: {'optimizer': 'SGD', 'lr': 1.5178081340011364e-05, 'n_layers': 3, 'n_units_l0': 53, 'n_units_l1': 78, 'n_units_l2': 69} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:15:16,102] Trial 283 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:15:25,864] Trial 284 failed with parameters: {'optimizer': 'SGD', 'lr': 1.5335552951533172e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 79, 'n_units_l2': 68} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:15:25,866] Trial 284 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:15:36,029] Trial 285 failed with parameters: {'optimizer': 'SGD', 'lr': 1.4966211782784047e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 77, 'n_units_l2': 73} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:15:36,030] Trial 285 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:15:46,992] Trial 286 failed with parameters: {'optimizer': 'SGD', 'lr': 1.5302109568946503e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 77, 'n_units_l2': 72} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:15:46,994] Trial 286 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:15:56,938] Trial 287 finished with value: 8.712313652038574 and parameters: {'optimizer': 'RMSprop', 'lr': 1.5376420221023184e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 80, 'n_units_l2': 55}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:16:07,884] Trial 288 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2482348781058298e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 69, 'n_units_l2': 70} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:16:07,886] Trial 288 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:16:18,813] Trial 289 failed with parameters: {'optimizer': 'SGD', 'lr': 2.458550708281892e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 127, 'n_units_l2': 74} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:16:18,814] Trial 289 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:16:27,664] Trial 290 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2588690934722012e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 88, 'n_units_l2': 71} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:16:27,666] Trial 290 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:16:38,770] Trial 291 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2847321395422331e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 89, 'n_units_l2': 74} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:16:38,772] Trial 291 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:16:48,679] Trial 292 finished with value: 4.02360725402832 and parameters: {'optimizer': 'RMSprop', 'lr': 1.2296553206900337e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 89, 'n_units_l2': 64}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:16:59,106] Trial 293 finished with value: 5.735983371734619 and parameters: {'optimizer': 'RMSprop', 'lr': 1.2543483764513701e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 91, 'n_units_l2': 69}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:17:09,749] Trial 294 finished with value: 75.18419647216797 and parameters: {'optimizer': 'RMSprop', 'lr': 1.0208822018935845e-05, 'n_layers': 3, 'n_units_l0': 53, 'n_units_l1': 127, 'n_units_l2': 73}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:17:20,718] Trial 295 failed with parameters: {'optimizer': 'SGD', 'lr': 2.1597759916149873e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 104, 'n_units_l2': 63} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:17:20,721] Trial 295 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:17:30,093] Trial 296 failed with parameters: {'optimizer': 'SGD', 'lr': 2.0452609799386293e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 91, 'n_units_l2': 63} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:17:30,101] Trial 296 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:17:40,825] Trial 297 failed with parameters: {'optimizer': 'SGD', 'lr': 2.1169774514738677e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 91, 'n_units_l2': 84} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:17:40,827] Trial 297 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:17:50,949] Trial 298 failed with parameters: {'optimizer': 'SGD', 'lr': 2.040080247273818e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 92, 'n_units_l2': 86} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:17:50,951] Trial 298 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:18:02,080] Trial 299 finished with value: 625.0740966796875 and parameters: {'optimizer': 'RMSprop', 'lr': 2.0396000394361517e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 91, 'n_units_l2': 66}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:18:12,402] Trial 300 failed with parameters: {'optimizer': 'SGD', 'lr': 1.4926018668670324e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 102, 'n_units_l2': 91} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:18:12,404] Trial 300 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:18:22,702] Trial 301 finished with value: 8.19958782196045 and parameters: {'optimizer': 'RMSprop', 'lr': 1.4571445444941812e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 103, 'n_units_l2': 62}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:18:33,635] Trial 302 failed with parameters: {'optimizer': 'SGD', 'lr': 1.25347085094115e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 75, 'n_units_l2': 71} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:18:33,637] Trial 302 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:18:43,051] Trial 303 finished with value: 15.086369514465332 and parameters: {'optimizer': 'RMSprop', 'lr': 2.5026109392885132e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 69, 'n_units_l2': 72}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:18:54,243] Trial 304 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2387391580451294e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 96, 'n_units_l2': 85} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:18:54,245] Trial 304 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:19:05,319] Trial 305 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2712062692871229e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 76, 'n_units_l2': 86} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:19:05,321] Trial 305 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:19:16,364] Trial 306 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2411996437387771e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 97, 'n_units_l2': 95} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:19:16,366] Trial 306 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:19:27,413] Trial 307 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2242424901805247e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 77, 'n_units_l2': 87} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:19:27,415] Trial 307 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:19:38,054] Trial 308 failed with parameters: {'optimizer': 'SGD', 'lr': 1.202104408373329e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 76, 'n_units_l2': 82} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:19:38,056] Trial 308 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:19:59,490] Trial 309 failed with parameters: {'optimizer': 'SGD', 'lr': 1.6754949215379115e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 97, 'n_units_l2': 86} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:19:59,492] Trial 309 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:20:10,552] Trial 310 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2473614959510478e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 108, 'n_units_l2': 82} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:20:10,555] Trial 310 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:20:19,462] Trial 311 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2619345770597293e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 76, 'n_units_l2': 86} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:20:19,464] Trial 311 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:20:30,488] Trial 312 failed with parameters: {'optimizer': 'SGD', 'lr': 1.240178856540248e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 77, 'n_units_l2': 41} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:20:30,490] Trial 312 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:20:40,530] Trial 313 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2537159610714125e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 78, 'n_units_l2': 86} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:20:40,532] Trial 313 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:20:51,645] Trial 314 finished with value: 19.73296546936035 and parameters: {'optimizer': 'RMSprop', 'lr': 1.2419240780051197e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 78, 'n_units_l2': 86}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:21:02,702] Trial 315 failed with parameters: {'optimizer': 'SGD', 'lr': 1.741952974425732e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 110, 'n_units_l2': 82} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:21:02,704] Trial 315 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:21:13,752] Trial 316 failed with parameters: {'optimizer': 'SGD', 'lr': 1.5657009223054194e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 107, 'n_units_l2': 41} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:21:13,753] Trial 316 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:21:24,687] Trial 317 failed with parameters: {'optimizer': 'SGD', 'lr': 1.56027326515296e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 109, 'n_units_l2': 40} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:21:24,689] Trial 317 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:21:35,646] Trial 318 failed with parameters: {'optimizer': 'SGD', 'lr': 1.772446226902746e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 75, 'n_units_l2': 39} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:21:35,648] Trial 318 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:21:44,723] Trial 319 failed with parameters: {'optimizer': 'SGD', 'lr': 1.6767658362594937e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 98, 'n_units_l2': 93} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:21:44,724] Trial 319 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 22:21:56,209] Trial 320 finished with value: 13.452498435974121 and parameters: {'optimizer': 'Adam', 'lr': 1.6486460701621662e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 96, 'n_units_l2': 39}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:22:06,275] Trial 321 failed with parameters: {'optimizer': 'SGD', 'lr': 2.0181916031704604e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 88, 'n_units_l2': 82} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:22:06,277] Trial 321 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:22:15,848] Trial 322 failed with parameters: {'optimizer': 'SGD', 'lr': 2.1572500810146645e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 76, 'n_units_l2': 68} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:22:15,850] Trial 322 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:22:26,797] Trial 323 failed with parameters: {'optimizer': 'SGD', 'lr': 2.103019063366701e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 108, 'n_units_l2': 80} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:22:26,799] Trial 323 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:22:35,926] Trial 324 failed with parameters: {'optimizer': 'SGD', 'lr': 1.9891642211004153e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 75, 'n_units_l2': 69} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:22:35,929] Trial 324 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:22:49,646] Trial 325 failed with parameters: {'optimizer': 'SGD', 'lr': 2.0411673783378658e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 111, 'n_units_l2': 80} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:22:49,648] Trial 325 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:22:59,071] Trial 326 failed with parameters: {'optimizer': 'SGD', 'lr': 1.985818835590145e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 61, 'n_units_l2': 81} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:22:59,073] Trial 326 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:23:10,282] Trial 327 failed with parameters: {'optimizer': 'SGD', 'lr': 2.0698356413090993e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 60, 'n_units_l2': 95} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:23:10,283] Trial 327 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:23:20,183] Trial 328 finished with value: 102.1751937866211 and parameters: {'optimizer': 'RMSprop', 'lr': 1.959863457121928e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 62, 'n_units_l2': 69}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:23:30,637] Trial 329 finished with value: 12.817835807800293 and parameters: {'optimizer': 'RMSprop', 'lr': 1.2284505788891867e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 108, 'n_units_l2': 46}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:23:41,497] Trial 330 failed with parameters: {'optimizer': 'SGD', 'lr': 2.3743417443417872e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 87, 'n_units_l2': 95} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:23:41,499] Trial 330 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:23:52,494] Trial 331 failed with parameters: {'optimizer': 'SGD', 'lr': 1.530174555581384e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 74, 'n_units_l2': 83} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:23:52,495] Trial 331 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:24:01,586] Trial 332 failed with parameters: {'optimizer': 'SGD', 'lr': 2.3627142462314314e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 88, 'n_units_l2': 94} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:24:01,590] Trial 332 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:24:12,978] Trial 333 finished with value: 25.623493194580078 and parameters: {'optimizer': 'RMSprop', 'lr': 2.398465362046934e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 86, 'n_units_l2': 101}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:24:24,168] Trial 334 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3125546691760042e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 75, 'n_units_l2': 83} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:24:24,170] Trial 334 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:24:35,158] Trial 335 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3848430522608444e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 75, 'n_units_l2': 57} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:24:35,161] Trial 335 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:24:46,103] Trial 336 failed with parameters: {'optimizer': 'SGD', 'lr': 1.4104179504373633e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 74, 'n_units_l2': 59} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:24:46,106] Trial 336 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:24:57,232] Trial 337 finished with value: 9.18651008605957 and parameters: {'optimizer': 'RMSprop', 'lr': 1.3259477114571573e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 76, 'n_units_l2': 63}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:25:07,227] Trial 338 finished with value: 14.939099311828613 and parameters: {'optimizer': 'RMSprop', 'lr': 1.6140130807828797e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 87, 'n_units_l2': 79}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:25:16,187] Trial 339 failed with parameters: {'optimizer': 'SGD', 'lr': 1.1903445384260864e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 67, 'n_units_l2': 36} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:25:16,189] Trial 339 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:25:27,503] Trial 340 failed with parameters: {'optimizer': 'SGD', 'lr': 1.258653368152325e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 68, 'n_units_l2': 59} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:25:27,505] Trial 340 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:25:36,798] Trial 341 failed with parameters: {'optimizer': 'SGD', 'lr': 1.0020994865984076e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 67, 'n_units_l2': 57} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:25:36,800] Trial 341 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:25:46,404] Trial 342 finished with value: 2.4964029788970947 and parameters: {'optimizer': 'RMSprop', 'lr': 1.1798229740251347e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 82, 'n_units_l2': 59}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:25:55,993] Trial 343 failed with parameters: {'optimizer': 'SGD', 'lr': 1.0529953641713027e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 68, 'n_units_l2': 34} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:25:55,995] Trial 343 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:26:05,446] Trial 344 failed with parameters: {'optimizer': 'SGD', 'lr': 1.4599840955618558e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 67, 'n_units_l2': 61} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:26:05,454] Trial 344 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:26:14,393] Trial 345 finished with value: 43.0509033203125 and parameters: {'optimizer': 'RMSprop', 'lr': 1.5179148496967166e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 69, 'n_units_l2': 66}. Best is trial 56 with value: 2.123854875564575.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:26:23,418] Trial 346 failed with parameters: {'optimizer': 'SGD', 'lr': 1.038142647598949e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 57, 'n_units_l2': 36} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:26:23,419] Trial 346 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:26:34,371] Trial 347 failed with parameters: {'optimizer': 'SGD', 'lr': 1.0040416236048865e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 57, 'n_units_l2': 37} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:26:34,373] Trial 347 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:26:45,416] Trial 348 failed with parameters: {'optimizer': 'SGD', 'lr': 1.0230347131859826e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 56, 'n_units_l2': 42} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:26:45,418] Trial 348 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:26:56,342] Trial 349 failed with parameters: {'optimizer': 'SGD', 'lr': 1.0983097453952458e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 57, 'n_units_l2': 42} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:26:56,344] Trial 349 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:27:07,292] Trial 350 failed with parameters: {'optimizer': 'SGD', 'lr': 1.036744111062074e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 58, 'n_units_l2': 34} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:27:07,294] Trial 350 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:27:16,568] Trial 351 finished with value: 2.040564775466919 and parameters: {'optimizer': 'RMSprop', 'lr': 1.015344475274754e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 76, 'n_units_l2': 35}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:27:25,887] Trial 352 failed with parameters: {'optimizer': 'SGD', 'lr': 1.11806018558379e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 56, 'n_units_l2': 34} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:27:25,888] Trial 352 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:27:35,550] Trial 353 finished with value: 46.01299285888672 and parameters: {'optimizer': 'RMSprop', 'lr': 1.3306998763702211e-05, 'n_layers': 3, 'n_units_l0': 12, 'n_units_l1': 59, 'n_units_l2': 42}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:27:44,704] Trial 354 failed with parameters: {'optimizer': 'SGD', 'lr': 1.0026390453564817e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 74, 'n_units_l2': 84} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:27:44,705] Trial 354 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:27:53,631] Trial 355 finished with value: 16.988998413085938 and parameters: {'optimizer': 'RMSprop', 'lr': 1.0819858360408079e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 75, 'n_units_l2': 82}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:28:04,783] Trial 356 failed with parameters: {'optimizer': 'SGD', 'lr': 1.0139173548607293e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 65, 'n_units_l2': 61} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:28:04,784] Trial 356 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:28:13,945] Trial 357 failed with parameters: {'optimizer': 'SGD', 'lr': 1.0322756524821306e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 56, 'n_units_l2': 72} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:28:13,946] Trial 357 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:28:24,925] Trial 358 failed with parameters: {'optimizer': 'SGD', 'lr': 1.1314486174045618e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 65, 'n_units_l2': 72} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:28:24,928] Trial 358 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:28:34,611] Trial 359 failed with parameters: {'optimizer': 'SGD', 'lr': 1.0071255481134436e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 65, 'n_units_l2': 33} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:28:34,613] Trial 359 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:28:45,587] Trial 360 failed with parameters: {'optimizer': 'SGD', 'lr': 1.068582192292883e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 93, 'n_units_l2': 60} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:28:45,589] Trial 360 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:28:56,615] Trial 361 finished with value: 6.868753433227539 and parameters: {'optimizer': 'RMSprop', 'lr': 1.0141070194830071e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 66, 'n_units_l2': 72}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:29:07,757] Trial 362 finished with value: 69.51345825195312 and parameters: {'optimizer': 'RMSprop', 'lr': 1.0791676136478749e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 57, 'n_units_l2': 33}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:29:18,793] Trial 363 finished with value: 14.447863578796387 and parameters: {'optimizer': 'RMSprop', 'lr': 1.1939450615972173e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 66, 'n_units_l2': 92}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:29:28,173] Trial 364 finished with value: 19.22833824157715 and parameters: {'optimizer': 'RMSprop', 'lr': 1.4234455461665661e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 94, 'n_units_l2': 72}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:29:37,555] Trial 365 failed with parameters: {'optimizer': 'SGD', 'lr': 2.1442022293221847e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 70, 'n_units_l2': 59} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:29:37,557] Trial 365 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:29:46,690] Trial 366 failed with parameters: {'optimizer': 'SGD', 'lr': 2.0574159513921196e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 73, 'n_units_l2': 60} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:29:46,692] Trial 366 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:29:55,768] Trial 367 failed with parameters: {'optimizer': 'SGD', 'lr': 2.066906579393993e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 73, 'n_units_l2': 60} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:29:55,770] Trial 367 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:30:06,818] Trial 368 finished with value: 9.706717491149902 and parameters: {'optimizer': 'RMSprop', 'lr': 1.0218826137436456e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 73, 'n_units_l2': 59}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:30:18,017] Trial 369 failed with parameters: {'optimizer': 'SGD', 'lr': 1.8289155702860836e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 63, 'n_units_l2': 63} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:30:18,023] Trial 369 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:30:29,334] Trial 370 failed with parameters: {'optimizer': 'SGD', 'lr': 2.1012630115148083e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 63, 'n_units_l2': 64} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:30:29,336] Trial 370 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:30:39,111] Trial 371 finished with value: 3.6758594512939453 and parameters: {'optimizer': 'RMSprop', 'lr': 2.1119979701040416e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 65, 'n_units_l2': 72}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:30:48,090] Trial 372 failed with parameters: {'optimizer': 'SGD', 'lr': 2.106131176848986e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 63, 'n_units_l2': 74} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:30:48,091] Trial 372 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:30:57,111] Trial 373 failed with parameters: {'optimizer': 'SGD', 'lr': 2.1873948166577955e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 62, 'n_units_l2': 73} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:30:57,113] Trial 373 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:31:08,061] Trial 374 failed with parameters: {'optimizer': 'SGD', 'lr': 2.06729375426515e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 64, 'n_units_l2': 63} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:31:08,062] Trial 374 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:31:16,693] Trial 375 finished with value: 16.363143920898438 and parameters: {'optimizer': 'RMSprop', 'lr': 2.0388566508043088e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 65, 'n_units_l2': 73}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:31:27,639] Trial 376 failed with parameters: {'optimizer': 'SGD', 'lr': 2.866971049744719e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 54, 'n_units_l2': 62} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:31:27,643] Trial 376 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:31:38,725] Trial 377 failed with parameters: {'optimizer': 'SGD', 'lr': 3.1456351592651835e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 56, 'n_units_l2': 28} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:31:38,730] Trial 377 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:31:47,729] Trial 378 failed with parameters: {'optimizer': 'SGD', 'lr': 1.74145633525733e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 55, 'n_units_l2': 63} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:31:47,730] Trial 378 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:31:58,678] Trial 379 failed with parameters: {'optimizer': 'SGD', 'lr': 1.769832142049116e-05, 'n_layers': 3, 'n_units_l0': 120, 'n_units_l1': 63, 'n_units_l2': 64} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:31:58,680] Trial 379 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:32:09,713] Trial 380 finished with value: 416.1938781738281 and parameters: {'optimizer': 'RMSprop', 'lr': 3.063393939860902e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 56, 'n_units_l2': 29}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:32:18,151] Trial 381 failed with parameters: {'optimizer': 'SGD', 'lr': 1.761200438413183e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 62, 'n_units_l2': 62} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:32:18,153] Trial 381 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:32:27,475] Trial 382 failed with parameters: {'optimizer': 'SGD', 'lr': 1.0000525665904056e-05, 'n_layers': 3, 'n_units_l0': 38, 'n_units_l1': 63, 'n_units_l2': 52} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:32:27,477] Trial 382 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:32:36,878] Trial 383 failed with parameters: {'optimizer': 'SGD', 'lr': 1.689857255759509e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 61, 'n_units_l2': 51} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:32:36,880] Trial 383 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:32:46,191] Trial 384 failed with parameters: {'optimizer': 'SGD', 'lr': 1.7492744032837417e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 61, 'n_units_l2': 61} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:32:46,193] Trial 384 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:32:57,093] Trial 385 failed with parameters: {'optimizer': 'SGD', 'lr': 1.7570681602180702e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 61, 'n_units_l2': 62} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:32:57,094] Trial 385 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "[I 2024-04-03 22:33:06,685] Trial 386 finished with value: 75.67491912841797 and parameters: {'optimizer': 'Adam', 'lr': 1.7244542531515786e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 61, 'n_units_l2': 38}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:33:16,194] Trial 387 failed with parameters: {'optimizer': 'SGD', 'lr': 2.202377558544775e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 69, 'n_units_l2': 63} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:33:16,196] Trial 387 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:33:27,249] Trial 388 finished with value: 54.6242790222168 and parameters: {'optimizer': 'RMSprop', 'lr': 2.1477930560741844e-05, 'n_layers': 3, 'n_units_l0': 123, 'n_units_l1': 89, 'n_units_l2': 63}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:33:36,677] Trial 389 finished with value: 18.50320053100586 and parameters: {'optimizer': 'RMSprop', 'lr': 1.2124923755461563e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 69, 'n_units_l2': 53}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:33:47,606] Trial 390 finished with value: 4489.5517578125 and parameters: {'optimizer': 'RMSprop', 'lr': 2.6100032119372734e-05, 'n_layers': 2, 'n_units_l0': 4, 'n_units_l1': 64}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:33:58,728] Trial 391 finished with value: 25.164182662963867 and parameters: {'optimizer': 'RMSprop', 'lr': 1.0150823515139034e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 98, 'n_units_l2': 35}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:34:09,738] Trial 392 failed with parameters: {'optimizer': 'SGD', 'lr': 1.5055753911872973e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 77, 'n_units_l2': 68} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:34:09,740] Trial 392 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:34:20,741] Trial 393 failed with parameters: {'optimizer': 'SGD', 'lr': 1.5226575767394124e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 79, 'n_units_l2': 70} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:34:20,743] Trial 393 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:34:29,506] Trial 394 failed with parameters: {'optimizer': 'SGD', 'lr': 1.5424665285682132e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 78, 'n_units_l2': 68} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:34:29,508] Trial 394 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:34:38,889] Trial 395 failed with parameters: {'optimizer': 'SGD', 'lr': 1.6210681414928354e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 73, 'n_units_l2': 67} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:34:38,892] Trial 395 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:34:49,820] Trial 396 failed with parameters: {'optimizer': 'SGD', 'lr': 1.5433801585638028e-05, 'n_layers': 3, 'n_units_l0': 27, 'n_units_l1': 79, 'n_units_l2': 66} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:34:49,822] Trial 396 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:35:00,825] Trial 397 failed with parameters: {'optimizer': 'SGD', 'lr': 1.609434416827714e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 79, 'n_units_l2': 69} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:35:00,827] Trial 397 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:35:10,515] Trial 398 failed with parameters: {'optimizer': 'SGD', 'lr': 1.4972980541249597e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 78, 'n_units_l2': 66} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:35:10,516] Trial 398 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:35:21,591] Trial 399 finished with value: 18.1328067779541 and parameters: {'optimizer': 'RMSprop', 'lr': 1.5067934312481908e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 77, 'n_units_l2': 68}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:35:30,386] Trial 400 failed with parameters: {'optimizer': 'SGD', 'lr': 0.05666156656533341, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 82, 'n_units_l2': 41} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:35:30,388] Trial 400 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:35:39,802] Trial 401 failed with parameters: {'optimizer': 'SGD', 'lr': 1.8090238590334167e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 71, 'n_units_l2': 75} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:35:39,804] Trial 401 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:35:50,775] Trial 402 failed with parameters: {'optimizer': 'SGD', 'lr': 1.7357804451117563e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 81, 'n_units_l2': 81} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:35:50,777] Trial 402 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:35:59,942] Trial 403 failed with parameters: {'optimizer': 'SGD', 'lr': 1.724636554842842e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 81, 'n_units_l2': 82} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:35:59,944] Trial 403 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:36:10,875] Trial 404 failed with parameters: {'optimizer': 'SGD', 'lr': 1.717061610678912e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 81, 'n_units_l2': 75} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:36:10,877] Trial 404 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:36:19,841] Trial 405 finished with value: 851.6298217773438 and parameters: {'optimizer': 'RMSprop', 'lr': 1.7545797734383738e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 83, 'n_units_l2': 41}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:36:29,451] Trial 406 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3385424009708086e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 72, 'n_units_l2': 75} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:36:29,453] Trial 406 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:36:38,822] Trial 407 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3858359020027932e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 70, 'n_units_l2': 77} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:36:38,823] Trial 407 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:36:52,011] Trial 408 failed with parameters: {'optimizer': 'SGD', 'lr': 0.05495722467374903, 'n_layers': 3, 'n_units_l0': 107, 'n_units_l1': 73, 'n_units_l2': 83} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:36:52,013] Trial 408 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:37:02,166] Trial 409 finished with value: 16.763591766357422 and parameters: {'optimizer': 'RMSprop', 'lr': 1.4505711950101752e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 54, 'n_units_l2': 82}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:37:12,516] Trial 410 finished with value: 102.78208923339844 and parameters: {'optimizer': 'RMSprop', 'lr': 1.2542802437982285e-05, 'n_layers': 3, 'n_units_l0': 35, 'n_units_l1': 74, 'n_units_l2': 60}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:37:23,548] Trial 411 failed with parameters: {'optimizer': 'SGD', 'lr': 2.0581183719440748e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 92, 'n_units_l2': 75} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:37:23,550] Trial 411 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:37:33,814] Trial 412 failed with parameters: {'optimizer': 'SGD', 'lr': 2.16200046595165e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 89, 'n_units_l2': 75} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:37:33,816] Trial 412 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:37:43,198] Trial 413 failed with parameters: {'optimizer': 'SGD', 'lr': 2.0946072154717177e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 90, 'n_units_l2': 75} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:37:43,199] Trial 413 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:37:54,192] Trial 414 failed with parameters: {'optimizer': 'SGD', 'lr': 2.054701645781108e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 92, 'n_units_l2': 75} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:37:54,194] Trial 414 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:38:03,833] Trial 415 finished with value: 14.170119285583496 and parameters: {'optimizer': 'RMSprop', 'lr': 2.012123545195703e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 91, 'n_units_l2': 75}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:38:13,218] Trial 416 failed with parameters: {'optimizer': 'SGD', 'lr': 1.570588258702104e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 81, 'n_units_l2': 69} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:38:13,220] Trial 416 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:38:22,146] Trial 417 failed with parameters: {'optimizer': 'SGD', 'lr': 0.05966535856139679, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 68, 'n_units_l2': 69} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:38:22,148] Trial 417 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:38:33,366] Trial 418 failed with parameters: {'optimizer': 'SGD', 'lr': 1.4952345446764927e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 69, 'n_units_l2': 68} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:38:33,368] Trial 418 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:38:44,509] Trial 419 finished with value: 19.25726318359375 and parameters: {'optimizer': 'RMSprop', 'lr': 1.570265907519811e-05, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 81, 'n_units_l2': 69}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:38:55,617] Trial 420 failed with parameters: {'optimizer': 'SGD', 'lr': 1.005489686650973e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 69, 'n_units_l2': 95} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:38:55,619] Trial 420 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:39:05,412] Trial 421 finished with value: 10.164806365966797 and parameters: {'optimizer': 'RMSprop', 'lr': 1.016432121719051e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 61, 'n_units_l2': 65}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:39:15,063] Trial 422 failed with parameters: {'optimizer': 'SGD', 'lr': 1.3092840416455126e-05, 'n_layers': 3, 'n_units_l0': 29, 'n_units_l1': 70, 'n_units_l2': 95} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:39:15,064] Trial 422 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:39:23,970] Trial 423 failed with parameters: {'optimizer': 'SGD', 'lr': 1.325806740296368e-05, 'n_layers': 3, 'n_units_l0': 27, 'n_units_l1': 72, 'n_units_l2': 47} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:39:23,972] Trial 423 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:39:33,926] Trial 424 finished with value: 6.343665599822998 and parameters: {'optimizer': 'RMSprop', 'lr': 1.3984945404844866e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 72, 'n_units_l2': 58}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:39:44,880] Trial 425 failed with parameters: {'optimizer': 'SGD', 'lr': 1.255635711313966e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 68, 'n_units_l2': 50} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:39:44,881] Trial 425 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:39:53,962] Trial 426 failed with parameters: {'optimizer': 'SGD', 'lr': 2.3402594051771276e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 70, 'n_units_l2': 48} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:39:53,964] Trial 426 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:40:04,897] Trial 427 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2183280692602294e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 70, 'n_units_l2': 49} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:40:04,899] Trial 427 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:40:15,891] Trial 428 failed with parameters: {'optimizer': 'SGD', 'lr': 2.2914826577493234e-05, 'n_layers': 3, 'n_units_l0': 108, 'n_units_l1': 67, 'n_units_l2': 46} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:40:15,893] Trial 428 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:40:26,912] Trial 429 failed with parameters: {'optimizer': 'SGD', 'lr': 1.2613833117684198e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 68, 'n_units_l2': 47} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:40:26,915] Trial 429 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n",
            "[I 2024-04-03 22:40:38,041] Trial 430 finished with value: 4.508717060089111 and parameters: {'optimizer': 'RMSprop', 'lr': 1.251540789139039e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 69, 'n_units_l2': 45}. Best is trial 351 with value: 2.040564775466919.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:40:46,744] Trial 431 failed with parameters: {'optimizer': 'SGD', 'lr': 2.323421827801675e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 69, 'n_units_l2': 48} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:40:46,745] Trial 431 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:40:57,708] Trial 432 failed with parameters: {'optimizer': 'SGD', 'lr': 2.3633769163455528e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 70, 'n_units_l2': 45} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:40:57,709] Trial 432 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:41:08,652] Trial 433 failed with parameters: {'optimizer': 'SGD', 'lr': 2.3186743254234134e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 71, 'n_units_l2': 49} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:41:08,653] Trial 433 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:41:18,481] Trial 434 failed with parameters: {'optimizer': 'SGD', 'lr': 2.331040043803801e-05, 'n_layers': 3, 'n_units_l0': 85, 'n_units_l1': 70, 'n_units_l2': 43} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:41:18,483] Trial 434 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:41:29,521] Trial 435 failed with parameters: {'optimizer': 'SGD', 'lr': 1.7839050365858036e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 70, 'n_units_l2': 55} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:41:29,524] Trial 435 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:41:39,031] Trial 436 failed with parameters: {'optimizer': 'SGD', 'lr': 2.435263935705347e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 69, 'n_units_l2': 46} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:41:39,033] Trial 436 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:41:50,271] Trial 437 failed with parameters: {'optimizer': 'SGD', 'lr': 1.9143942326035863e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 70, 'n_units_l2': 44} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:41:50,274] Trial 437 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:42:01,601] Trial 438 failed with parameters: {'optimizer': 'SGD', 'lr': 1.8509765808067126e-05, 'n_layers': 3, 'n_units_l0': 104, 'n_units_l1': 71, 'n_units_l2': 46} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:42:01,605] Trial 438 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:42:10,723] Trial 439 failed with parameters: {'optimizer': 'SGD', 'lr': 2.3091558137056957e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 68, 'n_units_l2': 48} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:42:10,725] Trial 439 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:42:19,857] Trial 440 failed with parameters: {'optimizer': 'SGD', 'lr': 2.3013822035770306e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 67, 'n_units_l2': 47} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:42:19,858] Trial 440 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:42:30,811] Trial 441 failed with parameters: {'optimizer': 'SGD', 'lr': 2.2318266435314094e-05, 'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 69, 'n_units_l2': 46} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:42:30,813] Trial 441 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
            "[W 2024-04-03 22:42:40,629] Trial 442 failed with parameters: {'optimizer': 'SGD', 'lr': 1.7720887863275695e-05, 'n_layers': 3, 'n_units_l0': 104, 'n_units_l1': 72, 'n_units_l2': 47} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-03 22:42:40,634] Trial 442 failed with value nan.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TrialError対策：lr：１e−１〜1e-5 → 〜1e-4＋optimizerの定義修正 row37-43"
      ],
      "metadata": {
        "id": "SXn1LE8q39Uc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### code"
      ],
      "metadata": {
        "id": "Ie9j9i5I4X1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# データセットの準備（ここでは合成データセットを使用）\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# データのスケーリング\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 目的関数の定義\n",
        "def objective(trial):\n",
        "    # オプティマイザの選択\n",
        "    optimizer_options = ['Adam', 'SGD', 'RMSprop']\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', optimizer_options)\n",
        "    lr = trial.suggest_float('lr', 1e-3, 1e-1, log=True)\n",
        "\n",
        "    # モデルの構築\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.Input(shape=(X_train.shape[1],)))\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 5)\n",
        "    for i in range(n_layers):\n",
        "        num_hidden = trial.suggest_int('n_units_l{}'.format(i), 4, 128, log=True)\n",
        "        model.add(Dense(num_hidden, activation='relu'))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # オプティマイザの設定\n",
        "    if optimizer_name == 'Adam':\n",
        "        # optimizer = Adam(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
        "    elif optimizer_name == 'SGD':\n",
        "        # optimizer = SGD(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)\n",
        "    else:\n",
        "        # optimizer = RMSprop(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=lr)\n",
        "\n",
        "    # モデルのコンパイル\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # モデルの訓練\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return loss\n",
        "\n",
        "# Studyオブジェクトの作成\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=5)\n",
        "\n",
        "# 最適化されたハイパーパラメータの出力\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:')\n",
        "trial = study.best_trial\n",
        "print('Value: {}'.format(trial.value))\n",
        "print('Params: ')\n",
        "for key, value in trial.params.items():\n",
        "    print('    {}: {}'.format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq0gyQNN395K",
        "outputId": "1bfe8a59-be6f-4c60-b0ec-7e58fa7ec3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-04 21:03:14,814] A new study created in memory with name: no-name-e6b17f10-a6be-4cba-9696-845b239d350a\n",
            "[I 2024-04-04 21:03:30,134] Trial 0 finished with value: 42.74287414550781 and parameters: {'optimizer': 'RMSprop', 'lr': 0.002767056982018216, 'n_layers': 3, 'n_units_l0': 68, 'n_units_l1': 10, 'n_units_l2': 54}. Best is trial 0 with value: 42.74287414550781.\n",
            "[I 2024-04-04 21:03:41,386] Trial 1 finished with value: 1124.7144775390625 and parameters: {'optimizer': 'RMSprop', 'lr': 0.039804393302957916, 'n_layers': 5, 'n_units_l0': 80, 'n_units_l1': 31, 'n_units_l2': 46, 'n_units_l3': 5, 'n_units_l4': 8}. Best is trial 0 with value: 42.74287414550781.\n",
            "[W 2024-04-04 21:03:50,439] Trial 2 failed with parameters: {'optimizer': 'SGD', 'lr': 0.03630615360002479, 'n_layers': 3, 'n_units_l0': 41, 'n_units_l1': 93, 'n_units_l2': 30} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-04 21:03:50,441] Trial 2 failed with value nan.\n",
            "[I 2024-04-04 21:04:01,363] Trial 3 finished with value: 4.428550720214844 and parameters: {'optimizer': 'Adam', 'lr': 0.004481620346106821, 'n_layers': 4, 'n_units_l0': 8, 'n_units_l1': 4, 'n_units_l2': 6, 'n_units_l3': 8}. Best is trial 3 with value: 4.428550720214844.\n",
            "[I 2024-04-04 21:04:10,904] Trial 4 finished with value: 365.864013671875 and parameters: {'optimizer': 'Adam', 'lr': 0.02200461546182985, 'n_layers': 4, 'n_units_l0': 70, 'n_units_l1': 6, 'n_units_l2': 55, 'n_units_l3': 68}. Best is trial 3 with value: 4.428550720214844.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 5\n",
            "Best trial:\n",
            "Value: 4.428550720214844\n",
            "Params: \n",
            "    optimizer: Adam\n",
            "    lr: 0.004481620346106821\n",
            "    n_layers: 4\n",
            "    n_units_l0: 8\n",
            "    n_units_l1: 4\n",
            "    n_units_l2: 6\n",
            "    n_units_l3: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD Only → ErrorSGD多いので原因特定する"
      ],
      "metadata": {
        "id": "V46hhRE98LEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  → SGDはすべてnanになっている ⇒ 使用しない"
      ],
      "metadata": {
        "id": "6EUR3WgG9CZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### code"
      ],
      "metadata": {
        "id": "4E3p7DRG8XiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# データセットの準備（ここでは合成データセットを使用）\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# データのスケーリング\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 目的関数の定義\n",
        "def objective(trial):\n",
        "    # オプティマイザの選択\n",
        "    optimizer_options = [ 'SGD']\n",
        "    # optimizer_options = ['Adam', 'SGD', 'RMSprop']\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', optimizer_options)\n",
        "    lr = trial.suggest_float('lr', 1e-3, 1e-1, log=True)\n",
        "\n",
        "    # モデルの構築\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.Input(shape=(X_train.shape[1],)))\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 5)\n",
        "    for i in range(n_layers):\n",
        "        num_hidden = trial.suggest_int('n_units_l{}'.format(i), 4, 128, log=True)\n",
        "        model.add(Dense(num_hidden, activation='relu'))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # オプティマイザの設定\n",
        "    optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)\n",
        "    # if optimizer_name == 'Adam':\n",
        "    #     # optimizer = Adam(lr=lr)\n",
        "    #     optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
        "    # elif optimizer_name == 'SGD':\n",
        "    #     # optimizer = SGD(lr=lr)\n",
        "    #     optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)\n",
        "    # else:\n",
        "    #     # optimizer = RMSprop(lr=lr)\n",
        "    #     optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=lr)\n",
        "\n",
        "    # モデルのコンパイル\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # モデルの訓練\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return loss\n",
        "\n",
        "# Studyオブジェクトの作成\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=5)\n",
        "\n",
        "# 最適化されたハイパーパラメータの出力\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:')\n",
        "trial = study.best_trial\n",
        "print('Value: {}'.format(trial.value))\n",
        "print('Params: ')\n",
        "for key, value in trial.params.items():\n",
        "    print('    {}: {}'.format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "nEe9QfmI8L67",
        "outputId": "a8002337-e8c0-4adf-ec7f-c5ca919708db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-04 21:10:01,508] A new study created in memory with name: no-name-77f4add5-e489-4668-a2f3-5f8c275722cb\n",
            "[W 2024-04-04 21:10:10,638] Trial 0 failed with parameters: {'optimizer': 'SGD', 'lr': 0.028279603055852223, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 10, 'n_units_l2': 63, 'n_units_l3': 62, 'n_units_l4': 63} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-04 21:10:10,640] Trial 0 failed with value nan.\n",
            "[W 2024-04-04 21:10:18,973] Trial 1 failed with parameters: {'optimizer': 'SGD', 'lr': 0.028230090099443293, 'n_layers': 3, 'n_units_l0': 9, 'n_units_l1': 9, 'n_units_l2': 29} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-04 21:10:18,974] Trial 1 failed with value nan.\n",
            "[W 2024-04-04 21:10:30,014] Trial 2 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0453029559259462, 'n_layers': 1, 'n_units_l0': 5} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-04 21:10:30,016] Trial 2 failed with value nan.\n",
            "[W 2024-04-04 21:10:40,772] Trial 3 failed with parameters: {'optimizer': 'SGD', 'lr': 0.0024260534074498747, 'n_layers': 3, 'n_units_l0': 103, 'n_units_l1': 14, 'n_units_l2': 52} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-04 21:10:40,773] Trial 3 failed with value nan.\n",
            "[W 2024-04-04 21:10:51,549] Trial 4 failed with parameters: {'optimizer': 'SGD', 'lr': 0.014905037163576473, 'n_layers': 3, 'n_units_l0': 89, 'n_units_l1': 13, 'n_units_l2': 68} because of the following error: The value nan is not acceptable.\n",
            "[W 2024-04-04 21:10:51,552] Trial 4 failed with value nan.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 5\n",
            "Best trial:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No trials are completed yet.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-31e984a71911>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of finished trials:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best trial:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Value: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Params: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36mbest_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m             )\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_study_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/storages/_in_memory.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_trial_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No trials are completed yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_studies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirections\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 raise RuntimeError(\n",
            "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tral failed with value nan対策:HeNormal追加@r8,33"
      ],
      "metadata": {
        "id": "9-bAM4rHxRRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### code"
      ],
      "metadata": {
        "id": "hpBhis-l9el5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "\n",
        "# データセットの準備（ここでは合成データセットを使用）\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# データのスケーリング\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 目的関数の定義\n",
        "def objective(trial):\n",
        "    # オプティマイザの選択※SGDは使用しない\n",
        "    # optimizer_options = ['Adam', 'SGD', 'RMSprop']\n",
        "    optimizer_options = ['Adam', 'RMSprop']\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', optimizer_options)\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "\n",
        "    # モデルの構築\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.Input(shape=(X_train.shape[1],)))\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 5)\n",
        "    for i in range(n_layers):\n",
        "        num_hidden = trial.suggest_int('n_units_l{}'.format(i), 4, 128, log=True)\n",
        "        # model.add(Dense(num_hidden, activation='relu'))\n",
        "        model.add(Dense(num_hidden, activation='relu',kernel_initializer=HeNormal()))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # オプティマイザの設定\n",
        "    if optimizer_name == 'Adam':\n",
        "        # optimizer = Adam(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
        "    # elif optimizer_name == 'SGD':\n",
        "    #     # optimizer = SGD(lr=lr)\n",
        "    #     optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)\n",
        "    else:\n",
        "        # optimizer = RMSprop(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=lr)\n",
        "\n",
        "    # モデルのコンパイル\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # モデルの訓練\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return loss\n",
        "\n",
        "# Studyオブジェクトの作成\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=5)\n",
        "\n",
        "# 最適化されたハイパーパラメータの出力\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:')\n",
        "trial = study.best_trial\n",
        "print('Value: {}'.format(trial.value))\n",
        "print('Params: ')\n",
        "for key, value in trial.params.items():\n",
        "    print('    {}: {}'.format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D01i0h7c9cgA",
        "outputId": "108c376d-07af-4eed-e080-08b98db590b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-05 20:25:21,775] A new study created in memory with name: no-name-dd26a900-1973-47cb-bf95-08502f4b9b55\n",
            "[I 2024-04-05 20:25:32,288] Trial 0 finished with value: 69.12345886230469 and parameters: {'optimizer': 'Adam', 'lr': 0.03240641476495899, 'n_layers': 2, 'n_units_l0': 90, 'n_units_l1': 21}. Best is trial 0 with value: 69.12345886230469.\n",
            "[I 2024-04-05 20:25:55,596] Trial 1 finished with value: 27200.806640625 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00010937405916599952, 'n_layers': 3, 'n_units_l0': 5, 'n_units_l1': 43, 'n_units_l2': 15}. Best is trial 0 with value: 69.12345886230469.\n",
            "[I 2024-04-05 20:26:04,564] Trial 2 finished with value: 12679.333984375 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0001567625772961543, 'n_layers': 5, 'n_units_l0': 4, 'n_units_l1': 92, 'n_units_l2': 57, 'n_units_l3': 16, 'n_units_l4': 4}. Best is trial 0 with value: 69.12345886230469.\n",
            "[I 2024-04-05 20:26:15,280] Trial 3 finished with value: 38243.06640625 and parameters: {'optimizer': 'Adam', 'lr': 2.8015334475901537e-05, 'n_layers': 1, 'n_units_l0': 77}. Best is trial 0 with value: 69.12345886230469.\n",
            "[I 2024-04-05 20:26:27,844] Trial 4 finished with value: 12007.40234375 and parameters: {'optimizer': 'Adam', 'lr': 4.010410122942008e-05, 'n_layers': 3, 'n_units_l0': 55, 'n_units_l1': 120, 'n_units_l2': 33}. Best is trial 0 with value: 69.12345886230469.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 5\n",
            "Best trial:\n",
            "Value: 69.12345886230469\n",
            "Params: \n",
            "    optimizer: Adam\n",
            "    lr: 0.03240641476495899\n",
            "    n_layers: 2\n",
            "    n_units_l0: 90\n",
            "    n_units_l1: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 最適化履歴を外部ファイルに保存\n"
      ],
      "metadata": {
        "id": "0WCsEVcF_R7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### code"
      ],
      "metadata": {
        "id": "dpxjQ-N9B3el"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# データセットの準備（ここでは合成データセットを使用）\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# データのスケーリング\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 目的関数の定義\n",
        "def objective(trial):\n",
        "    # オプティマイザの選択※SGDは使用しない\n",
        "    # optimizer_options = ['Adam', 'SGD', 'RMSprop']\n",
        "    optimizer_options = ['Adam', 'RMSprop']\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', optimizer_options)\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 5 )\n",
        "    n_units_per_layer = [trial.suggest_int(f'n_units_layer{i}', 8, 128) for i in range(n_layers)]\n",
        "    # モデルの構築\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(Dense(n_units_per_layer[0], activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for units in n_units_per_layer[1:]:\n",
        "      model.add(Dense(units, activation='relu',kernel_initializer=HeNormal()))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # オプティマイザの設定\n",
        "    if optimizer_name == 'Adam':\n",
        "        # optimizer = Adam(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
        "    # elif optimizer_name == 'SGD':\n",
        "    #     # optimizer = SGD(lr=lr)\n",
        "    #     optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)\n",
        "    else:\n",
        "        # optimizer = RMSprop(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=lr)\n",
        "\n",
        "    # モデルのコンパイル\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # モデルの訓練\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return loss\n",
        "\n",
        "def write_trial_to_file(study,trial):\n",
        "    # CSVファイルのパスとカラム名を指定\n",
        "    file_path = 'param.csv'\n",
        "\n",
        "    #列名が記載されたDataFrame作成\n",
        "    columns = ['trial_number','loss','optimizer', 'lr', 'batch_size','n_layers']\n",
        "    add_layer_columns=[\"n_units_layer\"+str(i) for i in range(trial.params['n_layers'])]\n",
        "    columns=columns+add_layer_columns\n",
        "    # print(f\"columns名：{columns}\")\n",
        "    trial_df=pd.DataFrame(columns=columns)\n",
        "\n",
        "    # ハイパーパラメータとlossの値を辞書に格納\n",
        "    trial_data = trial.params\n",
        "    # print(trial.params)\n",
        "    trial_data['loss'] = trial.value\n",
        "    trial_data['trial_number'] = trial.number\n",
        "\n",
        "    # DataFrameを作成\n",
        "    data_df=pd.DataFrame([trial_data])\n",
        "    trial_df=pd.concat([trial_df,data_df],ignore_index=True)\n",
        "    # print(f\"dic:{trial_data}\")\n",
        "    # print(f\"dataframe:{trial_df}\")\n",
        "\n",
        "    # 履歴データを書き込み\n",
        "    write_df_to_csv(file_path,trial_df)\n",
        "\n",
        "\n",
        "def write_trial_to_file(study,trial):\n",
        "    # CSVファイルのパスとカラム名を指定\n",
        "    file_path = 'param.csv'\n",
        "    # n_layers=5\n",
        "\n",
        "    #列名が記載されたDataFrame作成\n",
        "    columns = ['trial_number','loss','optimizer', 'lr', 'batch_size','n_layers']\n",
        "    add_layer_columns=[\"n_units_layer\"+str(i) for i in range(trial.params['n_layers'])]\n",
        "    columns=columns+add_layer_columns\n",
        "    # print(f\"columns名：{columns}\")\n",
        "    trial_df=pd.DataFrame(columns=columns)\n",
        "\n",
        "    # ハイパーパラメータとlossの値を辞書に格納\n",
        "    trial_data = trial.params\n",
        "    # print(trial.params)\n",
        "    trial_data['loss'] = trial.value\n",
        "    trial_data['trial_number'] = trial.number\n",
        "\n",
        "    # DataFrameを作成\n",
        "    data_df=pd.DataFrame([trial_data])\n",
        "    trial_df=pd.concat([trial_df,data_df],ignore_index=True)\n",
        "    # print(f\"dic:{trial_data}\")\n",
        "    # print(f\"dataframe:{trial_df}\")\n",
        "\n",
        "    # 履歴データを書き込み\n",
        "    write_df_to_csv(file_path,trial_df)\n",
        "\n",
        "\n",
        "def write_df_to_csv_old(file_path, data_df):\n",
        "  #ファイル書き込みの関数を定義\n",
        "    try:\n",
        "        # ファイルが存在しない場合は新規作成し、カラム名を含めて記載\n",
        "        if not os.path.isfile(file_path):\n",
        "            data_df.to_csv(file_path, index=False)\n",
        "        else:\n",
        "            # ファイルが存在する場合はデータのみを追記\n",
        "            data_df.to_csv(file_path, mode='a', header=False, index=False)\n",
        "    except Exception as e:\n",
        "        # エラーが発生した場合の処理\n",
        "        print(f'ファイル書き込み中にエラーが発生しました: {e}')\n",
        "\n",
        "def write_df_to_csv(file_path, data_df):\n",
        "  #ファイル書き込みの関数を定義\n",
        "    try:\n",
        "      # 既存のCSVファイルがあるかチェック\n",
        "      if os.path.isfile(file_path):\n",
        "          # 既存のCSVファイルを読み込む\n",
        "          existing_df = pd.read_csv(file_path)\n",
        "          # 新しいデータを結合する\n",
        "          ##※データ欠損は0で補完\n",
        "          combined_df = pd.concat([existing_df, data_df], axis=0, ignore_index=True).fillna(0)\n",
        "      else:\n",
        "          # CSVファイルが存在しない場合は新しいDataFrameを作成\n",
        "          combined_df = data_df\n",
        "\n",
        "      # 結合したDataFrameをCSVに書き込む\n",
        "      combined_df.to_csv(file_path, index=False)\n",
        "    except Exception as e:\n",
        "        # エラーが発生した場合の処理\n",
        "        print(f'ファイル書き込み中にエラーが発生しました: {e}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    # Studyオブジェクトの作成\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(objective, n_trials=2,callbacks=[write_trial_to_file])\n",
        "\n",
        "    # 最適化されたハイパーパラメータの出力\n",
        "    print('Number of finished trials:', len(study.trials))\n",
        "    print('Best trial:')\n",
        "    trial = study.best_trial\n",
        "    print('Value: {}'.format(trial.value))\n",
        "    print('Params: ')\n",
        "    for key, value in trial.params.items():\n",
        "        print('    {}: {}'.format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY_DtDiBAcco",
        "outputId": "d3f286b7-ba56-43df-8ee2-33992a53275c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-06 07:51:13,690] A new study created in memory with name: no-name-2f59cae1-b3af-4ee4-9668-3b5d8fe9e718\n",
            "[I 2024-04-06 07:51:22,934] Trial 0 finished with value: 20129.25390625 and parameters: {'optimizer': 'Adam', 'lr': 0.0002106424719857633, 'n_layers': 1, 'n_units_layer0': 84}. Best is trial 0 with value: 20129.25390625.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dic:{'optimizer': 'Adam', 'lr': 0.0002106424719857633, 'n_layers': 1, 'n_units_layer0': 84, 'loss': 20129.25390625, 'trial_number': 0}\n",
            "dataframe:  trial_number          loss optimizer        lr batch_size n_layers  \\\n",
            "0            0  20129.253906      Adam  0.000211        NaN        1   \n",
            "\n",
            "  n_units_layer0  \n",
            "0             84  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-06 07:51:44,153] Trial 1 finished with value: 37924.65625 and parameters: {'optimizer': 'Adam', 'lr': 3.643854540693037e-05, 'n_layers': 1, 'n_units_layer0': 106}. Best is trial 0 with value: 20129.25390625.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dic:{'optimizer': 'Adam', 'lr': 3.643854540693037e-05, 'n_layers': 1, 'n_units_layer0': 106, 'loss': 37924.65625, 'trial_number': 1}\n",
            "dataframe:  trial_number         loss optimizer        lr batch_size n_layers  \\\n",
            "0            1  37924.65625      Adam  0.000036        NaN        1   \n",
            "\n",
            "  n_units_layer0  \n",
            "0            106  \n",
            "Number of finished trials: 2\n",
            "Best trial:\n",
            "Value: 20129.25390625\n",
            "Params: \n",
            "    optimizer: Adam\n",
            "    lr: 0.0002106424719857633\n",
            "    n_layers: 1\n",
            "    n_units_layer0: 84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## バッチサイズのハイパーパラメータ最適化への考慮"
      ],
      "metadata": {
        "id": "mxZMBt_lcs9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### code"
      ],
      "metadata": {
        "id": "ouihNYIJc48k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# データセットの準備（ここでは合成データセットを使用）\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# データのスケーリング\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 目的関数の定義\n",
        "def objective(trial):\n",
        "    #ハイパーパラメータの提案\n",
        "    ## オプティマイザの提案※SGDは使用しない\n",
        "    # optimizer_options = ['Adam', 'SGD', 'RMSprop']\n",
        "    optimizer_options = ['Adam', 'RMSprop']\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', optimizer_options)\n",
        "    ## 学習率の提案\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "    ## 各層の数、ユニット数の提案\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 5 )\n",
        "    n_units_per_layer = [trial.suggest_int(f'n_units_layer{i}', 8, 128) for i in range(n_layers)]\n",
        "    # バッチサイズの提案\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "\n",
        "    # モデルの構築\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(Dense(n_units_per_layer[0], activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for units in n_units_per_layer[1:]:\n",
        "      model.add(Dense(units, activation='relu',kernel_initializer=HeNormal()))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # オプティマイザの設定\n",
        "    if optimizer_name == 'Adam':\n",
        "        # optimizer = Adam(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
        "    # elif optimizer_name == 'SGD':\n",
        "    #     # optimizer = SGD(lr=lr)\n",
        "    #     optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)\n",
        "    else:\n",
        "        # optimizer = RMSprop(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=lr)\n",
        "\n",
        "    # モデルのコンパイル\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # モデルの訓練\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return loss\n",
        "\n",
        "def write_trial_to_file(study,trial):\n",
        "    # CSVファイルのパスとカラム名を指定\n",
        "    file_path = 'param.csv'\n",
        "    # n_layers=5\n",
        "\n",
        "    #列名が記載されたDataFrame作成\n",
        "    columns = ['trial_number','loss','optimizer', 'lr', 'batch_size','n_layers']\n",
        "    add_layer_columns=[\"n_units_layer\"+str(i) for i in range(trial.params['n_layers'])]\n",
        "    columns=columns+add_layer_columns\n",
        "    # print(f\"columns名：{columns}\")\n",
        "    trial_df=pd.DataFrame(columns=columns)\n",
        "\n",
        "    # ハイパーパラメータとlossの値を辞書に格納\n",
        "    trial_data = trial.params\n",
        "    # print(trial.params)\n",
        "    trial_data['loss'] = trial.value\n",
        "    trial_data['trial_number'] = trial.number\n",
        "\n",
        "    # DataFrameを作成\n",
        "    data_df=pd.DataFrame([trial_data])\n",
        "    trial_df=pd.concat([trial_df,data_df],ignore_index=True)\n",
        "    # print(f\"dic:{trial_data}\")\n",
        "    # print(f\"dataframe:{trial_df}\")\n",
        "\n",
        "    # 履歴データを書き込み\n",
        "    write_df_to_csv(file_path,trial_df)\n",
        "\n",
        "\n",
        "def write_df_to_csv_old(file_path, data_df):\n",
        "  #ファイル書き込みの関数を定義\n",
        "    try:\n",
        "        # ファイルが存在しない場合は新規作成し、カラム名を含めて記載\n",
        "        if not os.path.isfile(file_path):\n",
        "            data_df.to_csv(file_path, index=False)\n",
        "        else:\n",
        "            # ファイルが存在する場合はデータのみを追記\n",
        "            data_df.to_csv(file_path, mode='a', header=False, index=False)\n",
        "    except Exception as e:\n",
        "        # エラーが発生した場合の処理\n",
        "        print(f'ファイル書き込み中にエラーが発生しました: {e}')\n",
        "\n",
        "def write_df_to_csv(file_path, data_df):\n",
        "  #ファイル書き込みの関数を定義\n",
        "    try:\n",
        "      # 既存のCSVファイルがあるかチェック\n",
        "      if os.path.isfile(file_path):\n",
        "          # 既存のCSVファイルを読み込む\n",
        "          existing_df = pd.read_csv(file_path)\n",
        "          # 新しいデータを結合する\n",
        "          ##※データ欠損は0で補完\n",
        "          combined_df = pd.concat([existing_df, data_df], axis=0, ignore_index=True).fillna(0)\n",
        "      else:\n",
        "          # CSVファイルが存在しない場合は新しいDataFrameを作成\n",
        "          combined_df = data_df\n",
        "\n",
        "      # 結合したDataFrameをCSVに書き込む\n",
        "      combined_df.to_csv(file_path, index=False)\n",
        "    except Exception as e:\n",
        "        # エラーが発生した場合の処理\n",
        "        print(f'ファイル書き込み中にエラーが発生しました: {e}')\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    # Studyオブジェクトの作成\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(objective, n_trials=2,callbacks=[write_trial_to_file])\n",
        "\n",
        "    # 最適化されたハイパーパラメータの出力\n",
        "    print('Number of finished trials:', len(study.trials))\n",
        "    print('Best trial:')\n",
        "    trial = study.best_trial\n",
        "    print('Value: {}'.format(trial.value))\n",
        "    print('Params: ')\n",
        "    for key, value in trial.params.items():\n",
        "        print('    {}: {}'.format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a37jPse-eKBJ",
        "outputId": "1639e83a-d69a-43cd-ff78-96c1aa8bd147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-06 10:33:53,576] A new study created in memory with name: no-name-95a2d8e4-ab79-4c78-93e9-0d10b430174e\n",
            "[I 2024-04-06 10:34:00,347] Trial 0 finished with value: 25717.8203125 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00020494907645502043, 'n_layers': 2, 'n_units_layer0': 108, 'n_units_layer1': 70, 'batch_size': 128}. Best is trial 0 with value: 25717.8203125.\n",
            "[I 2024-04-06 10:34:21,589] Trial 1 finished with value: 38.513790130615234 and parameters: {'optimizer': 'Adam', 'lr': 0.0035255409959211313, 'n_layers': 5, 'n_units_layer0': 122, 'n_units_layer1': 101, 'n_units_layer2': 15, 'n_units_layer3': 86, 'n_units_layer4': 66, 'batch_size': 32}. Best is trial 1 with value: 38.513790130615234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 2\n",
            "Best trial:\n",
            "Value: 38.513790130615234\n",
            "Params: \n",
            "    optimizer: Adam\n",
            "    lr: 0.0035255409959211313\n",
            "    n_layers: 5\n",
            "    n_units_layer0: 122\n",
            "    n_units_layer1: 101\n",
            "    n_units_layer2: 15\n",
            "    n_units_layer3: 86\n",
            "    n_units_layer4: 66\n",
            "    batch_size: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 最適化モデルの保存+Optimizerからlegacyなくした\n",
        "- [x] モデル保存\n",
        "- [x] keras保存\n",
        "- [x] keras読み込み\n",
        "- [ ] パラメータファイルを読み込み → モデル復元"
      ],
      "metadata": {
        "id": "yzXpMXaQf107"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### code"
      ],
      "metadata": {
        "id": "ZJJhglZ2gBYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "from time import sleep\n",
        "import pickle\n",
        "\n",
        "\n",
        "# データセットの準備（ここでは合成データセットを使用）\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# データのスケーリング\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "class TestModel():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def model_from_input(self,units,learning_rate,optimizer_name):\n",
        "      n_layers = len(units)\n",
        "      # モデルの構築\n",
        "      model = tf.keras.models.Sequential()\n",
        "      model.add(Dense(units[0], activation='relu', input_shape=(X_train.shape[1],)))\n",
        "      for unit in units[1:]:\n",
        "        model.add(Dense(unit, activation='relu',kernel_initializer=HeNormal()))\n",
        "        model.add(BatchNormalization())\n",
        "      model.add(Dense(1, activation='linear'))\n",
        "\n",
        "      # オプティマイザの設定\n",
        "      if optimizer_name == 'Adam':\n",
        "          optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "      # elif optimizer_name == 'SGD':\n",
        "      #     # optimizer = SGD(lr=lr)\n",
        "      #     optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate)\n",
        "      else:\n",
        "          # optimizer = RMSprop(lr=lr)\n",
        "          optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "      # モデルのコンパイル\n",
        "      model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "      return model\n",
        "\n",
        "  # 最適化されたハイパーパラメータを使用してモデルを構築する関数\n",
        "  def build_model_from_trial(self,trial):\n",
        "      #モデルパラメータの取得\n",
        "      print(f'trial params:{trial.params}')\n",
        "      units_len=trial.params['n_layers']\n",
        "      units=[value for key,value in trial.params.items() if 'n_units_layer' in key]\n",
        "      learning_rate=trial.params['lr']\n",
        "      optimizer_name=trial.params['optimizer']\n",
        "      print(f'optimizer name:{optimizer_name}')\n",
        "      print(f'lr:{learning_rate}')\n",
        "      print(f'n layers:{len(units)}')\n",
        "      print(f'units:{units}')\n",
        "\n",
        "      # モデルの構築\n",
        "      model=self.model_from_input(units,learning_rate,optimizer_name)\n",
        "\n",
        "      return model\n",
        "\n",
        "  def save_keras_model(self,model_save_path)\n",
        "    #kerasモデル保存\n",
        "    # model_save_path = './model'+str(trial.number)\n",
        "    tf.keras.models.save_model(model, model_save_path)\n",
        "\n",
        "\n",
        "\n",
        "  # def build_model_Ref(self,trial):\n",
        "  #     # モデルの構築\n",
        "  #     model = tf.keras.models.Sequential()\n",
        "  #     model.add(tf.keras.Input(shape=(X_train.shape[1],)))\n",
        "  #     for i in range(trial.params['n_layers']):\n",
        "  #         model.add(Dense(trial.params['n_units_l{}'.format(i)], activation='relu'))\n",
        "  #     model.add(Dense(1, activation='linear'))\n",
        "  #     ↑ × ↓正\n",
        "\n",
        "  #     model.add(Dense(n_units_per_layer[0], activation='relu', input_shape=(X_train.shape[1],)))\n",
        "  #     for units in n_units_per_layer[1:]:\n",
        "  #       model.add(Dense(units, activation='relu',kernel_initializer=HeNormal()))\n",
        "  #     model.add(Dense(1, activation='linear'))\n",
        "\n",
        "  #     # オプティマイザの設定\n",
        "  #     if optimizer_name == 'Adam':\n",
        "  #         # optimizer = Adam(lr=lr)\n",
        "  #         optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
        "  #     # elif optimizer_name == 'SGD':\n",
        "  #     #     # optimizer = SGD(lr=lr)\n",
        "  #     #     optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)\n",
        "  #     else:\n",
        "  #         # optimizer = RMSprop(lr=lr)\n",
        "  #         optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=lr)\n",
        "\n",
        "  #   # モデルのコンパイル\n",
        "  #   model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "  #   return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 目的関数の定義\n",
        "def objective(trial):\n",
        "    #ハイパーパラメータの提案\n",
        "    ## オプティマイザの提案※SGDは使用しない\n",
        "    # optimizer_options = ['Adam', 'SGD', 'RMSprop']\n",
        "    optimizer_options = ['Adam', 'RMSprop']\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', optimizer_options)\n",
        "    ## 学習率の提案\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "    ## 各層の数、ユニット数の提案\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 5 )\n",
        "    n_units_per_layer = [trial.suggest_int(f'n_units_layer{i}', 8, 128) for i in range(n_layers)]\n",
        "    # バッチサイズの提案\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "\n",
        "    # モデルの構築\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(Dense(n_units_per_layer[0], activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for units in n_units_per_layer[1:]:\n",
        "      model.add(Dense(units, activation='relu',kernel_initializer=HeNormal()))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # オプティマイザの設定\n",
        "    if optimizer_name == 'Adam':\n",
        "        # optimizer = Adam(lr=lr)\n",
        "        # optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    # elif optimizer_name == 'SGD':\n",
        "    #     # optimizer = SGD(lr=lr)\n",
        "    #     optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)\n",
        "    else:\n",
        "        # optimizer = RMSprop(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
        "        # optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=lr)\n",
        "\n",
        "    # モデルのコンパイル\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # モデルの訓練\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    # print(f'loss;{loss}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return loss\n",
        "\n",
        "def write_trial_to_file(study,trial):\n",
        "    # CSVファイルのパスとカラム名を指定\n",
        "    file_path = 'param.csv'\n",
        "    # n_layers=5\n",
        "\n",
        "    #列名が記載されたDataFrame作成\n",
        "    columns = ['trial_number','loss','optimizer', 'lr', 'batch_size','n_layers']\n",
        "    add_layer_columns=[\"n_units_layer\"+str(i) for i in range(trial.params['n_layers'])]\n",
        "    columns=columns+add_layer_columns\n",
        "    # print(f\"columns名：{columns}\")\n",
        "    trial_df=pd.DataFrame(columns=columns)\n",
        "\n",
        "    # ハイパーパラメータとlossの値を辞書に格納\n",
        "    trial_data = trial.params\n",
        "    # print(trial.params)\n",
        "    trial_data['loss'] = trial.value\n",
        "    trial_data['trial_number'] = trial.number\n",
        "\n",
        "    # DataFrameを作成\n",
        "    data_df=pd.DataFrame([trial_data])\n",
        "    trial_df=pd.concat([trial_df,data_df],ignore_index=True)\n",
        "    # print(f\"dic:{trial_data}\")\n",
        "    # print(f\"dataframe:{trial_df}\")\n",
        "\n",
        "    # 履歴データを書き込み\n",
        "    write_df_to_csv(file_path,trial_df)\n",
        "\n",
        "def write_df_to_csv(file_path, data_df):\n",
        "  #ファイル書き込みの関数を定義\n",
        "    try:\n",
        "      # 既存のCSVファイルがあるかチェック\n",
        "      if os.path.isfile(file_path):\n",
        "          # 既存のCSVファイルを読み込む\n",
        "          existing_df = pd.read_csv(file_path)\n",
        "          # 新しいデータを結合する\n",
        "          ##※データ欠損は0で補完\n",
        "          combined_df = pd.concat([existing_df, data_df], axis=0, ignore_index=True).fillna(0)\n",
        "      else:\n",
        "          # CSVファイルが存在しない場合は新しいDataFrameを作成\n",
        "          combined_df = data_df\n",
        "\n",
        "      # 結合したDataFrameをCSVに書き込む\n",
        "      combined_df.to_csv(file_path, index=False)\n",
        "    except Exception as e:\n",
        "        # エラーが発生した場合の処理\n",
        "        print(f'ファイル書き込み中にエラーが発生しました: {e}')\n",
        "\n",
        "# Callback関数の定義\n",
        "def save_intermediate_results(study, trial):\n",
        "    # 途中結果を保存するためのコールバック関数\n",
        "    print(f\"Completed Trials: {len(study.trials)}\")\n",
        "\n",
        "    # ここで必要に応じてstudy.trialsを保存する処理を追加\n",
        "    trials_l = study.trials\n",
        "\n",
        "    # trialsを外部ファイルに保存\n",
        "    with open('trials.pkl', 'wb') as f:\n",
        "        pickle.dump(trials_l, f)\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    n_trials=3\n",
        "    # Studyオブジェクトの作成\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(objective, n_trials=n_trials,callbacks=[write_trial_to_file,save_intermediate_results])\n",
        "\n",
        "    # 最適化されたハイパーパラメータの出力\n",
        "    print('Number of finished trials:', len(study.trials))\n",
        "    trial = study.best_trial\n",
        "    print(f'Best trial:{trial.number}')\n",
        "    print('Value: {}'.format(trial.value))\n",
        "    print('Params: ')\n",
        "    for key, value in trial.params.items():\n",
        "        print('    {}: {}'.format(key, value))\n",
        "\n",
        "\n",
        "    #kerasモデル読み込み\n",
        "    for i in range(n_trials):\n",
        "      model_save_path = './model'+str(i)\n",
        "      loaded_model = tf.keras.models.load_model(model_save_path)\n",
        "      loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "      print(f'loaded model{i} loss;{loss}')\n",
        "\n",
        "    print('**'*50)\n",
        "    #keras最適モデル読み込み\n",
        "    print(\"***best keras model***\")\n",
        "    best_model_save_path = './model'+str(trial.number)\n",
        "    loaded_model = tf.keras.models.load_model(best_model_save_path)\n",
        "    # loaded_model.summary()\n",
        "    loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best keras model loss;{loss}')\n",
        "\n",
        "    print('**'*50)\n",
        "    print(\"***loaded best model***\")\n",
        "    #最適モデル構築from trial\n",
        "    tm=TestModel()\n",
        "    model=tm.build_model_from_trial(trial)\n",
        "    # model.summary()\n",
        "    loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best model from trial loss;{loss}')\n",
        "\n",
        "    trials_l=study.trials\n",
        "    print('**'*50)\n",
        "    for i in trials_l:\n",
        "      print(f'study traials:{i}')\n",
        "      print(f'type;{type(i)}')\n",
        "    print(f'study trials:{trial}')\n",
        "    print(f'type;{type(trial)}')\n",
        "\n",
        "\n",
        "\n",
        "    # #keras最適モデル保存\n",
        "    # best_model_save_path = './best_model'\n",
        "    # tf.keras.models.save_model(model, model_save_path)\n",
        "\n",
        "    #\n",
        "    # モデルのコンパイル\n",
        "    # loaded_model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # # モデルの訓練\n",
        "    # loaded_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    # loss = loaded_model.evaluate(X_test, y_test, verbose=0,batch_size=batch_size)\n",
        "    # loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    # print(f'best model loss :{loss}')\n",
        "    # print(f'X test:{X_test}')\n",
        "\n",
        "    # 保存したtrialsを読み込む\n",
        "    with open('trials.pkl', 'rb') as f:\n",
        "        loaded_trials = pickle.load(f)\n",
        "\n",
        "    # 読み込んだtrialsを使用\n",
        "    print(f'loaded trials:{loaded_trials}')\n",
        "    for i in loaded_trials:\n",
        "      print(f'trials{str(i.number)}:{i}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yRREy8ANgH9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3d0446-6f03-4b1c-eaa5-bdd0976dc80c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-20 23:14:31,819] A new study created in memory with name: no-name-c29b24a4-661d-458f-b908-ed89e4e15580\n",
            "[I 2024-04-20 23:14:49,933] Trial 0 finished with value: 38176.96484375 and parameters: {'optimizer': 'RMSprop', 'lr': 3.7875191623291086e-05, 'n_layers': 1, 'n_units_layer0': 74, 'batch_size': 32}. Best is trial 0 with value: 38176.96484375.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed Trials: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-20 23:15:06,394] Trial 1 finished with value: 88.31385040283203 and parameters: {'optimizer': 'RMSprop', 'lr': 0.00021013082615291238, 'n_layers': 4, 'n_units_layer0': 93, 'n_units_layer1': 20, 'n_units_layer2': 72, 'n_units_layer3': 70, 'batch_size': 32}. Best is trial 1 with value: 88.31385040283203.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed Trials: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-20 23:15:15,595] Trial 2 finished with value: 176.19024658203125 and parameters: {'optimizer': 'Adam', 'lr': 0.0006756972573087853, 'n_layers': 5, 'n_units_layer0': 93, 'n_units_layer1': 113, 'n_units_layer2': 114, 'n_units_layer3': 70, 'n_units_layer4': 47, 'batch_size': 128}. Best is trial 1 with value: 88.31385040283203.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed Trials: 3\n",
            "Number of finished trials: 3\n",
            "Best trial:1\n",
            "Value: 88.31385040283203\n",
            "Params: \n",
            "    optimizer: RMSprop\n",
            "    lr: 0.00021013082615291238\n",
            "    n_layers: 4\n",
            "    n_units_layer0: 93\n",
            "    n_units_layer1: 20\n",
            "    n_units_layer2: 72\n",
            "    n_units_layer3: 70\n",
            "    batch_size: 32\n",
            "loaded model0 loss;38176.96484375\n",
            "loaded model1 loss;88.31385040283203\n",
            "loaded model2 loss;176.19024658203125\n",
            "****************************************************************************************************\n",
            "***best keras model***\n",
            "loaded best keras model loss;88.31385040283203\n",
            "****************************************************************************************************\n",
            "***loaded best model***\n",
            "trial params:{'optimizer': 'RMSprop', 'lr': 0.00021013082615291238, 'n_layers': 4, 'n_units_layer0': 93, 'n_units_layer1': 20, 'n_units_layer2': 72, 'n_units_layer3': 70, 'batch_size': 32}\n",
            "optimizer name:RMSprop\n",
            "lr:0.00021013082615291238\n",
            "n layers:4\n",
            "units:[93, 20, 72, 70]\n",
            "loaded best model from trial loss;88.31385040283203\n",
            "****************************************************************************************************\n",
            "study traials:FrozenTrial(number=0, state=TrialState.COMPLETE, values=[38176.96484375], datetime_start=datetime.datetime(2024, 4, 20, 23, 14, 31, 827424), datetime_complete=datetime.datetime(2024, 4, 20, 23, 14, 49, 932993), params={'optimizer': 'RMSprop', 'lr': 3.7875191623291086e-05, 'n_layers': 1, 'n_units_layer0': 74, 'batch_size': 32}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=0, value=None)\n",
            "type;<class 'optuna.trial._frozen.FrozenTrial'>\n",
            "study traials:FrozenTrial(number=1, state=TrialState.COMPLETE, values=[88.31385040283203], datetime_start=datetime.datetime(2024, 4, 20, 23, 14, 49, 956782), datetime_complete=datetime.datetime(2024, 4, 20, 23, 15, 6, 394422), params={'optimizer': 'RMSprop', 'lr': 0.00021013082615291238, 'n_layers': 4, 'n_units_layer0': 93, 'n_units_layer1': 20, 'n_units_layer2': 72, 'n_units_layer3': 70, 'batch_size': 32}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer1': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer2': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer3': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=1, value=None)\n",
            "type;<class 'optuna.trial._frozen.FrozenTrial'>\n",
            "study traials:FrozenTrial(number=2, state=TrialState.COMPLETE, values=[176.19024658203125], datetime_start=datetime.datetime(2024, 4, 20, 23, 15, 6, 412391), datetime_complete=datetime.datetime(2024, 4, 20, 23, 15, 15, 595567), params={'optimizer': 'Adam', 'lr': 0.0006756972573087853, 'n_layers': 5, 'n_units_layer0': 93, 'n_units_layer1': 113, 'n_units_layer2': 114, 'n_units_layer3': 70, 'n_units_layer4': 47, 'batch_size': 128}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer1': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer2': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer3': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer4': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=2, value=None)\n",
            "type;<class 'optuna.trial._frozen.FrozenTrial'>\n",
            "study trials:FrozenTrial(number=1, state=TrialState.COMPLETE, values=[88.31385040283203], datetime_start=datetime.datetime(2024, 4, 20, 23, 14, 49, 956782), datetime_complete=datetime.datetime(2024, 4, 20, 23, 15, 6, 394422), params={'optimizer': 'RMSprop', 'lr': 0.00021013082615291238, 'n_layers': 4, 'n_units_layer0': 93, 'n_units_layer1': 20, 'n_units_layer2': 72, 'n_units_layer3': 70, 'batch_size': 32}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer1': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer2': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer3': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=1, value=None)\n",
            "type;<class 'optuna.trial._frozen.FrozenTrial'>\n",
            "loaded trials:[FrozenTrial(number=0, state=TrialState.COMPLETE, values=[38176.96484375], datetime_start=datetime.datetime(2024, 4, 20, 23, 14, 31, 827424), datetime_complete=datetime.datetime(2024, 4, 20, 23, 14, 49, 932993), params={'optimizer': 'RMSprop', 'lr': 3.7875191623291086e-05, 'n_layers': 1, 'n_units_layer0': 74, 'batch_size': 32}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=0, value=None), FrozenTrial(number=1, state=TrialState.COMPLETE, values=[88.31385040283203], datetime_start=datetime.datetime(2024, 4, 20, 23, 14, 49, 956782), datetime_complete=datetime.datetime(2024, 4, 20, 23, 15, 6, 394422), params={'optimizer': 'RMSprop', 'lr': 0.00021013082615291238, 'n_layers': 4, 'n_units_layer0': 93, 'n_units_layer1': 20, 'n_units_layer2': 72, 'n_units_layer3': 70, 'batch_size': 32}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer1': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer2': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer3': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=1, value=None), FrozenTrial(number=2, state=TrialState.COMPLETE, values=[176.19024658203125], datetime_start=datetime.datetime(2024, 4, 20, 23, 15, 6, 412391), datetime_complete=datetime.datetime(2024, 4, 20, 23, 15, 15, 595567), params={'optimizer': 'Adam', 'lr': 0.0006756972573087853, 'n_layers': 5, 'n_units_layer0': 93, 'n_units_layer1': 113, 'n_units_layer2': 114, 'n_units_layer3': 70, 'n_units_layer4': 47, 'batch_size': 128}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer1': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer2': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer3': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer4': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=2, value=None)]\n",
            "trials0:FrozenTrial(number=0, state=TrialState.COMPLETE, values=[38176.96484375], datetime_start=datetime.datetime(2024, 4, 20, 23, 14, 31, 827424), datetime_complete=datetime.datetime(2024, 4, 20, 23, 14, 49, 932993), params={'optimizer': 'RMSprop', 'lr': 3.7875191623291086e-05, 'n_layers': 1, 'n_units_layer0': 74, 'batch_size': 32}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=0, value=None)\n",
            "trials1:FrozenTrial(number=1, state=TrialState.COMPLETE, values=[88.31385040283203], datetime_start=datetime.datetime(2024, 4, 20, 23, 14, 49, 956782), datetime_complete=datetime.datetime(2024, 4, 20, 23, 15, 6, 394422), params={'optimizer': 'RMSprop', 'lr': 0.00021013082615291238, 'n_layers': 4, 'n_units_layer0': 93, 'n_units_layer1': 20, 'n_units_layer2': 72, 'n_units_layer3': 70, 'batch_size': 32}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer1': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer2': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer3': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=1, value=None)\n",
            "trials2:FrozenTrial(number=2, state=TrialState.COMPLETE, values=[176.19024658203125], datetime_start=datetime.datetime(2024, 4, 20, 23, 15, 6, 412391), datetime_complete=datetime.datetime(2024, 4, 20, 23, 15, 15, 595567), params={'optimizer': 'Adam', 'lr': 0.0006756972573087853, 'n_layers': 5, 'n_units_layer0': 93, 'n_units_layer1': 113, 'n_units_layer2': 114, 'n_units_layer3': 70, 'n_units_layer4': 47, 'batch_size': 128}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer1': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer2': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer3': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer4': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=2, value=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデル保存処理の修正"
      ],
      "metadata": {
        "id": "sQeRU6APXvec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### code"
      ],
      "metadata": {
        "id": "3wzr8lfeEJlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "\n",
        "# データセットの準備（ここでは合成データセットを使用）\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# データのスケーリング\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "class TestModel():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  # 最適化されたハイパーパラメータを使用してモデルを構築する関数\n",
        "  def build_model_from_trial(self,trial):\n",
        "      #モデルパラメータの取得\n",
        "      # print(f'trial params:{trial.params}')\n",
        "      units_len=trial.params['n_layers']\n",
        "      units=[value for key,value in trial.params.items() if 'n_units_layer' in key]\n",
        "      learning_rate=trial.params['lr']\n",
        "      optimizer_name=trial.params['optimizer']\n",
        "      print(f'optimizer name:{optimizer_name}')\n",
        "      print(f'lr:{learning_rate}')\n",
        "      print(f'n layers:{len(units)}')\n",
        "      print(f'units:{units}')\n",
        "\n",
        "      # モデルの構築\n",
        "      model=model_definitinon(units,optimizer_name,learning_rate)\n",
        "      # model=self.model_from_input(units,learning_rate,optimizer_name)\n",
        "\n",
        "      return model\n",
        "\n",
        "  def save_keras_model(self,model_save_path):\n",
        "    #kerasモデル保存\n",
        "    # model_save_path = './model'+str(trial.number)\n",
        "    tf.keras.models.save_model(model, model_save_path)\n",
        "\n",
        "\n",
        "  def load_keras_model(self,model_save_path):\n",
        "    #kerasモデル読み込み\n",
        "    # model_save_path = './model'+str(trial.number)\n",
        "    loaded_model = tf.keras.models.load_model(model_save_path)\n",
        "    # loaded_model.summary()\n",
        "    loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best keras model loss;{loss}')\n",
        "    return loaded_model\n",
        "\n",
        "\n",
        "  def build_model_from_pickle(self,pickle_path,trial_number):\n",
        "    #指定したpickleファイルのtrial_numberのモデルを読み込み\n",
        "    pickle_path='trials.pkl'\n",
        "    # 保存したtrialsを読み込む\n",
        "    with open(pickle_path, 'rb') as f:\n",
        "        loaded_trials = pickle.load(f)\n",
        "\n",
        "    # 読み込んだtrialsを表示\n",
        "    print(f'loaded trials:{loaded_trials}')\n",
        "    for i in loaded_trials:\n",
        "      print(f'trials{str(i.number)}:{i}')\n",
        "\n",
        "    # 指定したtrialのモデルを読み込み\n",
        "    return self.build_model_from_trial(trial_number)\n",
        "\n",
        "def model_definitinon(n_units_per_layer,optimizer_name,lr):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(Dense(n_units_per_layer[0], activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for units in n_units_per_layer[1:]:\n",
        "      model.add(Dense(units, activation='relu',kernel_initializer=HeNormal()))\n",
        "      model.add(BatchNormalization())\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # オプティマイザの設定\n",
        "    if optimizer_name == 'Adam':\n",
        "        # optimizer = Adam(lr=lr)\n",
        "        # optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    # elif optimizer_name == 'SGD':\n",
        "    #     # optimizer = SGD(lr=lr)\n",
        "    #     optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)\n",
        "    else:\n",
        "        # optimizer = RMSprop(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
        "        # optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=lr)\n",
        "\n",
        "    # モデルのコンパイル\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# 目的関数の定義\n",
        "def objective(trial):\n",
        "    #ハイパーパラメータの提案\n",
        "    ## オプティマイザの提案※SGDは使用しない\n",
        "    # optimizer_options = ['Adam', 'SGD', 'RMSprop']\n",
        "    optimizer_options = ['Adam', 'RMSprop']\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', optimizer_options)\n",
        "    ## 学習率の提案\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "    ## 各層の数、ユニット数の提案\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 5 )\n",
        "    n_units_per_layer = [trial.suggest_int(f'n_units_layer{i}', 8, 128) for i in range(n_layers)]\n",
        "    # バッチサイズの提案\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "\n",
        "    # モデルの構築\n",
        "    model=model_definitinon(n_units_per_layer,optimizer_name,lr)\n",
        "    # モデルの訓練\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    # model.summary()\n",
        "    # print(f'loss;{loss}')\n",
        "\n",
        "    return loss\n",
        "\n",
        "def save_trial_data(study,trial):\n",
        "    #パラメータを書き込み\n",
        "    write_trial_to_file(study,trial)\n",
        "    #モデルを保存\n",
        "    save_model(study,trial)\n",
        "\n",
        "def write_trial_to_file(study,trial):\n",
        "    # CSVファイルのパスとカラム名を指定\n",
        "    file_path = 'param.csv'\n",
        "    # n_layers=5\n",
        "\n",
        "    #列名が記載されたDataFrame作成\n",
        "    columns = ['trial_number','loss','optimizer', 'lr', 'batch_size','n_layers']\n",
        "    add_layer_columns=[\"n_units_layer\"+str(i) for i in range(trial.params['n_layers'])]\n",
        "    columns=columns+add_layer_columns\n",
        "    # print(f\"columns名：{columns}\")\n",
        "    trial_df=pd.DataFrame(columns=columns)\n",
        "\n",
        "    # ハイパーパラメータとlossの値を辞書に格納\n",
        "    trial_data = trial.params\n",
        "    # print(trial.params)\n",
        "    trial_data['loss'] = trial.value\n",
        "    trial_data['trial_number'] = trial.number\n",
        "\n",
        "    # DataFrameを作成\n",
        "    data_df=pd.DataFrame([trial_data])\n",
        "    trial_df=pd.concat([trial_df,data_df],ignore_index=True)\n",
        "    # print(f\"dic:{trial_data}\")\n",
        "    # print(f\"dataframe:{trial_df}\")\n",
        "\n",
        "    # 履歴データを書き込み\n",
        "    write_df_to_csv(file_path,trial_df)\n",
        "\n",
        "def write_df_to_csv(file_path, data_df):\n",
        "  #ファイル書き込みの関数を定義\n",
        "    try:\n",
        "      # 既存のCSVファイルがあるかチェック\n",
        "      if os.path.isfile(file_path):\n",
        "          # 既存のCSVファイルを読み込む\n",
        "          existing_df = pd.read_csv(file_path)\n",
        "          # 新しいデータを結合する\n",
        "          ##※データ欠損は0で補完\n",
        "          combined_df = pd.concat([existing_df, data_df], axis=0, ignore_index=True).fillna(0)\n",
        "      else:\n",
        "          # CSVファイルが存在しない場合は新しいDataFrameを作成\n",
        "          combined_df = data_df\n",
        "\n",
        "      # 結合したDataFrameをCSVに書き込む\n",
        "      combined_df.to_csv(file_path, index=False)\n",
        "    except Exception as e:\n",
        "        # エラーが発生した場合の処理\n",
        "        print(f'ファイル書き込み中にエラーが発生しました: {e}')\n",
        "\n",
        "def save_model(study,trial):\n",
        "    #モデルを保存する\n",
        "    # 途中結果を保存するためのコールバック関数\n",
        "    print(f\"Completed Trials: {len(study.trials)}\")\n",
        "\n",
        "    # ここで必要に応じてstudy.trialsを保存する処理を追加\n",
        "    trials_l = study.trials\n",
        "\n",
        "    # trialsを外部ファイルに保存\n",
        "    with open('trial_info.pkl', 'wb') as f:\n",
        "        pickle.dump(trials_l, f)\n",
        "\n",
        "    # best trialと最新モデル以外削除\n",
        "    ## 過去のtrialの.h5を削除\n",
        "    pattern = re.compile(r'model_\\d+\\.h5$')\n",
        "    # List all files in the directory\n",
        "    cur_dir='.'\n",
        "    files = os.listdir(cur_dir)\n",
        "    for file in files:\n",
        "      # If the file matches the pattern\n",
        "      if pattern.match(file):\n",
        "        # Delete the file\n",
        "        os.remove(os.path.join(cur_dir, file))\n",
        "        # print(f\"Deleted file: {file}\")\n",
        "\n",
        "    # print(f'trial number:{trial.number}')\n",
        "    # print(f'best trial number;{study.best_trial.number}')\n",
        "    # 現在のトライアルの.h5モデルの保存\n",
        "    model_save_path = './model_'+str(trial.number)+'.h5'\n",
        "    model.save(model_save_path)\n",
        "    # bestトライアルならbest_trialとしてモデルを保存\n",
        "    if trial.number==study.best_trial.number:\n",
        "      model_save_path = './best_model.h5'\n",
        "      model.save(model_save_path)\n",
        "      print(f'Best trial trial number:{trial.number}')\n",
        "      print(f'Model saved to {model_save_path}')\n",
        "\n",
        "# Callback関数の定義\n",
        "def save_intermediate_results(study, trial):\n",
        "    #**************Don't Use**************\n",
        "    # 途中結果を保存するためのコールバック関数\n",
        "    print(f\"Completed Trials: {len(study.trials)}\")\n",
        "\n",
        "    # ここで必要に応じてstudy.trialsを保存する処理を追加\n",
        "    trials_l = study.trials\n",
        "\n",
        "    # trialsを外部ファイルに保存\n",
        "    with open('trial_info.pkl', 'wb') as f:\n",
        "        pickle.dump(trials_l, f)\n",
        "\n",
        "    # best trialと最新モデル以外削除\n",
        "    ## 過去のtrialの.h5を削除\n",
        "    pattern = re.compile(r'model_\\d+\\.h5$')\n",
        "    # List all files in the directory\n",
        "    cur_dir='.'\n",
        "    files = os.listdir(cur_dir)\n",
        "    for file in files:\n",
        "      # If the file matches the pattern\n",
        "      if pattern.match(file):\n",
        "        # Delete the file\n",
        "        os.remove(os.path.join(cur_dir, file))\n",
        "        print(f\"Deleted file: {file}\")\n",
        "\n",
        "    print(f'trial number:{trial.number}')\n",
        "\n",
        "    print(f'best trial number;{study.best_trial.number}')\n",
        "    # 現在のトライアルの.h5モデルの保存\n",
        "    model_save_path = './model_'+str(trial.number)+'.h5'\n",
        "    model.save(model_save_path)\n",
        "    # bestトライアルならbest_trialとしてモデルを保存\n",
        "    if trial.number==study.best_trial.number:\n",
        "      model_save_path = './best_model.h5'\n",
        "      model.save(model_save_path)\n",
        "      print(f'Best trial trial number:{trial.number}')\n",
        "      print(f'Model saved to {model_save_path}')\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    n_trials=5\n",
        "    # Studyオブジェクトの作成\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(objective, n_trials=n_trials,callbacks=[save_trial_data])\n",
        "\n",
        "    # 最適化されたハイパーパラメータの出力\n",
        "    print('Number of finished trials:', len(study.trials))\n",
        "    trial = study.best_trial\n",
        "    print(f'Best trial:{trial.number}')\n",
        "    print('Value: {}'.format(trial.value))\n",
        "    print('Params: ')\n",
        "    for key, value in trial.params.items():\n",
        "        print('    {}: {}'.format(key, value))\n",
        "\n",
        "    print('**'*50)\n",
        "\n",
        "    #最適モデル構築from trial\n",
        "    print(\"***loaded best model***\")\n",
        "    tm=TestModel()\n",
        "    model=tm.build_model_from_trial(trial)\n",
        "    batch_size=trial.params['batch_size']\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best model from trial loss;{loss}')\n",
        "\n",
        "    # .h5モデルの読み込み\n",
        "    print(\"=\"*30)\n",
        "    model_save_path = './best_model.h5'\n",
        "    loaded_model = tf.keras.models.load_model(model_save_path)\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best model from trial loss;{loss}')\n",
        "\n",
        "\n",
        "    # model_save_path = './model'+str(trial.number)\n",
        "    # tm.load_keras_model(model_save_path)\n",
        "\n",
        "    #kerasモデル読み込み\n",
        "    # trials_l=study.trials\n",
        "    # print('**'*50)\n",
        "    # for i in trials_l:\n",
        "    #   print(f'study traials:{i}')\n",
        "    # print(f'study trials:{trial}')\n",
        "\n",
        "\n",
        "\n",
        "    # #keras最適モデル保存\n",
        "    # best_model_save_path = './best_model'\n",
        "    # tf.keras.models.save_model(model, model_save_path)\n",
        "\n",
        "    #\n",
        "    # モデルのコンパイル\n",
        "    # loaded_model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # # モデルの訓練\n",
        "    # loaded_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    # loss = loaded_model.evaluate(X_test, y_test, verbose=0,batch_size=batch_size)\n",
        "    # loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    # print(f'best model loss :{loss}')\n",
        "    # print(f'X test:{X_test}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfXIBL-2EJCL",
        "outputId": "02f06b10-77db-4e29-d737-80b3aa79bb0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-28 01:58:24,879] A new study created in memory with name: no-name-366f3fb6-7541-4d7b-bed7-7a057d887fdd\n",
            "[I 2024-04-28 01:58:35,937] Trial 0 finished with value: 27993.841796875 and parameters: {'optimizer': 'Adam', 'lr': 0.0003463347918237899, 'n_layers': 4, 'n_units_layer0': 61, 'n_units_layer1': 83, 'n_units_layer2': 119, 'n_units_layer3': 49, 'batch_size': 128}. Best is trial 0 with value: 27993.841796875.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed Trials: 1\n",
            "Best trial trial number:0\n",
            "Model saved to ./best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-28 01:58:48,999] Trial 1 finished with value: 1490.1259765625 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0008115254270407171, 'n_layers': 5, 'n_units_layer0': 53, 'n_units_layer1': 82, 'n_units_layer2': 84, 'n_units_layer3': 33, 'n_units_layer4': 41, 'batch_size': 32}. Best is trial 1 with value: 1490.1259765625.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed Trials: 2\n",
            "Best trial trial number:1\n",
            "Model saved to ./best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-28 01:58:58,687] Trial 2 finished with value: 31429.634765625 and parameters: {'optimizer': 'Adam', 'lr': 0.00021041090324077697, 'n_layers': 5, 'n_units_layer0': 116, 'n_units_layer1': 33, 'n_units_layer2': 90, 'n_units_layer3': 26, 'n_units_layer4': 50, 'batch_size': 128}. Best is trial 1 with value: 1490.1259765625.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed Trials: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-28 01:59:13,395] Trial 3 finished with value: 2875.863037109375 and parameters: {'optimizer': 'Adam', 'lr': 0.018042337269037596, 'n_layers': 5, 'n_units_layer0': 90, 'n_units_layer1': 122, 'n_units_layer2': 29, 'n_units_layer3': 74, 'n_units_layer4': 103, 'batch_size': 32}. Best is trial 1 with value: 1490.1259765625.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed Trials: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-28 01:59:20,264] Trial 4 finished with value: 4.8179450035095215 and parameters: {'optimizer': 'Adam', 'lr': 0.06014906674060869, 'n_layers': 1, 'n_units_layer0': 99, 'batch_size': 64}. Best is trial 4 with value: 4.8179450035095215.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed Trials: 5\n",
            "Best trial trial number:4\n",
            "Model saved to ./best_model.h5\n",
            "Number of finished trials: 5\n",
            "Best trial:4\n",
            "Value: 4.8179450035095215\n",
            "Params: \n",
            "    optimizer: Adam\n",
            "    lr: 0.06014906674060869\n",
            "    n_layers: 1\n",
            "    n_units_layer0: 99\n",
            "    batch_size: 64\n",
            "****************************************************************************************************\n",
            "***loaded best model***\n",
            "optimizer name:Adam\n",
            "lr:0.06014906674060869\n",
            "n layers:1\n",
            "units:[99]\n",
            "loaded best model from trial loss;4.2019548416137695\n",
            "==============================\n",
            "loaded best model from trial loss;4.2019548416137695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remodel+保存形式.kerasに修正\n",
        "- [ ] 結果の確認\n",
        "- [ ] モデル使用した予測"
      ],
      "metadata": {
        "id": "J_I2_R-Jd88C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### code"
      ],
      "metadata": {
        "id": "e0iZmal1djk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "\n",
        "# データセットの準備（ここでは合成データセットを使用）\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# データのスケーリング\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "class TestModel():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  # 最適化されたハイパーパラメータを使用してモデルを構築する関数\n",
        "  def build_model_from_trial(self,trial):\n",
        "      #モデルパラメータの取得\n",
        "      # print(f'trial params:{trial.params}')\n",
        "      units_len=trial.params['n_layers']\n",
        "      units=[value for key,value in trial.params.items() if 'n_units_layer' in key]\n",
        "      learning_rate=trial.params['lr']\n",
        "      optimizer_name=trial.params['optimizer']\n",
        "      # print(f'optimizer name:{optimizer_name}')\n",
        "      # print(f'lr:{learning_rate}')\n",
        "      # print(f'n layers:{len(units)}')\n",
        "      # print(f'units:{units}')\n",
        "\n",
        "      # モデルの構築\n",
        "      model=model_definitinon(units,optimizer_name,learning_rate)\n",
        "      # model=self.model_from_input(units,learning_rate,optimizer_name)\n",
        "\n",
        "      return model\n",
        "\n",
        "  def save_keras_model(self,model_save_path):\n",
        "    #kerasモデル保存\n",
        "    # model_save_path = './model'+str(trial.number)\n",
        "    tf.keras.models.save_model(model, model_save_path)\n",
        "\n",
        "\n",
        "  def load_keras_model(self,model_save_path):\n",
        "    #kerasモデル読み込み\n",
        "    # model_save_path = './model'+str(trial.number)\n",
        "    loaded_model = tf.keras.models.load_model(model_save_path)\n",
        "    # loaded_model.summary()\n",
        "    loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best keras model loss;{loss}')\n",
        "    return loaded_model\n",
        "\n",
        "\n",
        "  def build_model_from_pickle(self,pickle_path,trial_number):\n",
        "    #指定したpickleファイルのtrial_numberのモデルを読み込み\n",
        "    pickle_path='trials.pkl'\n",
        "    # 保存したtrialsを読み込む\n",
        "    with open(pickle_path, 'rb') as f:\n",
        "        loaded_trials = pickle.load(f)\n",
        "\n",
        "    # 読み込んだtrialsを表示\n",
        "    print(f'loaded trials:{loaded_trials}')\n",
        "    for i in loaded_trials:\n",
        "      print(f'trials{str(i.number)}:{i}')\n",
        "\n",
        "    # 指定したtrialのモデルを読み込み\n",
        "    return self.build_model_from_trial(trial_number)\n",
        "\n",
        "def model_definitinon(n_units_per_layer,optimizer_name,lr):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(Dense(n_units_per_layer[0], activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for units in n_units_per_layer[1:]:\n",
        "      model.add(Dense(units, activation='relu',kernel_initializer=HeNormal()))\n",
        "      model.add(BatchNormalization())\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # オプティマイザの設定\n",
        "    if optimizer_name == 'Adam':\n",
        "        # optimizer = Adam(lr=lr)\n",
        "        # optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    # elif optimizer_name == 'SGD':\n",
        "    #     # optimizer = SGD(lr=lr)\n",
        "    #     optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)\n",
        "    else:\n",
        "        # optimizer = RMSprop(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
        "        # optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=lr)\n",
        "\n",
        "    # モデルのコンパイル\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# 目的関数の定義\n",
        "def objective(trial):\n",
        "    #ハイパーパラメータの提案\n",
        "    ## オプティマイザの提案※SGDは使用しない\n",
        "    # optimizer_options = ['Adam', 'SGD', 'RMSprop']\n",
        "    optimizer_options = ['Adam', 'RMSprop']\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', optimizer_options)\n",
        "    ## 学習率の提案\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "    ## 各層の数、ユニット数の提案\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 5 )\n",
        "    n_units_per_layer = [trial.suggest_int(f'n_units_layer{i}', 8, 128) for i in range(n_layers)]\n",
        "    # バッチサイズの提案\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "\n",
        "    # モデルの構築\n",
        "    model=model_definitinon(n_units_per_layer,optimizer_name,lr)\n",
        "    # モデルの訓練\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    # model.summary()\n",
        "    # print(f'loss;{loss}')\n",
        "\n",
        "    # best trialと最新モデル以外削除\n",
        "    ## 過去のtrialの.kerasを削除\n",
        "    pattern = re.compile(r'model_\\d+\\.keras$')\n",
        "    # List all files in the directory\n",
        "    cur_dir='.'\n",
        "    files = os.listdir(cur_dir)\n",
        "    for file in files:\n",
        "      # If the file matches the pattern\n",
        "      if pattern.match(file):\n",
        "        # Delete the file\n",
        "        os.remove(os.path.join(cur_dir, file))\n",
        "        # print(f\"Deleted file: {file}\")\n",
        "    # 現在のトライアルの.kerasモデルの保存\n",
        "    model_save_path = './model_'+str(trial.number)+'.keras'\n",
        "    model.save(model_save_path)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def save_trial_data(study,trial):\n",
        "    #パラメータを書き込み\n",
        "    write_trial_to_file(study,trial)\n",
        "    #モデルを保存\n",
        "    save_model(study,trial)\n",
        "\n",
        "def write_trial_to_file(study,trial):\n",
        "    # CSVファイルのパスとカラム名を指定\n",
        "    file_path = 'param.csv'\n",
        "    # n_layers=5\n",
        "\n",
        "    #列名が記載されたDataFrame作成\n",
        "    columns = ['trial_number','loss','optimizer', 'lr', 'batch_size','n_layers']\n",
        "    add_layer_columns=[\"n_units_layer\"+str(i) for i in range(trial.params['n_layers'])]\n",
        "    columns=columns+add_layer_columns\n",
        "    # print(f\"columns名：{columns}\")\n",
        "    trial_df=pd.DataFrame(columns=columns)\n",
        "\n",
        "    # ハイパーパラメータとlossの値を辞書に格納\n",
        "    trial_data = trial.params\n",
        "    # print(trial.params)\n",
        "    trial_data['loss'] = trial.value\n",
        "    trial_data['trial_number'] = trial.number\n",
        "\n",
        "    # DataFrameを作成\n",
        "    data_df=pd.DataFrame([trial_data])\n",
        "    trial_df=pd.concat([trial_df,data_df],ignore_index=True)\n",
        "    # print(f\"dic:{trial_data}\")\n",
        "    # print(f\"dataframe:{trial_df}\")\n",
        "\n",
        "    # 履歴データを書き込み\n",
        "    write_df_to_csv(file_path,trial_df)\n",
        "\n",
        "def write_df_to_csv(file_path, data_df):\n",
        "  #ファイル書き込みの関数を定義\n",
        "    try:\n",
        "      # 既存のCSVファイルがあるかチェック\n",
        "      if os.path.isfile(file_path):\n",
        "          # 既存のCSVファイルを読み込む\n",
        "          existing_df = pd.read_csv(file_path)\n",
        "          # 新しいデータを結合する\n",
        "          ##※データ欠損は0で補完\n",
        "          combined_df = pd.concat([existing_df, data_df], axis=0, ignore_index=True).fillna(0)\n",
        "      else:\n",
        "          # CSVファイルが存在しない場合は新しいDataFrameを作成\n",
        "          combined_df = data_df\n",
        "\n",
        "      # 結合したDataFrameをCSVに書き込む\n",
        "      combined_df.to_csv(file_path, index=False)\n",
        "    except Exception as e:\n",
        "        # エラーが発生した場合の処理\n",
        "        print(f'ファイル書き込み中にエラーが発生しました: {e}')\n",
        "\n",
        "def save_model(study,trial):\n",
        "    # 最新trialとモデルと最適モデルを.kerasで+trial情報をplkで保存ためのコールバック関数\n",
        "\n",
        "    # print(f\"Completed Trials: {len(study.trials)}\")\n",
        "\n",
        "    # ここで必要に応じてstudy.trialsを保存する処理を追加\n",
        "    trials_l = study.trials\n",
        "\n",
        "    # trialsを外部ファイルに保存\n",
        "    with open('trial_info.pkl', 'wb') as f:\n",
        "        pickle.dump(trials_l, f)\n",
        "\n",
        "\n",
        "    # print(f'trial number:{trial.number}')\n",
        "    # print(f'best trial number;{study.best_trial.number}')\n",
        "    # 現在のトライアルがbestトライアルならbest_trialとしてモデルを保存\n",
        "    if trial.number==study.best_trial.number:\n",
        "      load_model_path='./model_'+str(study.best_trial.number)+'.keras'\n",
        "      best_model=tf.keras.models.load_model(load_model_path)\n",
        "      model_save_path = './best_model.keras'\n",
        "      best_model.save(model_save_path)\n",
        "      print(f'Best trial trial number:{trial.number}')\n",
        "      print(f'Model saved to {model_save_path}')\n",
        "\n",
        "# Callback関数の定義\n",
        "def save_intermediate_results(study, trial):\n",
        "    #**************Don't Use**************\n",
        "    # 途中結果を保存するためのコールバック関数\n",
        "    print(f\"Completed Trials: {len(study.trials)}\")\n",
        "\n",
        "    # ここで必要に応じてstudy.trialsを保存する処理を追加\n",
        "    trials_l = study.trials\n",
        "\n",
        "    # trialsを外部ファイルに保存\n",
        "    with open('trial_info.pkl', 'wb') as f:\n",
        "        pickle.dump(trials_l, f)\n",
        "\n",
        "    # best trialと最新モデル以外削除\n",
        "    ## 過去のtrialの.kerasを削除\n",
        "    pattern = re.compile(r'model_\\d+\\.keras$')\n",
        "    # List all files in the directory\n",
        "    cur_dir='.'\n",
        "    files = os.listdir(cur_dir)\n",
        "    for file in files:\n",
        "      # If the file matches the pattern\n",
        "      if pattern.match(file):\n",
        "        # Delete the file\n",
        "        os.remove(os.path.join(cur_dir, file))\n",
        "        print(f\"Deleted file: {file}\")\n",
        "\n",
        "    # print(f'trial number:{trial.number}')\n",
        "    # print(f'best trial number;{study.best_trial.number}')\n",
        "    # 現在のトライアルの.kerasモデルの保存\n",
        "    model_save_path = './model_'+str(trial.number)+'.keras'\n",
        "    model.save(model_save_path)\n",
        "    # bestトライアルならbest_trialとしてモデルを保存\n",
        "    if trial.number==study.best_trial.number:\n",
        "      model_save_path = './best_model.keras'\n",
        "      model.save(model_save_path)\n",
        "      print(f'Best trial trial number:{trial.number}')\n",
        "      print(f'Model saved to {model_save_path}')\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    n_trials=4\n",
        "    #初期化処理\n",
        "    try:\n",
        "      ## best model 削除\n",
        "      model_save_path = './best_model.keras'\n",
        "      os.remove(model_save_path)\n",
        "      ## pkl削除\n",
        "      model_save_path = './trial_info.pkl'\n",
        "      os.remove(model_save_path)\n",
        "      ## param.csv削除\n",
        "      model_save_path = './param.csv'\n",
        "      os.remove(model_save_path)\n",
        "    except FileNotFoundError as e:\n",
        "      print(f'ファイルが存在しません{e.filename}')\n",
        "\n",
        "    # Studyオブジェクトの作成 → Hyper parameterの最適化\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(objective, n_trials=n_trials,callbacks=[save_trial_data])\n",
        "\n",
        "    # 最適化されたハイパーパラメータの出力\n",
        "    print('Number of finished trials:', len(study.trials))\n",
        "    trial = study.best_trial\n",
        "    print(f'Best trial:{trial.number}')\n",
        "    print('Value: {}'.format(trial.value))\n",
        "    print('Params: ')\n",
        "    for key, value in trial.params.items():\n",
        "        print('    {}: {}'.format(key, value))\n",
        "\n",
        "    print('**'*50)\n",
        "\n",
        "    #最適モデル構築from trial\n",
        "    print(\"***loaded best model***\")\n",
        "    tm=TestModel()\n",
        "    model=tm.build_model_from_trial(trial)\n",
        "    batch_size=trial.params['batch_size']\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best model from trial loss;{loss}')\n",
        "    print(model.summary())\n",
        "\n",
        "    # 最適モデル構築 from .keras\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    model_save_path = './best_model.keras'\n",
        "    loaded_model = tf.keras.models.load_model(model_save_path)\n",
        "    loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best model from keras loss;{loss}')\n",
        "    print(model.summary())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # model_save_path = './model'+str(trial.number)\n",
        "    # tm.load_keras_model(model_save_path)\n",
        "\n",
        "    #kerasモデル読み込み\n",
        "    # trials_l=study.trials\n",
        "    # print('**'*50)\n",
        "    # for i in trials_l:\n",
        "    #   print(f'study traials:{i}')\n",
        "    # print(f'study trials:{trial}')\n",
        "\n",
        "\n",
        "\n",
        "    # #keras最適モデル  保存\n",
        "    # best_model_save_path = './best_model'\n",
        "    # tf.keras.models.save_model(model, model_save_path)\n",
        "\n",
        "    #\n",
        "    # モデルのコンパイル\n",
        "    # loaded_model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # # モデルの訓練\n",
        "    # loaded_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    # loss = loaded_model.evaluate(X_test, y_test, verbose=0,batch_size=batch_size)\n",
        "    # loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    # print(f'best model loss :{loss}')\n",
        "    # print(f'X test:{X_test}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6hn_9KQdhWV",
        "outputId": "24dadae7-4c91-444a-8962-6aacf3642add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-28 05:13:17,492] A new study created in memory with name: no-name-a54e7e14-bf83-452f-a86f-95c461bddc76\n",
            "[I 2024-04-28 05:13:28,157] Trial 0 finished with value: 37252.69921875 and parameters: {'optimizer': 'RMSprop', 'lr': 1.6932673957489968e-05, 'n_layers': 5, 'n_units_layer0': 81, 'n_units_layer1': 113, 'n_units_layer2': 14, 'n_units_layer3': 114, 'n_units_layer4': 112, 'batch_size': 64}. Best is trial 0 with value: 37252.69921875.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial trial number:0\n",
            "Model saved to ./best_model.keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-28 05:13:36,069] Trial 1 finished with value: 38009.00390625 and parameters: {'optimizer': 'RMSprop', 'lr': 1.8795935585020584e-05, 'n_layers': 3, 'n_units_layer0': 50, 'n_units_layer1': 88, 'n_units_layer2': 123, 'batch_size': 128}. Best is trial 0 with value: 37252.69921875.\n",
            "[I 2024-04-28 05:13:42,811] Trial 2 finished with value: 38113.90625 and parameters: {'optimizer': 'RMSprop', 'lr': 5.7004864422796e-05, 'n_layers': 1, 'n_units_layer0': 101, 'batch_size': 64}. Best is trial 0 with value: 37252.69921875.\n",
            "[I 2024-04-28 05:13:55,158] Trial 3 finished with value: 37027.26953125 and parameters: {'optimizer': 'Adam', 'lr': 3.4949835824065653e-05, 'n_layers': 3, 'n_units_layer0': 26, 'n_units_layer1': 49, 'n_units_layer2': 26, 'batch_size': 32}. Best is trial 3 with value: 37027.26953125.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial trial number:3\n",
            "Model saved to ./best_model.keras\n",
            "Number of finished trials: 4\n",
            "Best trial:3\n",
            "Value: 37027.26953125\n",
            "Params: \n",
            "    optimizer: Adam\n",
            "    lr: 3.4949835824065653e-05\n",
            "    n_layers: 3\n",
            "    n_units_layer0: 26\n",
            "    n_units_layer1: 49\n",
            "    n_units_layer2: 26\n",
            "    batch_size: 32\n",
            "****************************************************************************************************\n",
            "***loaded best model***\n",
            "loaded best model from trial loss;36867.69921875\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_126 (Dense)           (None, 26)                546       \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 49)                1323      \n",
            "                                                                 \n",
            " batch_normalization_66 (Ba  (None, 49)                196       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 26)                1300      \n",
            "                                                                 \n",
            " batch_normalization_67 (Ba  (None, 26)                104       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 1)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3496 (13.66 KB)\n",
            "Trainable params: 3346 (13.07 KB)\n",
            "Non-trainable params: 150 (600.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "==============================\n",
            "loaded best model from keras loss;37027.26953125\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_126 (Dense)           (None, 26)                546       \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 49)                1323      \n",
            "                                                                 \n",
            " batch_normalization_66 (Ba  (None, 49)                196       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 26)                1300      \n",
            "                                                                 \n",
            " batch_normalization_67 (Ba  (None, 26)                104       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 1)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3496 (13.66 KB)\n",
            "Trainable params: 3346 (13.07 KB)\n",
            "Non-trainable params: 150 (600.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 最適化モデルの保存 → 途中から再開"
      ],
      "metadata": {
        "id": "5zSG_tTDhe6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### code"
      ],
      "metadata": {
        "id": "kebZaRgUU-di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import re\n",
        "import glob\n",
        "\n",
        "# データセットの準備（ここでは合成データセットを使用）\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# データのスケーリング\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "class TestModel():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  # 最適化されたハイパーパラメータを使用してモデルを構築する関数\n",
        "  def build_model_from_trial(self,trial):\n",
        "      #モデルパラメータの取得\n",
        "      # print(f'trial params:{trial.params}')\n",
        "      units_len=trial.params['n_layers']\n",
        "      units=[value for key,value in trial.params.items() if 'n_units_layer' in key]\n",
        "      learning_rate=trial.params['lr']\n",
        "      optimizer_name=trial.params['optimizer']\n",
        "      # print(f'optimizer name:{optimizer_name}')\n",
        "      # print(f'lr:{learning_rate}')\n",
        "      # print(f'n layers:{len(units)}')\n",
        "      # print(f'units:{units}')\n",
        "\n",
        "      # モデルの構築\n",
        "      model=model_definitinon(units,optimizer_name,learning_rate)\n",
        "      # model=self.model_from_input(units,learning_rate,optimizer_name)\n",
        "\n",
        "      return model\n",
        "\n",
        "  def save_keras_model(self,model_save_path):\n",
        "    #kerasモデル保存\n",
        "    # model_save_path = './model'+str(trial.number)\n",
        "    tf.keras.models.save_model(model, model_save_path)\n",
        "\n",
        "\n",
        "  def load_keras_model(self,model_save_path):\n",
        "    #kerasモデル読み込み\n",
        "    # model_save_path = './model'+str(trial.number)\n",
        "    loaded_model = tf.keras.models.load_model(model_save_path)\n",
        "    # loaded_model.summary()\n",
        "    loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best keras model loss;{loss}')\n",
        "    return loaded_model\n",
        "\n",
        "\n",
        "  def build_model_from_pickle(self,pickle_path,trial_number):\n",
        "    #指定したpickleファイルのtrial_numberのモデルを読み込み\n",
        "    pickle_path='trials.pkl'\n",
        "    # 保存したtrialsを読み込む\n",
        "    with open(pickle_path, 'rb') as f:\n",
        "        loaded_trials = pickle.load(f)\n",
        "\n",
        "    # 読み込んだtrialsを表示\n",
        "    print(f'loaded trials:{loaded_trials}')\n",
        "    for i in loaded_trials:\n",
        "      print(f'trials{str(i.number)}:{i}')\n",
        "\n",
        "    # 指定したtrialのモデルを読み込み\n",
        "    return self.build_model_from_trial(trial_number)\n",
        "\n",
        "def model_definitinon(n_units_per_layer,optimizer_name,lr):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(Dense(n_units_per_layer[0], activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for units in n_units_per_layer[1:]:\n",
        "      model.add(Dense(units, activation='relu',kernel_initializer=HeNormal()))\n",
        "      model.add(BatchNormalization())\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # オプティマイザの設定\n",
        "    if optimizer_name == 'Adam':\n",
        "        # optimizer = Adam(lr=lr)\n",
        "        # optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    # elif optimizer_name == 'SGD':\n",
        "    #     # optimizer = SGD(lr=lr)\n",
        "    #     optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)\n",
        "    else:\n",
        "        # optimizer = RMSprop(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
        "        # optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=lr)\n",
        "\n",
        "    # モデルのコンパイル\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# 目的関数の定義\n",
        "def objective(trial):\n",
        "    #ハイパーパラメータの提案\n",
        "    ## オプティマイザの提案※SGDは使用しない\n",
        "    # optimizer_options = ['Adam', 'SGD', 'RMSprop']\n",
        "    optimizer_options = ['Adam', 'RMSprop']\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', optimizer_options)\n",
        "    ## 学習率の提案\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "    ## 各層の数、ユニット数の提案\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 5 )\n",
        "    n_units_per_layer = [trial.suggest_int(f'n_units_layer{i}', 8, 128) for i in range(n_layers)]\n",
        "    # バッチサイズの提案\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "\n",
        "    # モデルの構築\n",
        "    model=model_definitinon(n_units_per_layer,optimizer_name,lr)\n",
        "    # モデルの訓練\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    # model.summary()\n",
        "    # print(f'loss;{loss}')\n",
        "\n",
        "    # best trialと最新モデル以外削除\n",
        "    ## 過去のtrialの.kerasを削除\n",
        "    pattern = re.compile(r'model_\\d+\\.keras$')\n",
        "    # List all files in the directory\n",
        "    cur_dir='.'\n",
        "    files = os.listdir(cur_dir)\n",
        "    for file in files:\n",
        "      # If the file matches the pattern\n",
        "      if pattern.match(file):\n",
        "        # Delete the file\n",
        "        os.remove(os.path.join(cur_dir, file))\n",
        "        # print(f\"Deleted file: {file}\")\n",
        "    # 現在のトライアルの.kerasモデルの保存\n",
        "    model_save_path = './model_'+str(trial.number)+'.keras'\n",
        "    model.save(model_save_path)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def save_trial_data(study,trial):\n",
        "    #パラメータを書き込み\n",
        "    write_trial_to_file(study,trial)\n",
        "    #モデルを保存\n",
        "    save_model(study,trial)\n",
        "\n",
        "def write_trial_to_file(study,trial):\n",
        "    # CSVファイルのパスとカラム名を指定\n",
        "    file_path = 'param.csv'\n",
        "    # n_layers=5\n",
        "\n",
        "    #列名が記載されたDataFrame作成\n",
        "    columns = ['trial_number','loss','optimizer', 'lr', 'batch_size','n_layers']\n",
        "    add_layer_columns=[\"n_units_layer\"+str(i) for i in range(trial.params['n_layers'])]\n",
        "    columns=columns+add_layer_columns\n",
        "    # print(f\"columns名：{columns}\")\n",
        "    trial_df=pd.DataFrame(columns=columns)\n",
        "\n",
        "    # ハイパーパラメータとlossの値を辞書に格納\n",
        "    trial_data = trial.params\n",
        "    # print(trial.params)\n",
        "    trial_data['loss'] = trial.value\n",
        "    trial_data['trial_number'] = trial.number\n",
        "\n",
        "    # DataFrameを作成\n",
        "    data_df=pd.DataFrame([trial_data])\n",
        "    trial_df=pd.concat([trial_df,data_df],ignore_index=True)\n",
        "    # print(f\"dic:{trial_data}\")\n",
        "    # print(f\"dataframe:{trial_df}\")\n",
        "\n",
        "    # 履歴データを書き込み\n",
        "    write_df_to_csv(file_path,trial_df)\n",
        "\n",
        "def write_df_to_csv(file_path, data_df):\n",
        "  #ファイル書き込みの関数を定義\n",
        "    try:\n",
        "      # 既存のCSVファイルがあるかチェック\n",
        "      if os.path.isfile(file_path):\n",
        "          # 既存のCSVファイルを読み込む\n",
        "          existing_df = pd.read_csv(file_path)\n",
        "          # 新しいデータを結合する\n",
        "          ##※データ欠損は0で補完\n",
        "          combined_df = pd.concat([existing_df, data_df], axis=0, ignore_index=True).fillna(0)\n",
        "      else:\n",
        "          # CSVファイルが存在しない場合は新しいDataFrameを作成\n",
        "          combined_df = data_df\n",
        "\n",
        "      # 結合したDataFrameをCSVに書き込む\n",
        "      combined_df.to_csv(file_path, index=False)\n",
        "    except Exception as e:\n",
        "        # エラーが発生した場合の処理\n",
        "        print(f'ファイル書き込み中にエラーが発生しました: {e}')\n",
        "\n",
        "def save_model(study,trial):\n",
        "    # 最新trialとモデルと最適モデルのみの.kerasモデルを保存する処理(保存自体はObjectiveで実施)+trial情報をplkで保存ためのコールバック関数\n",
        "    # ここで必要に応じてstudy.trialsを保存する処理を追加\n",
        "    trials_l = study.trials\n",
        "\n",
        "    # trialsを外部ファイルに保存\n",
        "    with open('trial_info.pkl', 'wb') as f:\n",
        "        pickle.dump(trials_l, f)\n",
        "\n",
        "    # print(f'trial number:{trial.number}')\n",
        "    # print(f'best trial number;{study.best_trial.number}')\n",
        "    # 現在のトライアルがbestトライアルならbest_trialとしてモデルを保存\n",
        "    if trial.number==study.best_trial.number:\n",
        "      load_model_path='./model_'+str(study.best_trial.number)+'.keras'\n",
        "      best_model=tf.keras.models.load_model(load_model_path)\n",
        "      model_save_path = './best_model.keras'\n",
        "      best_model.save(model_save_path)\n",
        "      print(f'Best trial trial number:{trial.number}')\n",
        "      print(f'Model saved to {model_save_path}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    #トライアル回数の指定\n",
        "    n_trials=4\n",
        "    #最適化の再開(True)か新規最適化(False)\n",
        "    resume_flag=True\n",
        "\n",
        "    # RDB Backendを使用したチェックポイントの保存\n",
        "    study_name = \"example-study\"\n",
        "    storage_name = f\"sqlite:///{study_name}.db\"\n",
        "    storage_path='./'+study_name+'.db'\n",
        "\n",
        "    if resume_flag==True:\n",
        "      # Studyオブジェクトの作成 → Hyper parameterの最適化\n",
        "      study = optuna.create_study(direction='minimize',study_name=study_name, storage=storage_name,load_if_exists=True)\n",
        "    else:\n",
        "      #初期化処理\n",
        "      ## keras file 削除\n",
        "      keras_files=glob.glob('./*.keras')\n",
        "      for k_file in keras_files:\n",
        "        os.remove(k_file)\n",
        "      ## pkl削除\n",
        "      pkl_path = './trial_info.pkl'\n",
        "      if os.path.exists(pkl_path):\n",
        "        os.remove(pkl_path)\n",
        "      ## param.csv削除\n",
        "      csv_path = './param.csv'\n",
        "      if os.path.exists(csv_path):\n",
        "        os.remove(csv_path)\n",
        "      # 最適化DBの初期化 → 最適化開始\n",
        "      if os.path.exists('./'+study_name+'.db'):\n",
        "        os.remove(storage_path)\n",
        "        study = optuna.create_study(direction='minimize',study_name=study_name, storage=storage_name)\n",
        "\n",
        "    # 最適化の開始\n",
        "    study.optimize(objective, n_trials=n_trials,callbacks=[save_trial_data])\n",
        "\n",
        "    # 最適化されたハイパーパラメータの出力\n",
        "    print('Number of finished trials:', len(study.trials))\n",
        "    trial = study.best_trial\n",
        "    print(f'Best trial:{trial.number}')\n",
        "    print('Value: {}'.format(trial.value))\n",
        "    print('Params: ')\n",
        "    for key, value in trial.params.items():\n",
        "        print('    {}: {}'.format(key, value))\n",
        "\n",
        "    print('**'*50)\n",
        "\n",
        "    #最適モデル構築from trial最適化時のlossにはならない\n",
        "    print(\"***loaded best model***\")\n",
        "    tm=TestModel()\n",
        "    model=tm.build_model_from_trial(trial)\n",
        "    batch_size=trial.params['batch_size']\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best model from trial loss;{loss}')\n",
        "    # print(model.summary())\n",
        "\n",
        "    # 最適モデル構築 from .keras\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    model_save_path = './best_model.keras'\n",
        "    loaded_model = tf.keras.models.load_model(model_save_path)\n",
        "    loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best model from keras loss;{loss}')\n",
        "    # print(model.summary())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIPf0JcoU0Df",
        "outputId": "c92d9503-9ef3-4da3-ea4e-6b95fea0ec06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-29 08:21:06,160] A new study created in RDB with name: example-study\n",
            "[I 2024-04-29 08:21:21,023] Trial 0 finished with value: 30219.1171875 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0002563850471883027, 'n_layers': 4, 'n_units_layer0': 123, 'n_units_layer1': 29, 'n_units_layer2': 123, 'n_units_layer3': 16, 'batch_size': 32}. Best is trial 0 with value: 30219.1171875.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial trial number:0\n",
            "Model saved to ./best_model.keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-29 08:21:29,075] Trial 1 finished with value: 7695.822265625 and parameters: {'optimizer': 'RMSprop', 'lr': 0.027240037301475027, 'n_layers': 4, 'n_units_layer0': 46, 'n_units_layer1': 68, 'n_units_layer2': 27, 'n_units_layer3': 32, 'batch_size': 128}. Best is trial 1 with value: 7695.822265625.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial trial number:1\n",
            "Model saved to ./best_model.keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-29 08:21:35,775] Trial 2 finished with value: 38079.80859375 and parameters: {'optimizer': 'Adam', 'lr': 8.991213457720888e-05, 'n_layers': 1, 'n_units_layer0': 113, 'batch_size': 128}. Best is trial 1 with value: 7695.822265625.\n",
            "[I 2024-04-29 08:21:41,812] Trial 3 finished with value: 35669.66796875 and parameters: {'optimizer': 'Adam', 'lr': 0.0002438769158971293, 'n_layers': 1, 'n_units_layer0': 82, 'batch_size': 128}. Best is trial 1 with value: 7695.822265625.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 4\n",
            "Best trial:1\n",
            "Value: 7695.822265625\n",
            "Params: \n",
            "    optimizer: RMSprop\n",
            "    lr: 0.027240037301475027\n",
            "    n_layers: 4\n",
            "    n_units_layer0: 46\n",
            "    n_units_layer1: 68\n",
            "    n_units_layer2: 27\n",
            "    n_units_layer3: 32\n",
            "    batch_size: 128\n",
            "****************************************************************************************************\n",
            "***loaded best model***\n",
            "loaded best model from trial loss;5818.4775390625\n",
            "==============================\n",
            "loaded best model from keras loss;7695.822265625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pklファイルの中身の確認"
      ],
      "metadata": {
        "id": "79tKg_vgHwc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### code"
      ],
      "metadata": {
        "id": "xjVdgffKH6wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('trial_info.pkl', 'rb') as f:\n",
        "    content = pickle.load(f)\n",
        "print(content)\n",
        "for c in content:\n",
        "  print(c)\n",
        "  print(f'number:{c.number}')\n",
        "  print(f'values:{c.values}')\n",
        "  print(f'params:{c.params}')\n",
        "  print(f'params type:{type(c.params)}')\n",
        "  print('-'*20)\n",
        "\n"
      ],
      "metadata": {
        "id": "tQVs_M1tH2gC",
        "outputId": "23d8fa13-4cff-491a-e64e-75948fa00e70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FrozenTrial(number=0, state=TrialState.COMPLETE, values=[30219.1171875], datetime_start=datetime.datetime(2024, 4, 29, 8, 21, 6, 204768), datetime_complete=datetime.datetime(2024, 4, 29, 8, 21, 20, 989425), params={'optimizer': 'RMSprop', 'lr': 0.0002563850471883027, 'n_layers': 4, 'n_units_layer0': 123, 'n_units_layer1': 29, 'n_units_layer2': 123, 'n_units_layer3': 16, 'batch_size': 32}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer1': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer2': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer3': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=1, value=None), FrozenTrial(number=1, state=TrialState.COMPLETE, values=[7695.822265625], datetime_start=datetime.datetime(2024, 4, 29, 8, 21, 21, 355497), datetime_complete=datetime.datetime(2024, 4, 29, 8, 21, 29, 44488), params={'optimizer': 'RMSprop', 'lr': 0.027240037301475027, 'n_layers': 4, 'n_units_layer0': 46, 'n_units_layer1': 68, 'n_units_layer2': 27, 'n_units_layer3': 32, 'batch_size': 128}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer1': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer2': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer3': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=2, value=None), FrozenTrial(number=2, state=TrialState.COMPLETE, values=[38079.80859375], datetime_start=datetime.datetime(2024, 4, 29, 8, 21, 29, 525434), datetime_complete=datetime.datetime(2024, 4, 29, 8, 21, 35, 752360), params={'optimizer': 'Adam', 'lr': 8.991213457720888e-05, 'n_layers': 1, 'n_units_layer0': 113, 'batch_size': 128}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=3, value=None), FrozenTrial(number=3, state=TrialState.COMPLETE, values=[35669.66796875], datetime_start=datetime.datetime(2024, 4, 29, 8, 21, 35, 815203), datetime_complete=datetime.datetime(2024, 4, 29, 8, 21, 41, 783376), params={'optimizer': 'Adam', 'lr': 0.0002438769158971293, 'n_layers': 1, 'n_units_layer0': 82, 'batch_size': 128}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=4, value=None)]\n",
            "FrozenTrial(number=0, state=TrialState.COMPLETE, values=[30219.1171875], datetime_start=datetime.datetime(2024, 4, 29, 8, 21, 6, 204768), datetime_complete=datetime.datetime(2024, 4, 29, 8, 21, 20, 989425), params={'optimizer': 'RMSprop', 'lr': 0.0002563850471883027, 'n_layers': 4, 'n_units_layer0': 123, 'n_units_layer1': 29, 'n_units_layer2': 123, 'n_units_layer3': 16, 'batch_size': 32}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer1': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer2': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer3': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=1, value=None)\n",
            "number:0\n",
            "values:[30219.1171875]\n",
            "params:{'optimizer': 'RMSprop', 'lr': 0.0002563850471883027, 'n_layers': 4, 'n_units_layer0': 123, 'n_units_layer1': 29, 'n_units_layer2': 123, 'n_units_layer3': 16, 'batch_size': 32}\n",
            "params type:<class 'dict'>\n",
            "--------------------\n",
            "FrozenTrial(number=1, state=TrialState.COMPLETE, values=[7695.822265625], datetime_start=datetime.datetime(2024, 4, 29, 8, 21, 21, 355497), datetime_complete=datetime.datetime(2024, 4, 29, 8, 21, 29, 44488), params={'optimizer': 'RMSprop', 'lr': 0.027240037301475027, 'n_layers': 4, 'n_units_layer0': 46, 'n_units_layer1': 68, 'n_units_layer2': 27, 'n_units_layer3': 32, 'batch_size': 128}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer1': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer2': IntDistribution(high=128, log=False, low=8, step=1), 'n_units_layer3': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=2, value=None)\n",
            "number:1\n",
            "values:[7695.822265625]\n",
            "params:{'optimizer': 'RMSprop', 'lr': 0.027240037301475027, 'n_layers': 4, 'n_units_layer0': 46, 'n_units_layer1': 68, 'n_units_layer2': 27, 'n_units_layer3': 32, 'batch_size': 128}\n",
            "params type:<class 'dict'>\n",
            "--------------------\n",
            "FrozenTrial(number=2, state=TrialState.COMPLETE, values=[38079.80859375], datetime_start=datetime.datetime(2024, 4, 29, 8, 21, 29, 525434), datetime_complete=datetime.datetime(2024, 4, 29, 8, 21, 35, 752360), params={'optimizer': 'Adam', 'lr': 8.991213457720888e-05, 'n_layers': 1, 'n_units_layer0': 113, 'batch_size': 128}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=3, value=None)\n",
            "number:2\n",
            "values:[38079.80859375]\n",
            "params:{'optimizer': 'Adam', 'lr': 8.991213457720888e-05, 'n_layers': 1, 'n_units_layer0': 113, 'batch_size': 128}\n",
            "params type:<class 'dict'>\n",
            "--------------------\n",
            "FrozenTrial(number=3, state=TrialState.COMPLETE, values=[35669.66796875], datetime_start=datetime.datetime(2024, 4, 29, 8, 21, 35, 815203), datetime_complete=datetime.datetime(2024, 4, 29, 8, 21, 41, 783376), params={'optimizer': 'Adam', 'lr': 0.0002438769158971293, 'n_layers': 1, 'n_units_layer0': 82, 'batch_size': 128}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('Adam', 'RMSprop')), 'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=5, log=False, low=1, step=1), 'n_units_layer0': IntDistribution(high=128, log=False, low=8, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128))}, trial_id=4, value=None)\n",
            "number:3\n",
            "values:[35669.66796875]\n",
            "params:{'optimizer': 'Adam', 'lr': 0.0002438769158971293, 'n_layers': 1, 'n_units_layer0': 82, 'batch_size': 128}\n",
            "params type:<class 'dict'>\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SQliteの中身の確認"
      ],
      "metadata": {
        "id": "WPqo_bVNIYxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### code"
      ],
      "metadata": {
        "id": "Fhq-DzmXItVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# データベースファイルのパス\n",
        "db_path = 'example-study.db'\n",
        "\n",
        "# データベースに接続\n",
        "conn = sqlite3.connect(db_path)\n",
        "\n",
        "# カーソルを作成\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# テーブル一覧を取得\n",
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "table_names = cursor.fetchall()\n",
        "\n",
        "# 各テーブルの内容を表示\n",
        "for table_name in table_names:\n",
        "    print(f\"Table: {table_name[0]}\")\n",
        "    cursor.execute(f\"SELECT * FROM {table_name[0]}\")\n",
        "    rows = cursor.fetchall()\n",
        "    for row in rows:\n",
        "        print(row)\n",
        "\n",
        "# 接続を閉じる\n",
        "conn.close()\n"
      ],
      "metadata": {
        "id": "RZ_VMevsh5C2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeefe495-6985-4a0b-8c99-21f8a7054f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table: studies\n",
            "(1, 'example-study')\n",
            "Table: version_info\n",
            "(1, 12, '3.6.1')\n",
            "Table: study_directions\n",
            "(1, 'MINIMIZE', 1, 0)\n",
            "Table: study_user_attributes\n",
            "Table: study_system_attributes\n",
            "Table: trials\n",
            "(1, 0, 1, 'COMPLETE', '2024-04-29 08:21:06.204768', '2024-04-29 08:21:20.989425')\n",
            "(2, 1, 1, 'COMPLETE', '2024-04-29 08:21:21.355497', '2024-04-29 08:21:29.044488')\n",
            "(3, 2, 1, 'COMPLETE', '2024-04-29 08:21:29.525434', '2024-04-29 08:21:35.752360')\n",
            "(4, 3, 1, 'COMPLETE', '2024-04-29 08:21:35.815203', '2024-04-29 08:21:41.783376')\n",
            "Table: trial_user_attributes\n",
            "Table: trial_system_attributes\n",
            "Table: trial_params\n",
            "(1, 1, 'optimizer', 1.0, '{\"name\": \"CategoricalDistribution\", \"attributes\": {\"choices\": [\"Adam\", \"RMSprop\"]}}')\n",
            "(2, 1, 'lr', 0.0002563850471883027, '{\"name\": \"FloatDistribution\", \"attributes\": {\"step\": null, \"low\": 1e-05, \"high\": 0.1, \"log\": true}}')\n",
            "(3, 1, 'n_layers', 4.0, '{\"name\": \"IntDistribution\", \"attributes\": {\"log\": false, \"step\": 1, \"low\": 1, \"high\": 5}}')\n",
            "(4, 1, 'n_units_layer0', 123.0, '{\"name\": \"IntDistribution\", \"attributes\": {\"log\": false, \"step\": 1, \"low\": 8, \"high\": 128}}')\n",
            "(5, 1, 'n_units_layer1', 29.0, '{\"name\": \"IntDistribution\", \"attributes\": {\"log\": false, \"step\": 1, \"low\": 8, \"high\": 128}}')\n",
            "(6, 1, 'n_units_layer2', 123.0, '{\"name\": \"IntDistribution\", \"attributes\": {\"log\": false, \"step\": 1, \"low\": 8, \"high\": 128}}')\n",
            "(7, 1, 'n_units_layer3', 16.0, '{\"name\": \"IntDistribution\", \"attributes\": {\"log\": false, \"step\": 1, \"low\": 8, \"high\": 128}}')\n",
            "(8, 1, 'batch_size', 0.0, '{\"name\": \"CategoricalDistribution\", \"attributes\": {\"choices\": [32, 64, 128]}}')\n",
            "(9, 2, 'optimizer', 1.0, '{\"name\": \"CategoricalDistribution\", \"attributes\": {\"choices\": [\"Adam\", \"RMSprop\"]}}')\n",
            "(10, 2, 'lr', 0.027240037301475027, '{\"name\": \"FloatDistribution\", \"attributes\": {\"step\": null, \"low\": 1e-05, \"high\": 0.1, \"log\": true}}')\n",
            "(11, 2, 'n_layers', 4.0, '{\"name\": \"IntDistribution\", \"attributes\": {\"log\": false, \"step\": 1, \"low\": 1, \"high\": 5}}')\n",
            "(12, 2, 'n_units_layer0', 46.0, '{\"name\": \"IntDistribution\", \"attributes\": {\"log\": false, \"step\": 1, \"low\": 8, \"high\": 128}}')\n",
            "(13, 2, 'n_units_layer1', 68.0, '{\"name\": \"IntDistribution\", \"attributes\": {\"log\": false, \"step\": 1, \"low\": 8, \"high\": 128}}')\n",
            "(14, 2, 'n_units_layer2', 27.0, '{\"name\": \"IntDistribution\", \"attributes\": {\"log\": false, \"step\": 1, \"low\": 8, \"high\": 128}}')\n",
            "(15, 2, 'n_units_layer3', 32.0, '{\"name\": \"IntDistribution\", \"attributes\": {\"log\": false, \"step\": 1, \"low\": 8, \"high\": 128}}')\n",
            "(16, 2, 'batch_size', 2.0, '{\"name\": \"CategoricalDistribution\", \"attributes\": {\"choices\": [32, 64, 128]}}')\n",
            "(17, 3, 'optimizer', 0.0, '{\"name\": \"CategoricalDistribution\", \"attributes\": {\"choices\": [\"Adam\", \"RMSprop\"]}}')\n",
            "(18, 3, 'lr', 8.991213457720888e-05, '{\"name\": \"FloatDistribution\", \"attributes\": {\"step\": null, \"low\": 1e-05, \"high\": 0.1, \"log\": true}}')\n",
            "(19, 3, 'n_layers', 1.0, '{\"name\": \"IntDistribution\", \"attributes\": {\"log\": false, \"step\": 1, \"low\": 1, \"high\": 5}}')\n",
            "(20, 3, 'n_units_layer0', 113.0, '{\"name\": \"IntDistribution\", \"attributes\": {\"log\": false, \"step\": 1, \"low\": 8, \"high\": 128}}')\n",
            "(21, 3, 'batch_size', 2.0, '{\"name\": \"CategoricalDistribution\", \"attributes\": {\"choices\": [32, 64, 128]}}')\n",
            "(22, 4, 'optimizer', 0.0, '{\"name\": \"CategoricalDistribution\", \"attributes\": {\"choices\": [\"Adam\", \"RMSprop\"]}}')\n",
            "(23, 4, 'lr', 0.0002438769158971293, '{\"name\": \"FloatDistribution\", \"attributes\": {\"step\": null, \"low\": 1e-05, \"high\": 0.1, \"log\": true}}')\n",
            "(24, 4, 'n_layers', 1.0, '{\"name\": \"IntDistribution\", \"attributes\": {\"log\": false, \"step\": 1, \"low\": 1, \"high\": 5}}')\n",
            "(25, 4, 'n_units_layer0', 82.0, '{\"name\": \"IntDistribution\", \"attributes\": {\"log\": false, \"step\": 1, \"low\": 8, \"high\": 128}}')\n",
            "(26, 4, 'batch_size', 2.0, '{\"name\": \"CategoricalDistribution\", \"attributes\": {\"choices\": [32, 64, 128]}}')\n",
            "Table: trial_values\n",
            "(1, 1, 0, 30219.1171875, 'FINITE')\n",
            "(2, 2, 0, 7695.822265625, 'FINITE')\n",
            "(3, 3, 0, 38079.80859375, 'FINITE')\n",
            "(4, 4, 0, 35669.66796875, 'FINITE')\n",
            "Table: trial_intermediate_values\n",
            "Table: trial_heartbeats\n",
            "Table: alembic_version\n",
            "('v3.2.0.a',)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データをBoston住宅価格に戻した"
      ],
      "metadata": {
        "id": "xTs28OVq-o_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### code"
      ],
      "metadata": {
        "id": "Gmk4xXuy8xdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import re\n",
        "import glob\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "\n",
        "# データセットの準備（ここでは合成データセットを使用）\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
        "\n",
        "# データのスケーリング\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "class TestModel():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  # 最適化されたハイパーパラメータを使用してモデルを構築する関数\n",
        "  def build_model_from_trial(self,trial):\n",
        "      #モデルパラメータの取得\n",
        "      # print(f'trial params:{trial.params}')\n",
        "      units_len=trial.params['n_layers']\n",
        "      units=[value for key,value in trial.params.items() if 'n_units_layer' in key]\n",
        "      learning_rate=trial.params['lr']\n",
        "      optimizer_name=trial.params['optimizer']\n",
        "      # print(f'optimizer name:{optimizer_name}')\n",
        "      # print(f'lr:{learning_rate}')\n",
        "      # print(f'n layers:{len(units)}')\n",
        "      # print(f'units:{units}')\n",
        "\n",
        "      # モデルの構築\n",
        "      model=model_definitinon(units,optimizer_name,learning_rate)\n",
        "      # model=self.model_from_input(units,learning_rate,optimizer_name)\n",
        "\n",
        "      return model\n",
        "\n",
        "  def save_keras_model(self,model_save_path):\n",
        "    #kerasモデル保存\n",
        "    # model_save_path = './model'+str(trial.number)\n",
        "    tf.keras.models.save_model(model, model_save_path)\n",
        "\n",
        "\n",
        "  def load_keras_model(self,model_save_path):\n",
        "    #kerasモデル読み込み\n",
        "    # model_save_path = './model'+str(trial.number)\n",
        "    loaded_model = tf.keras.models.load_model(model_save_path)\n",
        "    # loaded_model.summary()\n",
        "    loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best keras model loss;{loss}')\n",
        "    return loaded_model\n",
        "\n",
        "\n",
        "  def build_model_from_pickle(self,pickle_path,trial_number):\n",
        "    #指定したpickleファイルのtrial_numberのモデルを読み込み\n",
        "    pickle_path='trials.pkl'\n",
        "    # 保存したtrialsを読み込む\n",
        "    with open(pickle_path, 'rb') as f:\n",
        "        loaded_trials = pickle.load(f)\n",
        "\n",
        "    # 読み込んだtrialsを表示\n",
        "    print(f'loaded trials:{loaded_trials}')\n",
        "    for i in loaded_trials:\n",
        "      print(f'trials{str(i.number)}:{i}')\n",
        "\n",
        "    # 指定したtrialのモデルを読み込み\n",
        "    return self.build_model_from_trial(trial_number)\n",
        "\n",
        "def model_definitinon(n_units_per_layer,optimizer_name,lr):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(Dense(n_units_per_layer[0], activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for units in n_units_per_layer[1:]:\n",
        "      model.add(Dense(units, activation='relu',kernel_initializer=HeNormal()))\n",
        "      model.add(BatchNormalization())\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # オプティマイザの設定\n",
        "    if optimizer_name == 'Adam':\n",
        "        # optimizer = Adam(lr=lr)\n",
        "        # optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    # elif optimizer_name == 'SGD':\n",
        "    #     # optimizer = SGD(lr=lr)\n",
        "    #     optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)\n",
        "    else:\n",
        "        # optimizer = RMSprop(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
        "        # optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=lr)\n",
        "\n",
        "    # モデルのコンパイル\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# 目的関数の定義\n",
        "def objective(trial):\n",
        "    #ハイパーパラメータの提案\n",
        "    ## オプティマイザの提案※SGDは使用しない\n",
        "    # optimizer_options = ['Adam', 'SGD', 'RMSprop']\n",
        "    optimizer_options = ['Adam', 'RMSprop']\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', optimizer_options)\n",
        "    ## 学習率の提案\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "    ## 各層の数、ユニット数の提案\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 5 )\n",
        "    n_units_per_layer = [trial.suggest_int(f'n_units_layer{i}', 8, 128) for i in range(n_layers)]\n",
        "    # バッチサイズの提案\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "\n",
        "    # モデルの構築\n",
        "    model=model_definitinon(n_units_per_layer,optimizer_name,lr)\n",
        "    # モデルの訓練\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    # model.summary()\n",
        "    # print(f'loss;{loss}')\n",
        "\n",
        "    # best trialと最新モデル以外削除\n",
        "    ## 過去のtrialの.kerasを削除\n",
        "    pattern = re.compile(r'model_\\d+\\.keras$')\n",
        "    # List all files in the directory\n",
        "    cur_dir='.'\n",
        "    files = os.listdir(cur_dir)\n",
        "    for file in files:\n",
        "      # If the file matches the pattern\n",
        "      if pattern.match(file):\n",
        "        # Delete the file\n",
        "        os.remove(os.path.join(cur_dir, file))\n",
        "        # print(f\"Deleted file: {file}\")\n",
        "    # 現在のトライアルの.kerasモデルの保存\n",
        "    model_save_path = './model_'+str(trial.number)+'.keras'\n",
        "    model.save(model_save_path)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def save_trial_data(study,trial):\n",
        "    #パラメータを書き込み\n",
        "    write_trial_to_file(study,trial)\n",
        "    #モデルを保存\n",
        "    save_model(study,trial)\n",
        "\n",
        "def write_trial_to_file(study,trial):\n",
        "    # CSVファイルのパスとカラム名を指定\n",
        "    file_path = 'param.csv'\n",
        "    # n_layers=5\n",
        "\n",
        "    #列名が記載されたDataFrame作成\n",
        "    columns = ['trial_number','loss','optimizer', 'lr', 'batch_size','n_layers']\n",
        "    add_layer_columns=[\"n_units_layer\"+str(i) for i in range(trial.params['n_layers'])]\n",
        "    columns=columns+add_layer_columns\n",
        "    # print(f\"columns名：{columns}\")\n",
        "    trial_df=pd.DataFrame(columns=columns)\n",
        "\n",
        "    # ハイパーパラメータとlossの値を辞書に格納\n",
        "    trial_data = trial.params\n",
        "    # print(trial.params)\n",
        "    trial_data['loss'] = trial.value\n",
        "    trial_data['trial_number'] = trial.number\n",
        "\n",
        "    # DataFrameを作成\n",
        "    data_df=pd.DataFrame([trial_data])\n",
        "    trial_df=pd.concat([trial_df,data_df],ignore_index=True)\n",
        "    # print(f\"dic:{trial_data}\")\n",
        "    # print(f\"dataframe:{trial_df}\")\n",
        "\n",
        "    # 履歴データを書き込み\n",
        "    write_df_to_csv(file_path,trial_df)\n",
        "\n",
        "def write_df_to_csv(file_path, data_df):\n",
        "  #ファイル書き込みの関数を定義\n",
        "    try:\n",
        "      # 既存のCSVファイルがあるかチェック\n",
        "      if os.path.isfile(file_path):\n",
        "          # 既存のCSVファイルを読み込む\n",
        "          existing_df = pd.read_csv(file_path)\n",
        "          # 新しいデータを結合する\n",
        "          ##※データ欠損は0で補完\n",
        "          combined_df = pd.concat([existing_df, data_df], axis=0, ignore_index=True).fillna(0)\n",
        "      else:\n",
        "          # CSVファイルが存在しない場合は新しいDataFrameを作成\n",
        "          combined_df = data_df\n",
        "\n",
        "      # 結合したDataFrameをCSVに書き込む\n",
        "      combined_df.to_csv(file_path, index=False)\n",
        "    except Exception as e:\n",
        "        # エラーが発生した場合の処理\n",
        "        print(f'ファイル書き込み中にエラーが発生しました: {e}')\n",
        "\n",
        "def save_model(study,trial):\n",
        "    # 最新trialとモデルと最適モデルのみの.kerasモデルを保存する処理(保存自体はObjectiveで実施)+trial情報をplkで保存ためのコールバック関数\n",
        "    # ここで必要に応じてstudy.trialsを保存する処理を追加\n",
        "    trials_l = study.trials\n",
        "\n",
        "    # trialsを外部ファイルに保存\n",
        "    with open('trial_info.pkl', 'wb') as f:\n",
        "        pickle.dump(trials_l, f)\n",
        "\n",
        "    # print(f'trial number:{trial.number}')\n",
        "    # print(f'best trial number;{study.best_trial.number}')\n",
        "    # 現在のトライアルがbestトライアルならbest_trialとしてモデルを保存\n",
        "    if trial.number==study.best_trial.number:\n",
        "      load_model_path='./model_'+str(study.best_trial.number)+'.keras'\n",
        "      best_model=tf.keras.models.load_model(load_model_path)\n",
        "      model_save_path = './best_model.keras'\n",
        "      best_model.save(model_save_path)\n",
        "      print(f'Best trial trial number:{trial.number}')\n",
        "      print(f'Model saved to {model_save_path}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    #トライアル回数の指定\n",
        "    n_trials=4\n",
        "    #最適化の再開(True)か新規最適化(False)\n",
        "    resume_flag=False\n",
        "\n",
        "    # RDB Backendを使用したチェックポイントの保存\n",
        "    study_name = \"example-study\"\n",
        "    storage_name = f\"sqlite:///{study_name}.db\"\n",
        "    storage_path='./'+study_name+'.db'\n",
        "\n",
        "    if resume_flag==True:\n",
        "      # Studyオブジェクトの作成 → Hyper parameterの最適化\n",
        "      study = optuna.create_study(direction='minimize',study_name=study_name, storage=storage_name,load_if_exists=True)\n",
        "    else:\n",
        "      #初期化処理\n",
        "      ## keras file 削除\n",
        "      keras_files=glob.glob('./*.keras')\n",
        "      for k_file in keras_files:\n",
        "        os.remove(k_file)\n",
        "      ## pkl削除\n",
        "      pkl_path = './trial_info.pkl'\n",
        "      if os.path.exists(pkl_path):\n",
        "        os.remove(pkl_path)\n",
        "      ## param.csv削除\n",
        "      csv_path = './param.csv'\n",
        "      if os.path.exists(csv_path):\n",
        "        os.remove(csv_path)\n",
        "      # 最適化DBの初期化 → 最適化開始\n",
        "      if os.path.exists('./'+study_name+'.db'):\n",
        "        os.remove(storage_path)\n",
        "        study = optuna.create_study(direction='minimize',study_name=study_name, storage=storage_name)\n",
        "\n",
        "    # 最適化の開始\n",
        "    study.optimize(objective, n_trials=n_trials,callbacks=[save_trial_data])\n",
        "\n",
        "    # 最適化されたハイパーパラメータの出力\n",
        "    print('Number of finished trials:', len(study.trials))\n",
        "    trial = study.best_trial\n",
        "    print(f'Best trial:{trial.number}')\n",
        "    print('Value: {}'.format(trial.value))\n",
        "    print('Params: ')\n",
        "    for key, value in trial.params.items():\n",
        "        print('    {}: {}'.format(key, value))\n",
        "\n",
        "    print('**'*50)\n",
        "\n",
        "    #最適モデル構築from trial最適化時のlossにはならない\n",
        "    print(\"***loaded best model***\")\n",
        "    tm=TestModel()\n",
        "    model=tm.build_model_from_trial(trial)\n",
        "    batch_size=trial.params['batch_size']\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best model from trial loss;{loss}')\n",
        "    # print(model.summary())\n",
        "\n",
        "    # 最適モデル構築 from .keras\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    model_save_path = './best_model.keras'\n",
        "    loaded_model = tf.keras.models.load_model(model_save_path)\n",
        "    loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best model from keras loss;{loss}')\n",
        "    # print(model.summary())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FEBq-3DW8zhf",
        "outputId": "3cc165be-e969-4f2f-c2aa-5975baaefb2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-29 09:24:32,622] A new study created in RDB with name: example-study\n",
            "[I 2024-04-29 09:24:41,879] Trial 0 finished with value: 18.880834579467773 and parameters: {'optimizer': 'RMSprop', 'lr': 0.019198167131007436, 'n_layers': 1, 'n_units_layer0': 116, 'batch_size': 64}. Best is trial 0 with value: 18.880834579467773.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial trial number:0\n",
            "Model saved to ./best_model.keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-29 09:24:50,587] Trial 1 finished with value: 85.59780883789062 and parameters: {'optimizer': 'Adam', 'lr': 0.032861312852168596, 'n_layers': 4, 'n_units_layer0': 112, 'n_units_layer1': 87, 'n_units_layer2': 27, 'n_units_layer3': 70, 'batch_size': 64}. Best is trial 0 with value: 18.880834579467773.\n",
            "[I 2024-04-29 09:24:55,127] Trial 2 finished with value: 17.35651397705078 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0022349061225772605, 'n_layers': 2, 'n_units_layer0': 73, 'n_units_layer1': 77, 'batch_size': 128}. Best is trial 2 with value: 17.35651397705078.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial trial number:2\n",
            "Model saved to ./best_model.keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-29 09:25:02,218] Trial 3 finished with value: 20.91100311279297 and parameters: {'optimizer': 'Adam', 'lr': 0.0019172230884643812, 'n_layers': 1, 'n_units_layer0': 52, 'batch_size': 32}. Best is trial 2 with value: 17.35651397705078.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 4\n",
            "Best trial:2\n",
            "Value: 17.35651397705078\n",
            "Params: \n",
            "    optimizer: RMSprop\n",
            "    lr: 0.0022349061225772605\n",
            "    n_layers: 2\n",
            "    n_units_layer0: 73\n",
            "    n_units_layer1: 77\n",
            "    batch_size: 128\n",
            "****************************************************************************************************\n",
            "***loaded best model***\n",
            "loaded best model from trial loss;16.163360595703125\n",
            "==============================\n",
            "loaded best model from keras loss;17.35651397705078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prediction グラフ化追加"
      ],
      "metadata": {
        "id": "q1Nnd7onNxJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### code"
      ],
      "metadata": {
        "id": "qiV8LPFIN9ja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import re\n",
        "import glob\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "\n",
        "# データセットの準備（ここでは合成データセットを使用）\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
        "\n",
        "# データのスケーリング\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "class TestModel():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  # 最適化されたハイパーパラメータを使用してモデルを構築する関数\n",
        "  def build_model_from_trial(self,trial):\n",
        "      #モデルパラメータの取得\n",
        "      # print(f'trial params:{trial.params}')\n",
        "      units_len=trial.params['n_layers']\n",
        "      units=[value for key,value in trial.params.items() if 'n_units_layer' in key]\n",
        "      learning_rate=trial.params['lr']\n",
        "      optimizer_name=trial.params['optimizer']\n",
        "      # print(f'optimizer name:{optimizer_name}')\n",
        "      # print(f'lr:{learning_rate}')\n",
        "      # print(f'n layers:{len(units)}')\n",
        "      # print(f'units:{units}')\n",
        "\n",
        "      # モデルの構築\n",
        "      model=model_definitinon(units,optimizer_name,learning_rate)\n",
        "      # model=self.model_from_input(units,learning_rate,optimizer_name)\n",
        "\n",
        "      return model\n",
        "\n",
        "  def save_keras_model(self,model_save_path):\n",
        "    #kerasモデル保存\n",
        "    # model_save_path = './model'+str(trial.number)\n",
        "    tf.keras.models.save_model(model, model_save_path)\n",
        "\n",
        "\n",
        "  def load_keras_model(self,model_save_path):\n",
        "    #kerasモデル読み込み\n",
        "    # model_save_path = './model'+str(trial.number)\n",
        "    loaded_model = tf.keras.models.load_model(model_save_path)\n",
        "    # loaded_model.summary()\n",
        "    loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best keras model loss;{loss}')\n",
        "    return loaded_model\n",
        "\n",
        "\n",
        "  def build_model_from_pickle(self,pickle_path,trial_number):\n",
        "    #指定したpickleファイルのtrial_numberのモデルを読み込み\n",
        "    pickle_path='trials.pkl'\n",
        "    # 保存したtrialsを読み込む\n",
        "    with open(pickle_path, 'rb') as f:\n",
        "        loaded_trials = pickle.load(f)\n",
        "\n",
        "    # 読み込んだtrialsを表示\n",
        "    print(f'loaded trials:{loaded_trials}')\n",
        "    for i in loaded_trials:\n",
        "      print(f'trials{str(i.number)}:{i}')\n",
        "\n",
        "    # 指定したtrialのモデルを読み込み\n",
        "    return self.build_model_from_trial(trial_number)\n",
        "\n",
        "def model_definitinon(n_units_per_layer,optimizer_name,lr):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(Dense(n_units_per_layer[0], activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for units in n_units_per_layer[1:]:\n",
        "      model.add(Dense(units, activation='relu',kernel_initializer=HeNormal()))\n",
        "      model.add(BatchNormalization())\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # オプティマイザの設定\n",
        "    if optimizer_name == 'Adam':\n",
        "        # optimizer = Adam(lr=lr)\n",
        "        # optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    # elif optimizer_name == 'SGD':\n",
        "    #     # optimizer = SGD(lr=lr)\n",
        "    #     optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)\n",
        "    else:\n",
        "        # optimizer = RMSprop(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
        "        # optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=lr)\n",
        "\n",
        "    # モデルのコンパイル\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# 目的関数の定義\n",
        "def objective(trial):\n",
        "    #ハイパーパラメータの提案\n",
        "    ## オプティマイザの提案※SGDは使用しない\n",
        "    # optimizer_options = ['Adam', 'SGD', 'RMSprop']\n",
        "    optimizer_options = ['Adam', 'RMSprop']\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', optimizer_options)\n",
        "    ## 学習率の提案\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "    ## 各層の数、ユニット数の提案\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 5 )\n",
        "    n_units_per_layer = [trial.suggest_int(f'n_units_layer{i}', 8, 128) for i in range(n_layers)]\n",
        "    # バッチサイズの提案\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "\n",
        "    # モデルの構築\n",
        "    model=model_definitinon(n_units_per_layer,optimizer_name,lr)\n",
        "    # モデルの訓練\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    # model.summary()\n",
        "    # print(f'loss;{loss}')\n",
        "\n",
        "    # best trialと最新モデル以外削除\n",
        "    ## 過去のtrialの.kerasを削除\n",
        "    pattern = re.compile(r'model_\\d+\\.keras$')\n",
        "    # List all files in the directory\n",
        "    cur_dir='.'\n",
        "    files = os.listdir(cur_dir)\n",
        "    for file in files:\n",
        "      # If the file matches the pattern\n",
        "      if pattern.match(file):\n",
        "        # Delete the file\n",
        "        os.remove(os.path.join(cur_dir, file))\n",
        "        # print(f\"Deleted file: {file}\")\n",
        "    # 現在のトライアルの.kerasモデルの保存\n",
        "    model_save_path = './model_'+str(trial.number)+'.keras'\n",
        "    model.save(model_save_path)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def save_trial_data(study,trial):\n",
        "    #パラメータを書き込み\n",
        "    write_trial_to_file(study,trial)\n",
        "    #モデルを保存\n",
        "    save_model(study,trial)\n",
        "\n",
        "def write_trial_to_file(study,trial):\n",
        "    # CSVファイルのパスとカラム名を指定\n",
        "    file_path = 'param.csv'\n",
        "    # n_layers=5\n",
        "\n",
        "    #列名が記載されたDataFrame作成\n",
        "    columns = ['trial_number','loss','optimizer', 'lr', 'batch_size','n_layers']\n",
        "    add_layer_columns=[\"n_units_layer\"+str(i) for i in range(trial.params['n_layers'])]\n",
        "    columns=columns+add_layer_columns\n",
        "    # print(f\"columns名：{columns}\")\n",
        "    trial_df=pd.DataFrame(columns=columns)\n",
        "\n",
        "    # ハイパーパラメータとlossの値を辞書に格納\n",
        "    trial_data = trial.params\n",
        "    # print(trial.params)\n",
        "    trial_data['loss'] = trial.value\n",
        "    trial_data['trial_number'] = trial.number\n",
        "\n",
        "    # DataFrameを作成\n",
        "    data_df=pd.DataFrame([trial_data])\n",
        "    trial_df=pd.concat([trial_df,data_df],ignore_index=True)\n",
        "    # print(f\"dic:{trial_data}\")\n",
        "    # print(f\"dataframe:{trial_df}\")\n",
        "\n",
        "    # 履歴データを書き込み\n",
        "    write_df_to_csv(file_path,trial_df)\n",
        "\n",
        "def write_df_to_csv(file_path, data_df):\n",
        "  #ファイル書き込みの関数を定義\n",
        "    try:\n",
        "      # 既存のCSVファイルがあるかチェック\n",
        "      if os.path.isfile(file_path):\n",
        "          # 既存のCSVファイルを読み込む\n",
        "          existing_df = pd.read_csv(file_path)\n",
        "          # 新しいデータを結合する\n",
        "          ##※データ欠損は0で補完\n",
        "          combined_df = pd.concat([existing_df, data_df], axis=0, ignore_index=True).fillna(0)\n",
        "      else:\n",
        "          # CSVファイルが存在しない場合は新しいDataFrameを作成\n",
        "          combined_df = data_df\n",
        "\n",
        "      # 結合したDataFrameをCSVに書き込む\n",
        "      combined_df.to_csv(file_path, index=False)\n",
        "    except Exception as e:\n",
        "        # エラーが発生した場合の処理\n",
        "        print(f'ファイル書き込み中にエラーが発生しました: {e}')\n",
        "\n",
        "def save_model(study,trial):\n",
        "    # 最新trialとモデルと最適モデルのみの.kerasモデルを保存する処理(保存自体はObjectiveで実施)+trial情報をplkで保存ためのコールバック関数\n",
        "    # ここで必要に応じてstudy.trialsを保存する処理を追加\n",
        "    trials_l = study.trials\n",
        "\n",
        "    # trialsを外部ファイルに保存\n",
        "    with open('trial_info.pkl', 'wb') as f:\n",
        "        pickle.dump(trials_l, f)\n",
        "\n",
        "    # print(f'trial number:{trial.number}')\n",
        "    # print(f'best trial number;{study.best_trial.number}')\n",
        "    # 現在のトライアルがbestトライアルならbest_trialとしてモデルを保存\n",
        "    if trial.number==study.best_trial.number:\n",
        "      load_model_path='./model_'+str(study.best_trial.number)+'.keras'\n",
        "      best_model=tf.keras.models.load_model(load_model_path)\n",
        "      model_save_path = './best_model.keras'\n",
        "      best_model.save(model_save_path)\n",
        "      print(f'Best trial trial number:{trial.number}')\n",
        "      print(f'Model saved to {model_save_path}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    #トライアル回数の指定\n",
        "    n_trials=4\n",
        "    #最適化の再開(True)か新規最適化(False)\n",
        "    resume_flag=False\n",
        "\n",
        "    # RDB Backendを使用したチェックポイントの保存\n",
        "    study_name = \"example-study\"\n",
        "    storage_name = f\"sqlite:///{study_name}.db\"\n",
        "    storage_path='./'+study_name+'.db'\n",
        "\n",
        "    if resume_flag==True:\n",
        "      # Studyオブジェクトの作成 → Hyper parameterの最適化\n",
        "      study = optuna.create_study(direction='minimize',study_name=study_name, storage=storage_name,load_if_exists=True)\n",
        "    else:\n",
        "      #初期化処理\n",
        "      ## keras file 削除\n",
        "      keras_files=glob.glob('./*.keras')\n",
        "      for k_file in keras_files:\n",
        "        os.remove(k_file)\n",
        "      ## pkl削除\n",
        "      pkl_path = './trial_info.pkl'\n",
        "      if os.path.exists(pkl_path):\n",
        "        os.remove(pkl_path)\n",
        "      ## param.csv削除\n",
        "      csv_path = './param.csv'\n",
        "      if os.path.exists(csv_path):\n",
        "        os.remove(csv_path)\n",
        "      # 最適化DBの初期化 → 最適化開始\n",
        "      if os.path.exists('./'+study_name+'.db'):\n",
        "        os.remove(storage_path)\n",
        "        study = optuna.create_study(direction='minimize',study_name=study_name, storage=storage_name)\n",
        "\n",
        "    # 最適化の開始\n",
        "    study.optimize(objective, n_trials=n_trials,callbacks=[save_trial_data])\n",
        "\n",
        "    # 最適化されたハイパーパラメータの出力\n",
        "    print('Number of finished trials:', len(study.trials))\n",
        "    trial = study.best_trial\n",
        "    print(f'Best trial:{trial.number}')\n",
        "    print('Value: {}'.format(trial.value))\n",
        "    print('Params: ')\n",
        "    for key, value in trial.params.items():\n",
        "        print('    {}: {}'.format(key, value))\n",
        "\n",
        "    print('**'*50)\n",
        "\n",
        "    #最適モデル構築from trial最適化時のlossにはならない\n",
        "    print(\"***loaded best model***\")\n",
        "    tm=TestModel()\n",
        "    model=tm.build_model_from_trial(trial)\n",
        "    batch_size=trial.params['batch_size']\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best model from trial loss;{loss}')\n",
        "    # print(model.summary())\n",
        "\n",
        "    # 最適モデル構築 from .keras\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    model_save_path = './best_model.keras'\n",
        "    loaded_model = tf.keras.models.load_model(model_save_path)\n",
        "    loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best model from keras loss;{loss}')\n",
        "    # print(model.summary())\n",
        "\n",
        "    # 予測値の生成\n",
        "    y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "    # グラフ化\n",
        "    import plotly.graph_objs as go\n",
        "\n",
        "    # 訓練データ、実際の価格、予測価格をプロットするためのTraceを作成\n",
        "    valid_trace = go.Scatter(x=y_test, y=y_pred.flatten(), mode='markers', name='Real')\n",
        "\n",
        "    # データをリストにまとめる\n",
        "    data = [valid_trace]\n",
        "\n",
        "    # レイアウトを定義\n",
        "    layout = go.Layout(\n",
        "        title='y_pred - y_test',\n",
        "        xaxis={'title': 'y_test'},\n",
        "        yaxis={'title': 'y_pred'},\n",
        "        hovermode='closest'\n",
        "    )\n",
        "    # フィギュアを定義し、データとレイアウトを組み合わせる\n",
        "    fig = go.Figure(data=data, layout=layout)\n",
        "\n",
        "    # グラフを表示\n",
        "    fig.show()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "pzs2nRwQN3lt",
        "outputId": "dccd82aa-e872-4591-88b3-36b00122ec1e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-29 09:55:55,793] A new study created in RDB with name: example-study\n",
            "[I 2024-04-29 09:56:06,774] Trial 0 finished with value: 16.728321075439453 and parameters: {'optimizer': 'RMSprop', 'lr': 0.017713347690583844, 'n_layers': 1, 'n_units_layer0': 69, 'batch_size': 64}. Best is trial 0 with value: 16.728321075439453.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial trial number:0\n",
            "Model saved to ./best_model.keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-29 09:56:17,895] Trial 1 finished with value: 576.812255859375 and parameters: {'optimizer': 'Adam', 'lr': 1.036106267875548e-05, 'n_layers': 5, 'n_units_layer0': 102, 'n_units_layer1': 73, 'n_units_layer2': 51, 'n_units_layer3': 80, 'n_units_layer4': 95, 'batch_size': 64}. Best is trial 0 with value: 16.728321075439453.\n",
            "[I 2024-04-29 09:56:21,973] Trial 2 finished with value: 452.2883605957031 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0004890853929158422, 'n_layers': 1, 'n_units_layer0': 19, 'batch_size': 128}. Best is trial 0 with value: 16.728321075439453.\n",
            "[I 2024-04-29 09:56:26,938] Trial 3 finished with value: 40.487648010253906 and parameters: {'optimizer': 'RMSprop', 'lr': 0.0006985000657621156, 'n_layers': 1, 'n_units_layer0': 115, 'batch_size': 128}. Best is trial 0 with value: 16.728321075439453.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 4\n",
            "Best trial:0\n",
            "Value: 16.728321075439453\n",
            "Params: \n",
            "    optimizer: RMSprop\n",
            "    lr: 0.017713347690583844\n",
            "    n_layers: 1\n",
            "    n_units_layer0: 69\n",
            "    batch_size: 64\n",
            "****************************************************************************************************\n",
            "***loaded best model***\n",
            "loaded best model from trial loss;23.576257705688477\n",
            "==============================\n",
            "loaded best model from keras loss;16.728321075439453\n",
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"b98b16a6-cc1a-44ca-b480-847028ff1eec\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b98b16a6-cc1a-44ca-b480-847028ff1eec\")) {                    Plotly.newPlot(                        \"b98b16a6-cc1a-44ca-b480-847028ff1eec\",                        [{\"mode\":\"markers\",\"name\":\"Real\",\"x\":[7.2,18.8,19.0,27.0,22.2,24.5,31.2,22.9,20.5,23.2,18.6,14.5,17.8,50.0,20.8,24.3,24.2,19.8,19.1,22.7,12.0,10.2,20.0,18.5,20.9,23.0,27.5,30.1,9.5,22.0,21.2,14.1,33.1,23.4,20.1,7.4,15.4,23.8,20.1,24.5,33.0,28.4,14.1,46.7,32.5,29.6,28.4,19.8,20.2,25.0,35.4,20.3,9.7,14.5,34.9,26.6,7.2,50.0,32.4,21.6,29.8,13.1,27.5,21.2,23.1,21.9,13.0,23.2,8.1,5.6,21.7,29.6,19.6,7.0,26.4,18.9,20.9,28.1,35.4,10.2,24.3,43.1,17.6,15.4,16.2,27.1,21.4,21.5,22.4,25.0,16.6,18.6,22.0,42.8,35.1,21.5,36.0,21.9,24.1,50.0,26.7,25.0],\"y\":[10.687026023864746,19.599857330322266,22.8770751953125,38.22423553466797,26.298776626586914,22.027978897094727,28.764596939086914,23.02851104736328,20.86722183227539,22.324861526489258,16.904664993286133,17.036306381225586,17.72981071472168,46.05845642089844,21.537078857421875,21.02463722229004,27.196704864501953,19.339143753051758,19.379709243774414,23.01673126220703,14.485576629638672,15.241658210754395,22.405046463012695,16.17931365966797,21.253355026245117,24.32514762878418,30.383275985717773,30.067230224609375,13.735366821289062,20.4530029296875,21.414087295532227,16.29607391357422,36.98442840576172,25.120403289794922,19.381696701049805,10.544893264770508,18.12481689453125,17.76349639892578,19.977121353149414,27.921703338623047,31.668956756591797,28.79303741455078,14.966662406921387,46.90701675415039,30.988340377807617,26.897705078125,28.19733428955078,19.22092056274414,23.034555435180664,24.615999221801758,37.60490036010742,20.851665496826172,13.580487251281738,15.143457412719727,38.33010482788086,29.258848190307617,13.354564666748047,52.85771560668945,38.422080993652344,24.199167251586914,26.61888885498047,17.648433685302734,16.53466796875,20.455408096313477,24.852773666381836,22.354272842407227,15.956867218017578,22.830564498901367,17.422285079956055,8.927003860473633,22.474891662597656,31.134214401245117,25.853960037231445,16.698328018188477,26.792325973510742,18.596431732177734,19.91016387939453,26.164960861206055,38.4089241027832,13.423813819885254,23.081300735473633,40.31971740722656,15.313859939575195,14.183126449584961,18.83258628845215,18.35462188720703,22.75919532775879,21.448665618896484,23.273252487182617,31.56484031677246,21.401416778564453,18.975643157958984,27.70784568786621,45.68099594116211,39.138336181640625,21.238588333129883,37.10160446166992,43.14096450805664,27.065500259399414,52.588050842285156,32.023765563964844,20.350242614746094],\"type\":\"scatter\"}],                        {\"hovermode\":\"closest\",\"title\":{\"text\":\"y_pred - y_test\"},\"xaxis\":{\"title\":{\"text\":\"y_test\"}},\"yaxis\":{\"title\":{\"text\":\"y_pred\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b98b16a6-cc1a-44ca-b480-847028ff1eec');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BatchNormalization追加 ←入っていた+predict(training=False)追加"
      ],
      "metadata": {
        "id": "_WUrfy16dkkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### code"
      ],
      "metadata": {
        "id": "QBnQ7k7RuqEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import re\n",
        "import glob\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "\n",
        "# データセットの準備（ここでは合成データセットを使用）\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
        "\n",
        "# データのスケーリング\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "class TestModel():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  # 最適化されたハイパーパラメータを使用してモデルを構築する関数\n",
        "  def build_model_from_trial(self,trial):\n",
        "      #モデルパラメータの取得\n",
        "      # print(f'trial params:{trial.params}')\n",
        "      units_len=trial.params['n_layers']\n",
        "      units=[value for key,value in trial.params.items() if 'n_units_layer' in key]\n",
        "      learning_rate=trial.params['lr']\n",
        "      optimizer_name=trial.params['optimizer']\n",
        "      # print(f'optimizer name:{optimizer_name}')\n",
        "      # print(f'lr:{learning_rate}')\n",
        "      # print(f'n layers:{len(units)}')\n",
        "      # print(f'units:{units}')\n",
        "\n",
        "      # モデルの構築\n",
        "      model=model_definitinon(units,optimizer_name,learning_rate)\n",
        "      # model=self.model_from_input(units,learning_rate,optimizer_name)\n",
        "\n",
        "      return model\n",
        "\n",
        "  def save_keras_model(self,model_save_path):\n",
        "    #kerasモデル保存\n",
        "    # model_save_path = './model'+str(trial.number)\n",
        "    tf.keras.models.save_model(model, model_save_path)\n",
        "\n",
        "\n",
        "  def load_keras_model(self,model_save_path):\n",
        "    #kerasモデル読み込み\n",
        "    # model_save_path = './model'+str(trial.number)\n",
        "    loaded_model = tf.keras.models.load_model(model_save_path)\n",
        "    # loaded_model.summary()\n",
        "    loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best keras model loss;{loss}')\n",
        "    return loaded_model\n",
        "\n",
        "\n",
        "  def build_model_from_pickle(self,pickle_path,trial_number):\n",
        "    #指定したpickleファイルのtrial_numberのモデルを読み込み\n",
        "    pickle_path='trials.pkl'\n",
        "    # 保存したtrialsを読み込む\n",
        "    with open(pickle_path, 'rb') as f:\n",
        "        loaded_trials = pickle.load(f)\n",
        "\n",
        "    # 読み込んだtrialsを表示\n",
        "    print(f'loaded trials:{loaded_trials}')\n",
        "    for i in loaded_trials:\n",
        "      print(f'trials{str(i.number)}:{i}')\n",
        "\n",
        "    # 指定したtrialのモデルを読み込み\n",
        "    return self.build_model_from_trial(trial_number)\n",
        "\n",
        "def model_definitinon(n_units_per_layer,optimizer_name,lr):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(Dense(n_units_per_layer[0], activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for units in n_units_per_layer[1:]:\n",
        "      model.add(Dense(units, activation='relu',kernel_initializer=HeNormal()))\n",
        "      model.add(BatchNormalization())\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # オプティマイザの設定\n",
        "    if optimizer_name == 'Adam':\n",
        "        # optimizer = Adam(lr=lr)\n",
        "        # optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    # elif optimizer_name == 'SGD':\n",
        "    #     # optimizer = SGD(lr=lr)\n",
        "    #     optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)\n",
        "    else:\n",
        "        # optimizer = RMSprop(lr=lr)\n",
        "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
        "        # optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=lr)\n",
        "\n",
        "    # モデルのコンパイル\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# 目的関数の定義\n",
        "def objective(trial):\n",
        "    #ハイパーパラメータの提案\n",
        "    ## オプティマイザの提案※SGDは使用しない\n",
        "    # optimizer_options = ['Adam', 'SGD', 'RMSprop']\n",
        "    optimizer_options = ['Adam', 'RMSprop']\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', optimizer_options)\n",
        "    ## 学習率の提案\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "    ## 各層の数、ユニット数の提案\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 5 )\n",
        "    n_units_per_layer = [trial.suggest_int(f'n_units_layer{i}', 8, 128) for i in range(n_layers)]\n",
        "    # バッチサイズの提案\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "\n",
        "    # モデルの構築\n",
        "    model=model_definitinon(n_units_per_layer,optimizer_name,lr)\n",
        "    # モデルの訓練\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # モデルの評価\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    # model.summary()\n",
        "    # print(f'loss;{loss}')\n",
        "\n",
        "    # best trialと最新モデル以外削除\n",
        "    ## 過去のtrialの.kerasを削除\n",
        "    pattern = re.compile(r'model_\\d+\\.keras$')\n",
        "    # List all files in the directory\n",
        "    cur_dir='.'\n",
        "    files = os.listdir(cur_dir)\n",
        "    for file in files:\n",
        "      # If the file matches the pattern\n",
        "      if pattern.match(file):\n",
        "        # Delete the file\n",
        "        os.remove(os.path.join(cur_dir, file))\n",
        "        # print(f\"Deleted file: {file}\")\n",
        "    # 現在のトライアルの.kerasモデルの保存\n",
        "    model_save_path = './model_'+str(trial.number)+'.keras'\n",
        "    model.save(model_save_path)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def save_trial_data(study,trial):\n",
        "    #パラメータを書き込み\n",
        "    write_trial_to_file(study,trial)\n",
        "    #モデルを保存\n",
        "    save_model(study,trial)\n",
        "\n",
        "def write_trial_to_file(study,trial):\n",
        "    # CSVファイルのパスとカラム名を指定\n",
        "    file_path = 'param.csv'\n",
        "    # n_layers=5\n",
        "\n",
        "    #列名が記載されたDataFrame作成\n",
        "    columns = ['trial_number','loss','optimizer', 'lr', 'batch_size','n_layers']\n",
        "    add_layer_columns=[\"n_units_layer\"+str(i) for i in range(trial.params['n_layers'])]\n",
        "    columns=columns+add_layer_columns\n",
        "    # print(f\"columns名：{columns}\")\n",
        "    trial_df=pd.DataFrame(columns=columns)\n",
        "\n",
        "    # ハイパーパラメータとlossの値を辞書に格納\n",
        "    trial_data = trial.params\n",
        "    # print(trial.params)\n",
        "    trial_data['loss'] = trial.value\n",
        "    trial_data['trial_number'] = trial.number\n",
        "\n",
        "    # DataFrameを作成\n",
        "    data_df=pd.DataFrame([trial_data])\n",
        "    trial_df=pd.concat([trial_df,data_df],ignore_index=True)\n",
        "    # print(f\"dic:{trial_data}\")\n",
        "    # print(f\"dataframe:{trial_df}\")\n",
        "\n",
        "    # 履歴データを書き込み\n",
        "    write_df_to_csv(file_path,trial_df)\n",
        "\n",
        "def write_df_to_csv(file_path, data_df):\n",
        "  #ファイル書き込みの関数を定義\n",
        "    try:\n",
        "      # 既存のCSVファイルがあるかチェック\n",
        "      if os.path.isfile(file_path):\n",
        "          # 既存のCSVファイルを読み込む\n",
        "          existing_df = pd.read_csv(file_path)\n",
        "          # 新しいデータを結合する\n",
        "          ##※データ欠損は0で補完\n",
        "          combined_df = pd.concat([existing_df, data_df], axis=0, ignore_index=True).fillna(0)\n",
        "      else:\n",
        "          # CSVファイルが存在しない場合は新しいDataFrameを作成\n",
        "          combined_df = data_df\n",
        "\n",
        "      # 結合したDataFrameをCSVに書き込む\n",
        "      combined_df.to_csv(file_path, index=False)\n",
        "    except Exception as e:\n",
        "        # エラーが発生した場合の処理\n",
        "        print(f'ファイル書き込み中にエラーが発生しました: {e}')\n",
        "\n",
        "def save_model(study,trial):\n",
        "    # 最新trialとモデルと最適モデルのみの.kerasモデルを保存する処理(保存自体はObjectiveで実施)+trial情報をplkで保存ためのコールバック関数\n",
        "    # ここで必要に応じてstudy.trialsを保存する処理を追加\n",
        "    trials_l = study.trials\n",
        "\n",
        "    # trialsを外部ファイルに保存\n",
        "    with open('trial_info.pkl', 'wb') as f:\n",
        "        pickle.dump(trials_l, f)\n",
        "\n",
        "    # print(f'trial number:{trial.number}')\n",
        "    # print(f'best trial number;{study.best_trial.number}')\n",
        "    # 現在のトライアルがbestトライアルならbest_trialとしてモデルを保存\n",
        "    if trial.number==study.best_trial.number:\n",
        "      load_model_path='./model_'+str(study.best_trial.number)+'.keras'\n",
        "      best_model=tf.keras.models.load_model(load_model_path)\n",
        "      model_save_path = './best_model.keras'\n",
        "      best_model.save(model_save_path)\n",
        "      print(f'Best trial trial number:{trial.number}')\n",
        "      print(f'Model saved to {model_save_path}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    #トライアル回数の指定\n",
        "    n_trials=4\n",
        "    #最適化の再開(True)か新規最適化(False)\n",
        "    resume_flag=False\n",
        "\n",
        "    # RDB Backendを使用したチェックポイントの保存\n",
        "    study_name = \"example-study\"\n",
        "    storage_name = f\"sqlite:///{study_name}.db\"\n",
        "    storage_path='./'+study_name+'.db'\n",
        "\n",
        "    if resume_flag==True:\n",
        "      # Studyオブジェクトの作成 → Hyper parameterの最適化\n",
        "      study = optuna.create_study(direction='minimize',study_name=study_name, storage=storage_name,load_if_exists=True)\n",
        "    else:\n",
        "      #初期化処理\n",
        "      ## keras file 削除\n",
        "      keras_files=glob.glob('./*.keras')\n",
        "      for k_file in keras_files:\n",
        "        os.remove(k_file)\n",
        "      ## pkl削除\n",
        "      pkl_path = './trial_info.pkl'\n",
        "      if os.path.exists(pkl_path):\n",
        "        os.remove(pkl_path)\n",
        "      ## param.csv削除\n",
        "      csv_path = './param.csv'\n",
        "      if os.path.exists(csv_path):\n",
        "        os.remove(csv_path)\n",
        "      # 最適化DBの初期化 → 最適化開始\n",
        "      if os.path.exists('./'+study_name+'.db'):\n",
        "        os.remove(storage_path)\n",
        "        study = optuna.create_study(direction='minimize',study_name=study_name, storage=storage_name)\n",
        "\n",
        "    # 最適化の開始\n",
        "    study.optimize(objective, n_trials=n_trials,callbacks=[save_trial_data])\n",
        "\n",
        "    # 最適化されたハイパーパラメータの出力\n",
        "    print('Number of finished trials:', len(study.trials))\n",
        "    trial = study.best_trial\n",
        "    print(f'Best trial:{trial.number}')\n",
        "    print('Value: {}'.format(trial.value))\n",
        "    print('Params: ')\n",
        "    for key, value in trial.params.items():\n",
        "        print('    {}: {}'.format(key, value))\n",
        "\n",
        "    print('**'*50)\n",
        "\n",
        "    #最適モデル構築from trial最適化時のlossにはならない\n",
        "    print(\"***loaded best model***\")\n",
        "    tm=TestModel()\n",
        "    model=tm.build_model_from_trial(trial)\n",
        "    batch_size=trial.params['batch_size']\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=batch_size, verbose=0)\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best model from trial loss;{loss}')\n",
        "    # print(model.summary())\n",
        "\n",
        "    # 最適モデル構築 from .keras\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    model_save_path = './best_model.keras'\n",
        "    loaded_model = tf.keras.models.load_model(model_save_path)\n",
        "    loss = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'loaded best model from keras loss;{loss}')\n",
        "    # print(model.summary())\n",
        "\n",
        "    # 予測値の生成\n",
        "    y_pred = loaded_model.predict(X_test,training=False)\n",
        "\n",
        "    # グラフ化\n",
        "    import plotly.graph_objs as go\n",
        "\n",
        "    # 訓練データ、実際の価格、予測価格をプロットするためのTraceを作成\n",
        "    valid_trace = go.Scatter(x=y_test, y=y_pred.flatten(), mode='markers', name='Real')\n",
        "\n",
        "    # データをリストにまとめる\n",
        "    data = [valid_trace]\n",
        "\n",
        "    # レイアウトを定義\n",
        "    layout = go.Layout(\n",
        "        title='y_pred - y_test',\n",
        "        xaxis={'title': 'y_test'},\n",
        "        yaxis={'title': 'y_pred'},\n",
        "        hovermode='closest'\n",
        "    )\n",
        "    # フィギュアを定義し、データとレイアウトを組み合わせる\n",
        "    fig = go.Figure(data=data, layout=layout)\n",
        "\n",
        "    # グラフを表示\n",
        "    fig.show()\n",
        ""
      ],
      "metadata": {
        "id": "mYk29XMjultD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test"
      ],
      "metadata": {
        "id": "G7UE7HMUh9-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import boston_housing\n",
        "import optuna\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "# データセットの準備（ここでは合成データセットを使用）\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# データのスケーリング\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "#データの作成\n",
        "# データの読み込み\n",
        "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()\n",
        "\n",
        "print(len(boston_housing.load_data()[0][1]))\n",
        "# 特徴エンジニアリング\n",
        "scaler = StandardScaler()\n",
        "train_data_scaled = scaler.fit_transform(train_data)\n",
        "test_data_scaled = scaler.transform(test_data)\n",
        "\n",
        "\n",
        "# データの分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_data_scaled, train_labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "phq2miSb5SOH",
        "outputId": "fba6a2cd-32c4-4b79-b52c-869f60847172",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "404\n"
          ]
        }
      ]
    }
  ]
}